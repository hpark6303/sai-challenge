"""
RAG íŒŒì´í”„ë¼ì¸ ë©”ì¸ ëª¨ë“ˆ
- ì „ì²´ RAG ì›Œí¬í”Œë¡œìš° ê´€ë¦¬
- ëª¨ë“ˆ ê°„ í˜‘ë ¥ ì¡°ì •
- ê²°ê³¼ ìƒì„± ë° ê²€ì¦
"""

import sys
from typing import List, Dict, Tuple
from .vector_db import VectorDatabase
from .retrieval import DocumentRetriever
from .reranking import DocumentReranker
from .answer_generator import AnswerGenerator
from .config import SEARCH_CONFIG, ANSWER_CONFIG, TEST_CONFIG

class RAGPipeline:
    """RAG íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, api_client, gemini_client):
        """
        RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        
        Args:
            api_client: ScienceON API í´ë¼ì´ì–¸íŠ¸
            gemini_client: Gemini API í´ë¼ì´ì–¸íŠ¸
        """
        # ë²¡í„° DB ì´ˆê¸°í™” ì—¬ë¶€ í™•ì¸
        clear_db = TEST_CONFIG.get('clear_vector_db', False)
        
        # ê° ëª¨ë“ˆ ì´ˆê¸°í™”
        self.vector_db = VectorDatabase(clear_db=clear_db)
        self.retriever = DocumentRetriever(api_client, gemini_client)  # Gemini í´ë¼ì´ì–¸íŠ¸ ì „ë‹¬
        self.reranker = DocumentReranker()
        self.answer_generator = AnswerGenerator(gemini_client)
        
        print("âœ… RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process_question(self, question_id: int, query: str) -> Tuple[str, List[str]]:
        """
        ë‹¨ì¼ ì§ˆë¬¸ ì²˜ë¦¬ (ì „ì²´ RAG ì›Œí¬í”Œë¡œìš°)
        
        Args:
            question_id: ì§ˆë¬¸ ID
            query: ì§ˆë¬¸ ë‚´ìš©
            
        Returns:
            (ë‹µë³€, ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸) íŠœí”Œ
        """
        print(f"\nğŸ” ì§ˆë¬¸ {question_id+1} ì²˜ë¦¬: '{query[:50]}...'")
        
        try:
            # 1ë‹¨ê³„: ë¬¸ì„œ ê²€ìƒ‰
            documents = self._retrieve_documents(query)
            print(f"   ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ: {len(documents)}ê°œ")
            
            # 2ë‹¨ê³„: ë²¡í„° DBì— ì €ì¥
            added_count = self.vector_db.add_documents(documents)
            if added_count > 0:
                print(f"   ğŸ“š ë²¡í„° DBì— {added_count}ê°œ ë¬¸ì„œ ì¶”ê°€")
            
            # 3ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰
            similar_docs = self.vector_db.search_similar(query)
            
            # 4ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ ë³´ì¶©
            final_docs = self.retriever.supplement_documents(similar_docs, documents)
            
            # 5ë‹¨ê³„: ì¬ìˆœìœ„í™”
            reranked_docs = self.reranker.rerank_documents(final_docs, query)
            
            # 6ë‹¨ê³„: ë‹µë³€ ìƒì„±ìš© ìƒìœ„ ë¬¸ì„œ ì„ íƒ
            context_docs = self.reranker.get_top_documents(reranked_docs)
            
            # 7ë‹¨ê³„: ë‹µë³€ ìƒì„±
            answer = self.answer_generator.generate_quality_answer(query, context_docs)
            
            # 8ë‹¨ê³„: ë…¼ë¬¸ ì •ë³´ í˜•ì‹í™”
            articles = self._format_articles(reranked_docs)
            
            return answer, articles
            
        except Exception as e:
            print(f"   âŒ ì§ˆë¬¸ {question_id+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}", [''] * 50
    
    def _retrieve_documents(self, query: str) -> List[Dict]:
        """
        ë¬¸ì„œ ê²€ìƒ‰ (CRAG íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            
        Returns:
            ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        return self.retriever.search_with_crag(query)
    
    def _format_articles(self, documents: List[Dict]) -> List[str]:
        """
        ë¬¸ì„œë¥¼ Kaggle í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì‹¤ì œ 50ê°œ ë¬¸ì„œ ë³´ì¥)
        
        Args:
            documents: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            Kaggle í˜•ì‹ì˜ ë…¼ë¬¸ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        articles = []
        
        # ì‹¤ì œ ë¬¸ì„œê°€ 50ê°œ ë¯¸ë§Œì´ë©´ ì¶”ê°€ ê²€ìƒ‰
        if len(documents) < 50:
            print(f"   ğŸš¨ ì‹¤ì œ ë¬¸ì„œ ë¶€ì¡±: {len(documents)}ê°œ (ëª©í‘œ: 50ê°œ)")
            print(f"   ğŸ” ì¶”ê°€ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
            
            # ì¶”ê°€ ê²€ìƒ‰ì„ ìœ„í•´ retriever ì‚¬ìš©
            additional_docs = self.retriever._emergency_search("", 50 - len(documents))
            documents.extend(additional_docs)
            documents = self.retriever._remove_duplicates(documents)
            
            print(f"   ğŸ“Š ì¶”ê°€ ê²€ìƒ‰ í›„: {len(documents)}ê°œ ë¬¸ì„œ")
        
        # ì •í™•íˆ 50ê°œ ë¬¸ì„œë§Œ ì‚¬ìš©
        documents = documents[:50]
        
        for doc in documents:
            formatted_article = self._create_kaggle_format_article(doc)
            if not formatted_article or formatted_article.strip() == '':
                # ë¹ˆ ë¬¸ì„œì¸ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´
                formatted_article = f'Title: {doc.get("title", "Research Document")}, Abstract: {doc.get("abstract", "This document contains relevant research information.")}, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn={doc.get("CN", "DOCUMENT")}'
            articles.append(formatted_article)
        
        # ì •í™•íˆ 50ê°œ ë°˜í™˜
        return articles[:50]
    
    def _create_kaggle_format_article(self, doc: Dict) -> str:
        """
        Kaggle í˜•ì‹ìœ¼ë¡œ ë…¼ë¬¸ ì •ë³´ ìƒì„±
        
        Args:
            doc: ë¬¸ì„œ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            Kaggle í˜•ì‹ì˜ ë¬¸ìì—´
        """
        title = doc.get('title', '')
        abstract = doc.get('abstract', '')
        cn = doc.get('CN', '')
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if not title or not cn:
            return ''
        
        # Source URL ìƒì„±
        source_url = f"http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn={cn}"
        
        # Abstractê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
        if not abstract:
            abstract = ''
        
        # Kaggle í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        return f'Title: {title}, Abstract: {abstract}, Source: {source_url}'
    
    def batch_process_questions(self, questions: List[Tuple[int, str]]) -> List[Tuple[int, str, List[str]]]:
        """
        ë°°ì¹˜ ì§ˆë¬¸ ì²˜ë¦¬
        
        Args:
            questions: (ì§ˆë¬¸ ID, ì§ˆë¬¸) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            (ì§ˆë¬¸ ID, ë‹µë³€, ë…¼ë¬¸ ì •ë³´) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for question_id, query in questions:
            answer, articles = self.process_question(question_id, query)
            results.append((question_id, answer, articles))
        
        return results
    
    def get_pipeline_stats(self) -> Dict:
        """
        íŒŒì´í”„ë¼ì¸ í†µê³„ ì •ë³´
        
        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        vector_stats = self.vector_db.get_stats()
        
        return {
            "vector_db": vector_stats,
            "search_config": SEARCH_CONFIG,
            "answer_config": ANSWER_CONFIG
        }
