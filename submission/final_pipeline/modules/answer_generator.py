"""
ë‹µë³€ ìƒì„± ëª¨ë“ˆ
- Gemini APIë¥¼ í†µí•œ ë‹µë³€ ìƒì„±
- í’ˆì§ˆ ê²€ì¦ ë° ì¬ì‹œë„
- Fallback ë‹µë³€ ì²˜ë¦¬
"""

import time
from typing import List, Dict, Tuple
from .config import ANSWER_CONFIG
from .prompting import PromptEngineer

class AnswerGenerator:
    """ë‹µë³€ ìƒì„±ê¸°"""
    
    def __init__(self, gemini_client):
        """
        ë‹µë³€ ìƒì„±ê¸° ì´ˆê¸°í™”
        
        Args:
            gemini_client: Gemini API í´ë¼ì´ì–¸íŠ¸
        """
        self.gemini_client = gemini_client
        self.prompt_engineer = PromptEngineer()
    
    def generate_answer(self, query: str, context: str, max_retries: int = ANSWER_CONFIG['max_retries']) -> str:
        """
        ë‹µë³€ ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            context: ì°¸ê³  ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            
        Returns:
            ìƒì„±ëœ ë‹µë³€
        """
        # ì–¸ì–´ ê°ì§€
        language = self.prompt_engineer.detect_language(query)
        
        # ì»¨í…ìŠ¤íŠ¸ ê°•í™”
        enhanced_context = self.prompt_engineer.enhance_context(context, query)
        
        # ì–¸ì–´ì— ë”°ë¥¸ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
        if language == "en":
            # ì˜ì–´ ì§ˆë¬¸: ì˜ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            prompt = self.prompt_engineer.create_english_prompt(query, enhanced_context)
        else:
            # í•œêµ­ì–´ ì§ˆë¬¸: í•œêµ­ì–´ íŠ¹í™” í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            prompt = self.prompt_engineer.create_final_prompt(query, enhanced_context, language)
        
        # ë‹µë³€ ìƒì„± (ì¬ì‹œë„ í¬í•¨)
        for attempt in range(max_retries):
            try:
                response = self.gemini_client.generate_answer(prompt)
                
                if response and self._validate_answer(response, query):
                    return response.strip()
                else:
                    print(f"   âš ï¸  ì‹œë„ {attempt + 1}: ë‹µë³€ í’ˆì§ˆ ë¶€ì¡±")
                    
            except Exception as e:
                print(f"   âš ï¸  ì‹œë„ {attempt + 1}: API í˜¸ì¶œ ì‹¤íŒ¨ - {str(e)[:50]}...")
            
            # ì¬ì‹œë„ ê°„ ëŒ€ê¸°
            if attempt < max_retries - 1:
                time.sleep(1)
        
        # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ì‹œ fallback ë‹µë³€
        return self._generate_fallback_answer(query)
    
    def _validate_answer(self, answer: str, query: str) -> bool:
        """
        ë‹µë³€ í’ˆì§ˆ ê²€ì¦ (ê°•í™”ëœ ë²„ì „)
        
        Args:
            answer: ìƒì„±ëœ ë‹µë³€
            query: ì›ë³¸ ì§ˆë¬¸
            
        Returns:
            í’ˆì§ˆ ê²€ì¦ ê²°ê³¼
        """
        if not answer or not answer.strip():
            return False
        
        # ìµœì†Œ ê¸¸ì´ ê²€ì¦
        if len(answer.strip()) < ANSWER_CONFIG['min_answer_length']:
            return False
        
        # ê¸°ë³¸ì ì¸ í’ˆì§ˆ ê²€ì¦
        if answer.lower() in ['ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤', 'error', 'failed', 'cannot generate']:
            return False
        
        # ë©”íƒ€ ì„¤ëª… ê²€ì¦ (ì œê±°ëœ ë©”íƒ€ ì„¤ëª…ì´ ë‹¤ì‹œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸)
        meta_phrases = [
            'ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ', 'ë¬¸ì„œ ë¶„ì„ì„ í†µí•œ', 'ì°¸ê³ ë¬¸í—Œì„ í†µí•´',
            'based on the provided documents', 'document analysis shows', 'according to the references'
        ]
        
        answer_lower = answer.lower()
        for phrase in meta_phrases:
            if phrase in answer_lower:
                print(f"   âš ï¸  ë©”íƒ€ ì„¤ëª… ê°ì§€: {phrase}")
                return False
        
        # êµ¬ì¡° ê²€ì¦ (ì œëª©, ë³¸ë¬¸, ê²°ë¡  í¬í•¨ ì—¬ë¶€)
        has_title = any(keyword in answer for keyword in ['ì œëª©:', 'Title:', '**ì œëª©**', '**Title**'])
        has_body = any(keyword in answer for keyword in ['ë³¸ë¡ :', 'Main Body:', '**ë³¸ë¡ **', '**Main Body**'])
        has_conclusion = any(keyword in answer for keyword in ['ê²°ë¡ :', 'Conclusion:', '**ê²°ë¡ **', '**Conclusion**'])
        
        # ìµœì†Œí•œ ì œëª©ê³¼ ë³¸ë¬¸ì€ ìˆì–´ì•¼ í•¨
        if not (has_title or has_body):
            return False
        
        return True
    
    def _generate_fallback_answer(self, query: str) -> str:
        """
        Fallback ë‹µë³€ ìƒì„±
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            Fallback ë‹µë³€
        """
        language = self.prompt_engineer.detect_language(query)
        
        if language == "ko":
            return f"ì§ˆë¬¸ '{query}'ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì œê³µëœ ì°¸ê³  ë¬¸ì„œë¥¼ í™•ì¸í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
        else:
            return f"An error occurred while generating an answer for the question '{query}'. Please check the provided reference documents."
    
    def generate_quality_answer(self, query: str, documents: List[Dict], 
                              max_retries: int = ANSWER_CONFIG['max_retries']) -> str:
        """
        í’ˆì§ˆì´ ë³´ì¥ëœ ë‹µë³€ ìƒì„±
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            documents: ì°¸ê³  ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            
        Returns:
            í’ˆì§ˆ ë³´ì¥ëœ ë‹µë³€
        """
        if not documents:
            return self._generate_fallback_answer(query)
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = self._create_context_from_documents(documents)
        
        # ë‹µë³€ ìƒì„±
        answer = self.generate_answer(query, context, max_retries)
        
        # í’ˆì§ˆ ì¬ê²€ì¦
        if not self._validate_answer(answer, query):
            # ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
            simple_prompt = self.prompt_engineer.create_simple_prompt(query, context)
            try:
                answer = self.gemini_client.generate_answer(simple_prompt)
                if answer:
                    answer = answer.strip()
            except:
                pass
        
        return answer if self._validate_answer(answer, query) else self._generate_fallback_answer(query)
    
    def _create_context_from_documents(self, documents: List[Dict]) -> str:
        """
        ë¬¸ì„œë“¤ë¡œë¶€í„° í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ëŒ€íšŒ í•µì‹¬ ìš”êµ¬ì‚¬í•­)
        
        Args:
            documents: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í™•ì¥ëœ ì»¨í…ìŠ¤íŠ¸
        """
        if not documents:
            return ""
        
        context_parts = []
        for i, doc in enumerate(documents[:ANSWER_CONFIG['max_context_docs']]):
            # ë¬¸ì„œ í™•ì¥
            expanded_content = self._expand_document_content(doc)
            
            context = f"[ë¬¸ì„œ {i+1}]\n"
            context += f"ì œëª©: {doc.get('title', '')}\n"
            context += f"í™•ì¥ëœ ë‚´ìš©: {expanded_content}\n"
            context_parts.append(context)
        
        return "\n".join(context_parts)
    
    def _expand_document_content(self, document: Dict) -> str:
        """
        ë¬¸ì„œ ë‚´ìš© í™•ì¥ (ëŒ€íšŒ í•µì‹¬ ìš”êµ¬ì‚¬í•­)
        
        Args:
            document: ì›ë³¸ ë¬¸ì„œ
            
        Returns:
            í™•ì¥ëœ ë¬¸ì„œ ë‚´ìš©
        """
        title = document.get('title', '')
        abstract = document.get('abstract', '')
        
        # 1. ê¸°ë³¸ ë‚´ìš©
        expanded = abstract
        
        # 2. ì œëª©ì—ì„œ í•µì‹¬ ê°œë… ì¶”ì¶œ ë° ì„¤ëª… ì¶”ê°€
        title_concepts = self._extract_concepts_from_title(title)
        if title_concepts:
            expanded += f"\n\ní•µì‹¬ ê°œë…: {', '.join(title_concepts)}"
        
        # 3. ë°©ë²•ë¡ /ê¸°ìˆ  ì¶”ì¶œ ë° ì„¤ëª…
        methodologies = self._extract_methodologies(abstract)
        if methodologies:
            expanded += f"\n\nì£¼ìš” ë°©ë²•ë¡ : {', '.join(methodologies)}"
        
        # 4. ê²°ê³¼/ì„±ê³¼ ì¶”ì¶œ
        results = self._extract_results(abstract)
        if results:
            expanded += f"\n\nì£¼ìš” ê²°ê³¼: {', '.join(results)}"
        
        # 5. ì‘ìš© ë¶„ì•¼ ì¶”ì¶œ
        applications = self._extract_applications(abstract)
        if applications:
            expanded += f"\n\nì‘ìš© ë¶„ì•¼: {', '.join(applications)}"
        
        return expanded
    
    def _extract_concepts_from_title(self, title: str) -> List[str]:
        """ì œëª©ì—ì„œ í•µì‹¬ ê°œë… ì¶”ì¶œ"""
        concepts = []
        
        # ì „ë¬¸ ìš©ì–´ íŒ¨í„´ ë§¤ì¹­
        technical_terms = [
            'neural network', 'machine learning', 'deep learning', 'artificial intelligence',
            'algorithm', 'framework', 'methodology', 'approach', 'technique',
            'sustainability', 'corporate culture', 'management', 'strategy',
            'mathematics', 'engineering', 'medical', 'clinical'
        ]
        
        title_lower = title.lower()
        for term in technical_terms:
            if term in title_lower:
                concepts.append(term)
        
        return concepts[:3]  # ìƒìœ„ 3ê°œë§Œ
    
    def _extract_methodologies(self, abstract: str) -> List[str]:
        """ì´ˆë¡ì—ì„œ ë°©ë²•ë¡  ì¶”ì¶œ"""
        methodologies = []
        
        # ë°©ë²•ë¡  ê´€ë ¨ í‚¤ì›Œë“œ
        method_keywords = [
            'method', 'approach', 'technique', 'algorithm', 'framework',
            'model', 'system', 'procedure', 'strategy', 'methodology'
        ]
        
        sentences = abstract.split('.')
        for sentence in sentences:
            sentence_lower = sentence.lower()
            for keyword in method_keywords:
                if keyword in sentence_lower:
                    # í•´ë‹¹ ë¬¸ì¥ì—ì„œ í•µì‹¬ ë¶€ë¶„ ì¶”ì¶œ
                    start = max(0, sentence_lower.find(keyword) - 50)
                    end = min(len(sentence), sentence_lower.find(keyword) + 100)
                    methodologies.append(sentence[start:end].strip())
                    break
        
        return methodologies[:2]  # ìƒìœ„ 2ê°œë§Œ
    
    def _extract_results(self, abstract: str) -> List[str]:
        """ì´ˆë¡ì—ì„œ ê²°ê³¼ ì¶”ì¶œ"""
        results = []
        
        # ê²°ê³¼ ê´€ë ¨ í‚¤ì›Œë“œ
        result_keywords = [
            'result', 'outcome', 'performance', 'accuracy', 'efficiency',
            'improvement', 'enhancement', 'effectiveness', 'success'
        ]
        
        sentences = abstract.split('.')
        for sentence in sentences:
            sentence_lower = sentence.lower()
            for keyword in result_keywords:
                if keyword in sentence_lower:
                    start = max(0, sentence_lower.find(keyword) - 30)
                    end = min(len(sentence), sentence_lower.find(keyword) + 80)
                    results.append(sentence[start:end].strip())
                    break
        
        return results[:2]  # ìƒìœ„ 2ê°œë§Œ
    
    def _extract_applications(self, abstract: str) -> List[str]:
        """ì´ˆë¡ì—ì„œ ì‘ìš© ë¶„ì•¼ ì¶”ì¶œ"""
        applications = []
        
        # ì‘ìš© ë¶„ì•¼ í‚¤ì›Œë“œ
        application_keywords = [
            'application', 'use', 'implement', 'deploy', 'apply',
            'industry', 'field', 'domain', 'sector', 'area'
        ]
        
        sentences = abstract.split('.')
        for sentence in sentences:
            sentence_lower = sentence.lower()
            for keyword in application_keywords:
                if keyword in sentence_lower:
                    start = max(0, sentence_lower.find(keyword) - 40)
                    end = min(len(sentence), sentence_lower.find(keyword) + 60)
                    applications.append(sentence[start:end].strip())
                    break
        
        return applications[:2]  # ìƒìœ„ 2ê°œë§Œ
    
    def batch_generate_answers(self, questions: List[Tuple[int, str]], 
                             documents_list: List[List[Dict]]) -> List[str]:
        """
        ë°°ì¹˜ ë‹µë³€ ìƒì„±
        
        Args:
            questions: (ì§ˆë¬¸ ID, ì§ˆë¬¸) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
            documents_list: ê° ì§ˆë¬¸ë³„ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ìƒì„±ëœ ë‹µë³€ ë¦¬ìŠ¤íŠ¸
        """
        answers = []
        
        for (question_id, query), documents in zip(questions, documents_list):
            print(f"   ğŸ” ì§ˆë¬¸ {question_id+1} ë‹µë³€ ìƒì„± ì¤‘...")
            
            answer = self.generate_quality_answer(query, documents)
            answers.append(answer)
            
            # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
            time.sleep(0.5)
        
        return answers
