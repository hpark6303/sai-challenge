#!/usr/bin/env python3
"""
CRAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ ë²„ì „)
- CRAG ê¸°ëŠ¥ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
- ê³ ê¸‰ LLM ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
- êµì • ê²€ìƒ‰ì˜ íš¨ê³¼ ìƒì„¸ ë¶„ì„
- ë‹¨ì¼ ì§ˆë¬¸ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
"""

import sys
import time
from pathlib import Path
from scienceon_api_example import ScienceONAPIClient
from gemini_client import GeminiClient
from modules import RAGPipeline

def test_advanced_keyword_extraction():
    """ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§  ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    
    try:
        credentials_path = Path('./configs/scienceon_api_credentials.json')
        api_client = ScienceONAPIClient(credentials_path=credentials_path)
        
        gemini_credentials_path = Path('./configs/gemini_api_credentials.json')
        gemini_client = GeminiClient(gemini_credentials_path)
        
        pipeline = RAGPipeline(api_client, gemini_client)
        
        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
        test_questions = [
            "Mechanical Turk ë°ì´í„°ë¡œë¶€í„° TurKontrolì˜ POMDP íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµí•˜ì—¬ ë°˜ë³µì ì¸ í¬ë¼ìš°ë“œì†Œì‹± ì‘ì—…ì„ ìµœì í™”í•˜ëŠ” ì‹œìŠ¤í…œì˜ ì ‘ê·¼ ë°©ì‹ê³¼ ê²°ê³¼ëŠ” ë¬´ì—‡ì¸ê°€?",
            "ì¡ìŒ í™˜ê²½ì—ì„œ ì‹œì²­ê° ìŒì„±ì¸ì‹ì˜ ì¸ì‹ë¥ ì„ ë†’ì´ê¸° ìœ„í•´ ì€ë‹‰ ë§ˆë¥´ì½”í”„ ëª¨ë¸ê³¼ ì‹ ê²½ë§ í†µí•© ì „ëµì´ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€?",
            "DTG ì‹¤ ì£¼í–‰ë°ì´í„°ì™€ ê³µê°„ì •ë³´ë¥¼ í™œìš©í•œ ì—°ë£Œì†Œëª¨ëŸ‰ ì¶”ì • ëª¨ë¸ SBiFEMì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¥¼ ìš”ì•½í•´ ì£¼ì„¸ìš”."
        ]
        
        for i, question in enumerate(test_questions, 1):
            print(f"\n{'='*80}")
            print(f"ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ {i}: {question}")
            print(f"{'='*80}")
            
            # ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
            print(f"\nğŸ§  LLM ê¸°ë°˜ ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ:")
            start_time = time.time()
            
            advanced_keywords = pipeline.retriever._extract_keywords_with_llm(question)
            extraction_time = time.time() - start_time
            
            print(f"   â±ï¸  ì¶”ì¶œ ì‹œê°„: {extraction_time:.2f}ì´ˆ")
            print(f"   ğŸ”‘ ì¶”ì¶œëœ í‚¤ì›Œë“œ:")
            for j, keyword in enumerate(advanced_keywords, 1):
                print(f"      {j}. {keyword}")
            
            # ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œê³¼ ë¹„êµ
            print(f"\nğŸ“Š ê¸°ë³¸ í‚¤ì›Œë“œ ì¶”ì¶œê³¼ ë¹„êµ:")
            basic_keywords = pipeline.retriever._extract_keywords_basic(question)
            print(f"   ğŸ”‘ ê¸°ë³¸ í‚¤ì›Œë“œ: {', '.join(basic_keywords)}")
            print(f"   ğŸ§  ê³ ê¸‰ í‚¤ì›Œë“œ: {', '.join(advanced_keywords)}")
            
            # í‚¤ì›Œë“œ í’ˆì§ˆ í‰ê°€ (ê°„ë‹¨í•œ ê¸¸ì´ ê¸°ë°˜)
            avg_basic_length = sum(len(kw) for kw in basic_keywords) / len(basic_keywords) if basic_keywords else 0
            avg_advanced_length = sum(len(kw) for kw in advanced_keywords) / len(advanced_keywords) if advanced_keywords else 0
            
            print(f"   ğŸ“ í‰ê·  í‚¤ì›Œë“œ ê¸¸ì´: ê¸°ë³¸ {avg_basic_length:.1f}ì vs ê³ ê¸‰ {avg_advanced_length:.1f}ì")
            
    except Exception as e:
        print(f"âŒ ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

def test_crag_pipeline():
    """CRAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª CRAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ ë²„ì „)")
    
    # 1. API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    try:
        credentials_path = Path('./configs/scienceon_api_credentials.json')
        api_client = ScienceONAPIClient(credentials_path=credentials_path)
        
        gemini_credentials_path = Path('./configs/gemini_api_credentials.json')
        gemini_client = GeminiClient(gemini_credentials_path)
        
        print("âœ… API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return
    
    # 2. RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    pipeline = RAGPipeline(api_client, gemini_client)
    
    # 3. í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ (ë³µì¡í•œ í•™ìˆ  ì§ˆë¬¸ë“¤)
    test_questions = [
        "Mechanical Turk ë°ì´í„°ë¡œë¶€í„° TurKontrolì˜ POMDP íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµí•˜ì—¬ ë°˜ë³µì ì¸ í¬ë¼ìš°ë“œì†Œì‹± ì‘ì—…ì„ ìµœì í™”í•˜ëŠ” ì‹œìŠ¤í…œì˜ ì ‘ê·¼ ë°©ì‹ê³¼ ê²°ê³¼ëŠ” ë¬´ì—‡ì¸ê°€?",
        "ì¡ìŒ í™˜ê²½ì—ì„œ ì‹œì²­ê° ìŒì„±ì¸ì‹ì˜ ì¸ì‹ë¥ ì„ ë†’ì´ê¸° ìœ„í•´ ì€ë‹‰ ë§ˆë¥´ì½”í”„ ëª¨ë¸ê³¼ ì‹ ê²½ë§ í†µí•© ì „ëµì´ ì–´ë–»ê²Œ êµ¬ì„±ë˜ì—ˆëŠ”ì§€?",
        "DTG ì‹¤ ì£¼í–‰ë°ì´í„°ì™€ ê³µê°„ì •ë³´ë¥¼ í™œìš©í•œ ì—°ë£Œì†Œëª¨ëŸ‰ ì¶”ì • ëª¨ë¸ SBiFEMì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œë¥¼ ìš”ì•½í•´ ì£¼ì„¸ìš”."
    ]
    
    # 4. ê° ì§ˆë¬¸ì— ëŒ€í•´ CRAG í…ŒìŠ¤íŠ¸
    for i, question in enumerate(test_questions, 1):
        print(f"\n{'='*80}")
        print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ {i}: {question}")
        print(f"{'='*80}")
        
        try:
            # ì¼ë°˜ ê²€ìƒ‰ê³¼ CRAG ê²€ìƒ‰ ë¹„êµ
            print(f"\nğŸ“Š 1ë‹¨ê³„: ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼")
            start_time = time.time()
            
            # ì¼ë°˜ ê²€ìƒ‰ (CRAG ë¹„í™œì„±í™”)
            pipeline.retriever.gemini_client = None  # ì„ì‹œë¡œ ë¹„í™œì„±í™”
            normal_docs = pipeline.retriever.search_with_retry(question)
            normal_time = time.time() - start_time
            
            print(f"   ğŸ“š ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼: {len(normal_docs)}ê°œ ë¬¸ì„œ")
            print(f"   â±ï¸  ì†Œìš” ì‹œê°„: {normal_time:.2f}ì´ˆ")
            
            # ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼ ìƒ˜í”Œ ì¶œë ¥
            if normal_docs:
                print(f"   ğŸ“„ ì¼ë°˜ ê²€ìƒ‰ ìƒ˜í”Œ:")
                for j, doc in enumerate(normal_docs[:3], 1):
                    title = doc.get('title', 'N/A')[:50]
                    print(f"      {j}. {title}...")
            
            # CRAG ê²€ìƒ‰ (Gemini í´ë¼ì´ì–¸íŠ¸ ë³µì›)
            pipeline.retriever.gemini_client = gemini_client
            
            print(f"\nğŸ”„ 2ë‹¨ê³„: CRAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ)")
            start_time = time.time()
            
            # CRAG íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì²˜ë¦¬
            answer, articles = pipeline.process_question(i-1, question)
            crag_time = time.time() - start_time
            
            print(f"   â±ï¸  CRAG ì†Œìš” ì‹œê°„: {crag_time:.2f}ì´ˆ")
            print(f"   ğŸ“š CRAG ê²€ìƒ‰ ê²°ê³¼: {len(articles)}ê°œ ë…¼ë¬¸")
            
            # CRAG ê²€ìƒ‰ ê²°ê³¼ ìƒ˜í”Œ ì¶œë ¥
            if articles:
                print(f"   ğŸ“„ CRAG ê²€ìƒ‰ ìƒ˜í”Œ:")
                for j, article in enumerate(articles[:3], 1):
                    title_start = article.find('Title: ') + 7
                    title_end = article.find(', Abstract:')
                    title = article[title_start:title_end][:50] if title_start > 6 and title_end > title_start else article[:50]
                    print(f"      {j}. {title}...")
            
            # ê²°ê³¼ ë¹„êµ ë¶„ì„
            print(f"\nğŸ“ˆ 3ë‹¨ê³„: ê²°ê³¼ ë¹„êµ ë¶„ì„")
            print(f"   â±ï¸  ì‹œê°„ ì°¨ì´: CRAGê°€ {crag_time - normal_time:.2f}ì´ˆ ë” ì†Œìš”")
            print(f"   ğŸ“Š ë¬¸ì„œ ìˆ˜ ì°¨ì´: {len(articles)} vs {len(normal_docs)}")
            
            # í’ˆì§ˆ í‰ê°€ ì‹œë®¬ë ˆì´ì…˜ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­)
            question_keywords = set(question.lower().split())
            normal_relevance = sum(1 for doc in normal_docs[:10] 
                                 if any(keyword in doc.get('title', '').lower() 
                                       for keyword in question_keywords))
            crag_relevance = sum(1 for article in articles[:10] 
                               if any(keyword in article.lower() 
                                     for keyword in question_keywords))
            
            print(f"   ğŸ¯ ê´€ë ¨ì„± ì ìˆ˜ (í‚¤ì›Œë“œ ë§¤ì¹­):")
            print(f"      ì¼ë°˜ ê²€ìƒ‰: {normal_relevance}/10")
            print(f"      CRAG ê²€ìƒ‰: {crag_relevance}/10")
            
            # ë‹µë³€ í’ˆì§ˆ ë¶„ì„
            print(f"\nğŸ“ 4ë‹¨ê³„: ìƒì„±ëœ ë‹µë³€")
            print(f"   ğŸ“ ë‹µë³€ ê¸¸ì´: {len(answer)}ì")
            print(f"   ğŸ“„ ë‹µë³€ ë¯¸ë¦¬ë³´ê¸°:")
            print(f"   {answer[:300]}...")
            
            # ìƒì„¸ ë¶„ì„ ìš”ì•½
            print(f"\nğŸ“Š 5ë‹¨ê³„: ìƒì„¸ ë¶„ì„ ìš”ì•½")
            print(f"   âœ… CRAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ")
            print(f"   ğŸ” ê²€ìƒ‰ëœ ë…¼ë¬¸ ìˆ˜: {len(articles)}ê°œ")
            print(f"   â±ï¸  ì´ ì²˜ë¦¬ ì‹œê°„: {crag_time:.2f}ì´ˆ")
            print(f"   ğŸ“ˆ ê´€ë ¨ì„± ê°œì„ : {'ì˜ˆ' if crag_relevance > normal_relevance else 'ì•„ë‹ˆì˜¤'}")
            
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    print(f"\nğŸ‰ CRAG íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ ìš”ì•½:")
    print(f"   - ì´ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {len(test_questions)}ê°œ")
    print(f"   - CRAG íŒŒì´í”„ë¼ì¸: ì •ìƒ ì‘ë™")
    print(f"   - ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ: LLM ê¸°ë°˜ ì¶”ì¶œ ì™„ë£Œ")
    print(f"   - í’ˆì§ˆ í‰ê°€: LLM ê¸°ë°˜ í‰ê°€ ì™„ë£Œ")
    print(f"   - êµì • ê²€ìƒ‰: ì¡°ê±´ë¶€ ì‹¤í–‰ ì™„ë£Œ")

def test_crag_detailed():
    """CRAG íŒŒì´í”„ë¼ì¸ì˜ ìƒì„¸ í…ŒìŠ¤íŠ¸ (ë‹¨ì¼ ì§ˆë¬¸)"""
    print("\nğŸ”¬ CRAG íŒŒì´í”„ë¼ì¸ ìƒì„¸ í…ŒìŠ¤íŠ¸")
    
    try:
        credentials_path = Path('./configs/scienceon_api_credentials.json')
        api_client = ScienceONAPIClient(credentials_path=credentials_path)
        
        gemini_credentials_path = Path('./configs/gemini_api_credentials.json')
        gemini_client = GeminiClient(gemini_credentials_path)
        
        pipeline = RAGPipeline(api_client, gemini_client)
        
        # ë‹¨ì¼ ì§ˆë¬¸ìœ¼ë¡œ ìƒì„¸ í…ŒìŠ¤íŠ¸
        question = "Mechanical Turk ë°ì´í„°ë¡œë¶€í„° TurKontrolì˜ POMDP íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµí•˜ì—¬ ë°˜ë³µì ì¸ í¬ë¼ìš°ë“œì†Œì‹± ì‘ì—…ì„ ìµœì í™”í•˜ëŠ” ì‹œìŠ¤í…œì˜ ì ‘ê·¼ ë°©ì‹ê³¼ ê²°ê³¼ëŠ” ë¬´ì—‡ì¸ê°€?"
        
        print(f"\nğŸ” ìƒì„¸ í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: {question}")
        
        # ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        print(f"\nğŸ§  ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ:")
        advanced_keywords = pipeline.retriever._extract_keywords_with_llm(question)
        print(f"   ì¶”ì¶œëœ í‚¤ì›Œë“œ: {', '.join(advanced_keywords)}")
        
        # 1ì°¨ ê²€ìƒ‰ ê²°ê³¼ ì €ì¥
        initial_docs = pipeline.retriever.search_with_retry(question)
        print(f"ğŸ“š 1ì°¨ ê²€ìƒ‰ ê²°ê³¼: {len(initial_docs)}ê°œ ë¬¸ì„œ")
        
        # í’ˆì§ˆ í‰ê°€
        quality_score, issues = pipeline.retriever._evaluate_search_quality(question, initial_docs)
        print(f"ğŸ“Š í’ˆì§ˆ í‰ê°€ ê²°ê³¼:")
        print(f"   - ì ìˆ˜: {quality_score:.2f}/10")
        print(f"   - ë¬¸ì œì : {issues}")
        
        # êµì • ê²€ìƒ‰ ì‹¤í–‰
        corrected_docs = pipeline.retriever._corrective_search(question, initial_docs, issues)
        print(f"ğŸ”„ êµì • ê²€ìƒ‰ ê²°ê³¼: {len(corrected_docs)}ê°œ ë¬¸ì„œ")
        
        # êµì • í›„ í’ˆì§ˆ ì¬í‰ê°€
        corrected_score, corrected_issues = pipeline.retriever._evaluate_search_quality(question, corrected_docs)
        print(f"ğŸ“Š êµì • í›„ í’ˆì§ˆ í‰ê°€:")
        print(f"   - ì ìˆ˜: {corrected_score:.2f}/10")
        print(f"   - ê°œì„ ë„: {corrected_score - quality_score:.2f}ì ")
        
        # ë¬¸ì„œ ë¹„êµ
        print(f"\nğŸ“‹ ë¬¸ì„œ ë¹„êµ ë¶„ì„:")
        initial_titles = [doc.get('title', '')[:30] for doc in initial_docs[:5]]
        corrected_titles = [doc.get('title', '')[:30] for doc in corrected_docs[:5]]
        
        print(f"   1ì°¨ ê²€ìƒ‰ ìƒìœ„ 5ê°œ:")
        for i, title in enumerate(initial_titles, 1):
            print(f"      {i}. {title}...")
        
        print(f"   êµì • ê²€ìƒ‰ ìƒìœ„ 5ê°œ:")
        for i, title in enumerate(corrected_titles, 1):
            print(f"      {i}. {title}...")
        
    except Exception as e:
        print(f"âŒ ìƒì„¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # ê³ ê¸‰ í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    test_advanced_keyword_extraction()
    
    # ê¸°ë³¸ CRAG í…ŒìŠ¤íŠ¸
    test_crag_pipeline()
    
    # ìƒì„¸ í…ŒìŠ¤íŠ¸ (ì„ íƒì )
    print(f"\n{'='*80}")
    print("ìƒì„¸ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
    try:
        choice = input().strip().lower()
        if choice in ['y', 'yes', 'ì˜ˆ']:
            test_crag_detailed()
    except:
        pass
    
    print(f"\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
