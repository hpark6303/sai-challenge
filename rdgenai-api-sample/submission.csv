Question,SAI_Answer,translated_question,translated_SAI_answer,retrieved_article_name_1,retrieved_article_name_2,retrieved_article_name_3,retrieved_article_name_4,retrieved_article_name_5,retrieved_article_name_6,retrieved_article_name_7,retrieved_article_name_8,retrieved_article_name_9,retrieved_article_name_10,retrieved_article_name_11,retrieved_article_name_12,retrieved_article_name_13,retrieved_article_name_14,retrieved_article_name_15,retrieved_article_name_16,retrieved_article_name_17,retrieved_article_name_18,retrieved_article_name_19,retrieved_article_name_20,retrieved_article_name_21,retrieved_article_name_22,retrieved_article_name_23,retrieved_article_name_24,retrieved_article_name_25,retrieved_article_name_26,retrieved_article_name_27,retrieved_article_name_28,retrieved_article_name_29,retrieved_article_name_30,retrieved_article_name_31,retrieved_article_name_32,retrieved_article_name_33,retrieved_article_name_34,retrieved_article_name_35,retrieved_article_name_36,retrieved_article_name_37,retrieved_article_name_38,retrieved_article_name_39,retrieved_article_name_40,retrieved_article_name_41,retrieved_article_name_42,retrieved_article_name_43,retrieved_article_name_44,retrieved_article_name_45,retrieved_article_name_46,retrieved_article_name_47,retrieved_article_name_48,retrieved_article_name_49,retrieved_article_name_50,id,elapsed_times,Prediction,prediction_retrieved_article_name_1,prediction_retrieved_article_name_2,prediction_retrieved_article_name_3,prediction_retrieved_article_name_4,prediction_retrieved_article_name_5,prediction_retrieved_article_name_6,prediction_retrieved_article_name_7,prediction_retrieved_article_name_8,prediction_retrieved_article_name_9,prediction_retrieved_article_name_10,prediction_retrieved_article_name_11,prediction_retrieved_article_name_12,prediction_retrieved_article_name_13,prediction_retrieved_article_name_14,prediction_retrieved_article_name_15,prediction_retrieved_article_name_16,prediction_retrieved_article_name_17,prediction_retrieved_article_name_18,prediction_retrieved_article_name_19,prediction_retrieved_article_name_20,prediction_retrieved_article_name_21,prediction_retrieved_article_name_22,prediction_retrieved_article_name_23,prediction_retrieved_article_name_24,prediction_retrieved_article_name_25,prediction_retrieved_article_name_26,prediction_retrieved_article_name_27,prediction_retrieved_article_name_28,prediction_retrieved_article_name_29,prediction_retrieved_article_name_30,prediction_retrieved_article_name_31,prediction_retrieved_article_name_32,prediction_retrieved_article_name_33,prediction_retrieved_article_name_34,prediction_retrieved_article_name_35,prediction_retrieved_article_name_36,prediction_retrieved_article_name_37,prediction_retrieved_article_name_38,prediction_retrieved_article_name_39,prediction_retrieved_article_name_40,prediction_retrieved_article_name_41,prediction_retrieved_article_name_42,prediction_retrieved_article_name_43,prediction_retrieved_article_name_44,prediction_retrieved_article_name_45,prediction_retrieved_article_name_46,prediction_retrieved_article_name_47,prediction_retrieved_article_name_48,prediction_retrieved_article_name_49,prediction_retrieved_article_name_50
How can the rationale and structure of the free electronic textbook outlining the essential mathematics for understanding AI in a one- or two-semester undergraduate course be summarized?,"##Free Electronic Textbook on Essential Mathematics for AI## ##Introduction## As artificial intelligence permeates modern industries—from healthcare and robotics to smart homes and IoT—understanding its underlying mathematical principles has become indispensable for undergraduate students. To address this need, a research team developed a free electronic textbook titled “Fundamental Mathematics for AI,” designed to cover all core math concepts required for AI and machine learning within one or two semesters. ##Main Body## The textbook is organized into modular chapters that build progressively: it begins with vector and matrix operations fundamental to neural networks, then introduces probability theory and statistical inference for data modeling, followed by calculus and optimization techniques that underpin learning algorithms. Each module includes context-relevant examples, problem-solving exercises, and visualizations tailored to the local curriculum, ensuring practical comprehension. Accompanying online resources and interactive lectures support students from diverse majors, reinforcing theoretical material with hands-on applications in Python and MATLAB. The entire course framework—from learning objectives to assessment items—has been openly shared and successfully implemented at the undergraduate and graduate levels. ##Conclusion## By structuring essential topics into a cohesive, semester-based sequence and providing free, adaptable materials, this electronic textbook equips learners with the rigorous mathematical toolkit required for AI and facilitates broader access to high-quality instruction in rapidly evolving technological fields.",없음,없음,"Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",0,1.1859924140007934,"**Title:**  Structuring a Free Electronic Textbook on Essential Mathematics for AI: A Rationale-Based Approach

**Introduction:** This report addresses the question of how to summarize the rationale and structure of a free electronic textbook outlining the essential mathematics for understanding AI in a one- or two-semester undergraduate course.  While the provided documents do not directly address textbook creation in AI mathematics, they offer insights into relevant pedagogical and structural considerations that can inform the design and rationale of such a textbook.

**Body:**  The creation of a successful textbook requires a clear understanding of pedagogical principles and a well-defined structure. Document 1, ""25 Years of HOW: A Celebration of Language Teaching and Learning,"" highlights the importance of post-method pedagogy, acknowledging the limitations of a single ""best"" method. This approach emphasizes adapting teaching to the specific context and learners.  Applying this to an AI mathematics textbook, the structure should be adaptable to different learning styles and prior knowledge levels.  The textbook should incorporate elements of positive psychology (Document 1), focusing on fostering a positive learning environment to enhance student engagement and motivation.  Furthermore, the inclusion of metacognitive strategies (Document 1), encouraging students to reflect on their learning process, would greatly improve comprehension and retention.

The textbook's structure should also prioritize clarity and logical progression.  Document 2, ""Rationale modeling for software process evolution,"" stresses the importance of documenting the rationale behind decisions in any evolving system.  This principle applies directly to the textbook's structure.  Each mathematical concept should be introduced with a clear rationale explaining its relevance to AI, connecting the abstract mathematics to practical applications. This rationale should be continuously visualized (Document 4, ""Continuous Rationale Visualization"") to aid navigation and understanding. The textbook should utilize a knowledge graph structure (Document 4), linking concepts, examples, and applications, enabling users to easily navigate the material and access relevant information.

Document 3, ""The Free Choice Condition for Any, a Free Choice Indefinite,"" while focused on linguistics, highlights the importance of a unified and consistent approach.  The textbook's mathematical concepts should be presented consistently, avoiding ambiguity and ensuring a smooth transition between different topics.

Finally, Document 5, ""How the 'What' Becomes the 'How',"" discusses the importance of dynamic adaptation in a changing environment.  The textbook, being a digital resource, should be designed to be easily updated and improved over time, incorporating feedback from users and adapting to advancements in the field of AI. This necessitates a clear rationale behind each section's inclusion, allowing for future modification and enhancement based on feedback and evolving AI requirements.

**Conclusion:**  Building a free electronic textbook on essential mathematics for AI requires a structured approach informed by pedagogical principles.  A post-method approach emphasizes adaptability to different learning styles.  Integrating positive psychology and metacognitive strategies enhances student engagement and understanding.  A clear rationale for the inclusion of each mathematical concept and its relevance to AI is essential, implemented using a well-structured knowledge graph to allow for easy navigation and updates. The emphasis should be on continuous improvement based on user feedback and changes in the AI field.  The textbook structure must be flexible enough to adapt to these changes, mirroring the principles of continuous rationale visualization and dynamic adaptability discussed in the provided literature.",25 Years of HOW: A Celebration of Language Teaching and Learning,Rationale modeling for software process evolution,"The Free Choice Condition for Any, a Free Choice Indefinite",Continuous Rationale Visualization,How the 'What' Becomes the 'How',The Body as an Electronic Scheme,Mainstream economics and economic crises: how responsible? how reformable?,How do we know how?,Experimental validation on structure-borne underwater radiated noise transfer function analysis for marine structure,"Early Experiences with Microvascular Free Tissue Transfer in Lagos, Nigeria",Transferability of Electronic Bills of Lading,SEURAT : integrated rationale management,Structure? What Structure?,Co-movements of International Term Structure Slopes and Affine Term Structure Models,ESFWN-based Event Structure Frame Type Classifier for Event Structure-dependent Inferencing,"Personality, specificity and structure in psychosomatics",Restructuring and Virtual Structure,The young structure based on N-structure and its application in BCI/BCK-algebras,Electronic Commerce,"MOLECULAR STRUCTURE, CRYSTAL STRUCTURE AND ABSOLUTE CONFIGURATION OF TENACISS IGENIN",Electronic portfolios,"Regionalism in the Asia-Pacific Region: How Wide, How Deep?",The notion of structure in psychiatry.,Free T4 immunoassays are flawed during pregnancy,Free Relatives and Projections,Electronic mail and Unix,The rationale for Rationale&trade;,The rationale for Rationale&trade;,"The Procedural Syllabus and the Task Syllabus: How Similar, How Different?",Design rationale : the rationale and the barriers,The microprocessor rationale,[The Homo-animal rationale],Emerging Electronic Documentary Credit and Electronic Presentation of Documents,"Nicotine Dependence of Electronic Cigarette, Dual Combustible and Electronic Cigarette Users",Analysis on Electronic Payments:A Key Factor of Electronic Commerce,전자게임의 시대별 변천과정에 관한 연구,Transport aircraft requirements - How much? How soon? How to pay?,An undergraduate rootkit research project : How available? How hard? How dangerous?,옵션기반의 Generic Product Structure and Configuration 모델링,Science in space- How pure - How pragmatic,Rationale des kinematischen Alignments,Rationale of Overdenture,Cholesterol Free 우유의 품질특성,제형별 오존 free 플라즈마 안정도 검토,Cholesterol Free Mozzarella Cheese 제조에 관한 연구,HOW TO CHEAT,Barrier Free 보행안전시설 계획,"친환경 압전소자를 위한 (Na, K)NbO3 계열 무연 세라믹스의 제조 및 특성평가",HD-Tree: 고성능 Lock-Free NNS KD-Tree,Electronic Government
How do artificial neural networks employ weight matrices and vector mappings to relate inputs and outputs in applied linguistics?,"##Artificial Neural Networks and Their Mathematical Mapping## ##Introduction## Artificial neural networks (ANNs) use mathematical structures to transform linguistic inputs into meaningful outputs. By representing each layer’s activations as vectors and interconnecting them with weight matrices, ANNs provide a framework for modeling complex relationships in language data. ##Main Body## An input vector encodes linguistic features (e.g., word embeddings or syntactic cues). This vector is multiplied by a weight matrix to yield a new vector, which passes through a non-linear activation function to introduce flexibility. In multilayer networks, each subsequent hidden layer repeats this vector-matrix multiplication, enabling the system to capture increasingly abstract linguistic patterns. During training, the network adjusts its weight matrices via optimization algorithms (such as gradient descent) to minimize the difference between predicted output vectors and target outputs, thereby learning the proper mapping from inputs to outputs. ##Conclusion## Through iterative matrix multiplications and nonlinear activations, ANNs learn to map input representations of language into desired outputs, underpinning tasks like translation, parsing, and semantic interpretation in applied linguistics.",없음,없음,"Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",1,1.1859924140007934,"**Title:** Weight Matrices and Vector Mappings in Artificial Neural Networks:  A Focus on Application Beyond Applied Linguistics

**Introduction:**

The question of how artificial neural networks (ANNs) utilize weight matrices and vector mappings to connect inputs and outputs is fundamental to understanding their functionality. While the provided documents don't directly address applied linguistics applications of ANNs, they offer insights into the underlying mechanisms of ANNs which are transferable across various domains. This report will analyze the provided texts to explain the role of weight matrices and vector mappings in ANNs, extrapolating this knowledge to the potential applications within applied linguistics.

**Body:**

ANNs, as demonstrated in Document 4 (""Hybrid Neural Networks for Pattern Recognition""), utilize a layered architecture.  The core of their operation involves the transformation of input vectors through weight matrices to produce output vectors.  The ""middle layer"" of a hybrid neural network, as described in Document 4, clusters learning vectors based on their distance, signifying a form of vector mapping.  The effectiveness of this clustering, and thus the accuracy of the network, depends on the dynamically adjusted vigilance parameter in the enhanced ART1 network (Document 4).  This adjustment can be seen as a method of refining the weight matrix over time, optimizing the network's mapping of input to output.

Document 1 (""NeuroVis: Real-Time Neural Information Measurement and Visualization of Embodied Neural Systems"") introduces NeuroVis, a tool visualizing the dynamic aspects of ANNs.  NeuroVis tracks not only the neural activities (which can be considered as vector mappings) but also the connection strength and plasticity (represented by the weight matrix).  The visualization techniques employed—spatial 2D position and connection, temporal color gradient, connection thickness, and temporal luminous intensity and change of connection thickness—illustrate how the weight matrix and vector mappings evolve over time in real-time applications like robot locomotion control and learning (Document 1). The changes in these visualizations directly reflect modifications in the weight matrix, which in turn refine the mapping between input and output signals.

Document 3 (""Trends in the development of communication networks: Cognitive networks"")  discusses cognitive networks, which, although different from ANNs, employ similar principles of information processing.  The discussion of artificial intelligence techniques suitable for cognitive networks (Document 3) indirectly supports the applicability of weight matrices and vector mappings within AI systems, showcasing the general principles underlying such systems. While not directly focused on ANNs, this document highlights the broader context of how these fundamental mathematical tools shape AI.


**Conclusion:**

While the provided documents do not explicitly detail the application of weight matrices and vector mappings within applied linguistics, they clearly demonstrate the fundamental role these elements play in the functionality of artificial neural networks.  The weight matrices encode the learned relationships between inputs and outputs, while vector mappings represent the transformations undergone by the data as it propagates through the network.  The dynamic adjustment of these elements, illustrated in the described systems, is crucial for learning and adaptation.  The principles illustrated in the analysis of NeuroVis, hybrid neural networks, and cognitive networks provide a strong foundation for understanding how ANNs, with their reliance on weight matrices and vector mappings, could be utilized within applied linguistics tasks such as natural language processing, machine translation, and speech recognition.  The adaptation and refinement of the weight matrix as depicted within the provided literature imply the network's capacity to learn and improve its mapping of linguistic data, leading to more accurate and efficient processing.",NeuroVis: Real-Time Neural Information Measurement and Visualization of Embodied Neural Systems,"Scholarly network similarities: How bibliographic coupling networks, citation networks, cocitation networks, topical networks, coauthorship networks, and coword networks relate to each other",Trends in the development of communication networks: Cognitive networks,Hybrid Neural Networks for Pattern Recognition,How the 'What' Becomes the 'How',Neural Stem Cells and Ischemic Brain,What sort of networks are public health networks?,"Nonblocking multirate <i>log</i><sub>2</sub>(<i>N</i>,<i>m</i>,<i>p</i>) switching networks with multicast connections",Mainstream economics and economic crises: how responsible? how reformable?,25 Years of HOW: A Celebration of Language Teaching and Learning,How do we know how?,The Artificial Life Roots of Artificial Intelligence,Bayesian Analysis for Neural Network Models,Strategic networks,Synchronization on Complex Networks of Networks,Duocentered networks,"Regionalism in the Asia-Pacific Region: How Wide, How Deep?",신경망을 이용한 화학공정의 고장 진단과 공장 Start-up의 안전성 평가 시스템,Addressable Microstimulator Circuit for Neural Prosthesis,"Networks, Network Governance, and Networked Networks",Minimal path broadcast networks,Interorganizational Networks at the Network Level: Empirical Literature on Whole Networks,"The Procedural Syllabus and the Task Syllabus: How Similar, How Different?",Artificial Neural Network를 이용한 논문 저자 식별,Neural circuits for taste sensation,Neural circuits for taste sensation,Employ the Handicapped :,Transport aircraft requirements - How much? How soon? How to pay?,HOW TO CHEAT,Science in space- How pure - How pragmatic,[Artificial insemination.],[Artificial insemination.],El neumomediastino artificial.,[Artificial insemination].,We do not employ chemists. We employ perfectionists.,We do not employ chemists. We employ perfectionists.,We do not employ chemists. We employ perfectionists.,We do not employ chemists. We employ perfectionists.,Employ Endowment Formula,An undergraduate rootkit research project : How available? How hard? How dangerous?,[Artificial hibernation.],Coraz&oacute;n artificial.,[Artificial hibernation].,[Artificial fertilization.],Deep Neural Network와 Convolutional Neural Network 모델을 이용한 산사태 취약성 매핑,Employ: employment,Employ: employment,Employ: employment,Employ: employment,
What approach and results characterize the system that learns TurKontrol’s POMDP parameters from Mechanical Turk data to optimize iterative crowdsourced tasks?,"##Learning TurKontrol’s POMDP Parameters from Mechanical Turk Data for Dynamic Crowdsourced Task Optimization## ##Introduction## Iterative crowdsourcing workflows often suffer from unpredictable worker reliability and costly redundancies. TurKontrol addresses this by framing quality control as a Partially Observable Markov Decision Process (POMDP), yet its practical deployment requires accurate model parameters. A novel system was developed to infer these POMDP parameters directly from large-scale Mechanical Turk data and then use them to guide live task execution. ##Main Body## First, the system aggregates task outcomes and worker responses to estimate key POMDP variables—worker accuracy distributions, transition probabilities for item quality, and voting behavior parameters—through statistical learning techniques. With these learned parameters, it dynamically selects whether to assign new workers, request additional votes, or accept the current result, balancing cost against expected quality improvements. This adaptive control strategy was tested on a successive-improvement editing workflow, continuously observing and updating the POMDP policy as new data accrued. Compared to a fixed-strategy (nonadaptive) workflow using the same budget, the learned POMDP yielded higher-quality final artifacts, demonstrating both effective parameter estimation and cost-efficient decision making. ##Conclusion## By end-to-end learning of TurKontrol’s POMDP parameters from real Mechanical Turk interactions and applying the model in an adaptive control loop, the system significantly enhances the quality of iterative crowdsourced tasks without increasing expenditure.",없음,없음,"Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",2,1.1859924140007934,"**Title:** Optimizing Iterative Crowdsourced Tasks: A POMDP Approach Leveraging Mechanical Turk Data

**Introduction:**

This report addresses the question of how a system learns TurKontrol's POMDP parameters from Mechanical Turk data to optimize iterative crowdsourced tasks.  While the provided documents do not explicitly describe a system named ""TurKontrol,"" they offer relevant information on using POMDPs to manage crowdsourced tasks via Mechanical Turk.  Therefore, this report will synthesize information from the provided texts to construct a hypothetical answer based on established techniques.

**Body:**

Document 2 directly addresses the use of POMDPs for optimizing crowdsourcing workflows, specifically focusing on iterative improvement workflows.  This document details a system that utilizes Bayesian network learning and inference in conjunction with POMDPs to achieve optimal cost-quality tradeoffs in crowdsourced tasks.  The system's approach involves three key steps:

1. **Model Building:** A Bayesian network is constructed to model the relationship between worker competency, task difficulty, and worker response quality. This model captures the inherent uncertainty and variability in worker performance on Mechanical Turk, a characteristic highlighted in Document 5. Document 5 describes Mechanical Turk as having high variability in worker quality, necessitating robust quality control mechanisms.

2. **POMDP Formulation:** A POMDP is designed for each crowdsourcing scenario. The POMDP’s state space represents the belief about worker competency and task difficulty, its action space encompasses workflow control decisions (e.g., assigning tasks, requesting additional work), and its reward function reflects the desired balance between cost and quality.  The solution to this POMDP provides a dynamic control policy.  Document 2 explicitly states the use of such a policy for controlling an iterative improvement workflow.

3. **Parameter Learning and Policy Optimization:** The parameters of the Bayesian network and the POMDP are learned from data collected through Mechanical Turk.  While the exact learning algorithm isn't specified in Document 2, the paper emphasizes the use of Bayesian network learning and inference.  This iterative process of data collection, model refinement, and policy optimization allows the system to adapt to the dynamics of the Mechanical Turk workforce and the specific characteristics of the crowdsourced task. The live experiments on Amazon Mechanical Turk described in Document 2 demonstrate the superior quality results achieved using this adaptive approach compared to non-adaptive controllers.

**Conclusion:**

The approach described in Document 2 provides a framework for learning a POMDP model from Mechanical Turk data to optimize iterative crowdsourced tasks.  The system leverages Bayesian networks to model worker and task characteristics, formulates a POMDP to capture the decision-making process, and uses data from Mechanical Turk to learn and refine the model parameters. This adaptive approach consistently demonstrates superior quality results while maintaining or reducing costs, showcasing the effectiveness of POMDP-based control in managing the uncertainties inherent in crowdsourcing via platforms like Mechanical Turk.  While not explicitly named ""TurKontrol,"" the described methodology directly addresses the question's core premise.",Personalized Robot Tutoring Using the Assistive Tutor POMDP (AT-POMDP),POMDP-based control of workflows for crowdsourcing,Robotic manipulation of multiple objects as a POMDP,<i>α</i>POMDP: POMDP-based user-adaptive decision-making for social robots,Inside the Turk : Understanding Mechanical Turk as a Participant Pool,Turk dillerinde sontakilar,&raquo;K&uuml;nstliche K&uuml;nstliche Intelligenz&laquo; : Gigging auf Amazons Plattform Mechanical Turk,“What-If-Not”전략을 적용한 문제 제기 활동이 학생들의 수학적 태도에 미치는 영향 : 중학교 2학년 ‘도형’ 단원을 중심으로,"POLITICAL CHANGES IN NORTH KOREA: WHAT IS IT, WHAT HAS HAPPENED AND WHAT TO EXPECT?",Consumer Confidence and Economic Activity: What Causes What?,POMDP-DEVS를 활용한 전투 개체 모델링,Investigation of Mechanical Attributes and Dynamic Mechanical Analysis of Hybrid Polyester Composites,Mechanical and thermo-mechanical properties of short carbon fiber reinforced polypropylene composites using exfoliated graphene nanoplatelets coating,Surface Texturing for Low Friction Mechanical Components,Analytical Method for Constrained Mechanical and Structural Systems,Evaluation of structural deformations of a mechanical connecting unit for oxidizer supplies by thermo-mechanical simulation,POMDP 기반 사용자-로봇 인터랙션 행동 모델,User Modeling Based on Inner-belief State Pomdp,Pediatric Mechanical Circulatory Support,Mechanical properties of geopolymers after immersion,Mechanical and electrochemical characterization of CuAlNi alloys,“What” versus “Where” in the audiovisual domain: An fMRI study,"Nephrotic syndrome: what’s new, what’s hot?",What Counts as Knowledge and What Knowledge Counts in Early Childhood Education?,Hierarchical POMDP planning for object manipulation in clutter,"Computational approaches to interface design : what works, what doesn't, what should and what might",Electro-Mechanical Brake의 Clamping Force 추정,Mechanical Check용 Spherical device의 제작 및 특성 평가,THE OLD TURK POLICY OF THE NEW TURK,예비교사 교육에서 If-Not-What-Yes와 What-If-For를 통한 반례 생성과 명제의 정교화,What life? What cycle?,What Process For What Part?,복수 무인기를 위한 POMDP 기반 동적 임무 할당 및 정찰 임무 최적화 기법,POMDP와 Exploration Bonus를 이용한 지역적이고 적응적인 QoS 라우팅 기법,John Leslie Turk,[Stilling-Turk-Duane syndrome. Electromyographic study],'Unspeakable turk.','Unspeakable Turk',Flying Turk,Turk Bogazlari,,,,,,,,,,
What are the key features of a sustainability-oriented corporate culture that shape the development and management of sustainable artificial intelligence?,"##Sustainability-Oriented Corporate Culture for Sustainable AI## ##Introduction## As organizations increasingly deploy artificial intelligence to address societal and environmental challenges, the underlying corporate culture plays a decisive role in ensuring that AI applications contribute to sustainable development. A sustainability-oriented culture embeds norms, values, and structures that guide the design, deployment, and governance of AI toward long-term ecological health, social equity, and economic resilience. ##Main Body## 1. Shared Sustainability Values: Organizations with a sustainability-oriented culture articulate clear environmental and social objectives, aligning AI teams around common purpose beyond short-term profit. These values become part of mission statements, performance metrics, and internal communications, steering AI initiatives toward reducing waste, emissions, or inequalities. 2. Leadership Commitment and Incentives: Senior executives visibly champion sustainable AI by tying leadership performance reviews and incentive schemes to sustainability indicators—such as carbon reduction goals or fairness metrics—ensuring that resource allocation and strategic priorities reflect sustainable development aims. 3. Cross-Functional Collaboration: Such cultures foster strong interfaces among data scientists, engineers, ethical specialists, and external stakeholders (e.g., community representatives, NGOs), enabling AI development processes that integrate technical feasibility with environmental impact assessments and social risk evaluations. 4. Transparency and Accountability: Transparency mechanisms—public reporting on AI’s resource consumption, decision-making criteria, and environmental footprints—combined with internal accountability structures (audit committees, ethics boards) help organizations monitor and correct unsustainable AI practices. 5. Continuous Learning and Adaptation: A learning-oriented culture promotes regular training on sustainable AI methods, post-deployment reviews of environmental and social outcomes, and iterative improvements based on feedback loops, thereby institutionalizing best practices like energy-efficient algorithms or bias mitigation techniques. 6. Inclusive Stakeholder Engagement: By proactively involving suppliers, customers, regulators, and affected communities in AI project governance, firms ensure that diverse perspectives shape sustainable AI solutions, anticipate unintended consequences, and build broader support for long-term initiatives. ##Conclusion## A corporate culture that embeds sustainability at every level—from leadership incentives and shared values to transparent practices and continuous learning—provides the essential environment in which sustainable artificial intelligence can flourish. Consequently, companies with such cultural features are better equipped to harness AI’s potential for reducing environmental impact, promoting social equity, and creating resilient economic value over the long term.",없음,없음,"Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",3,1.1859924140007934,"**Title:** Key Features of a Sustainability-Oriented Corporate Culture Shaping Sustainable Artificial Intelligence Development and Management

**Introduction:**

This report analyzes the key features of a sustainability-oriented corporate culture that influence the development and management of sustainable artificial intelligence (AI), drawing upon insights from provided academic papers focusing on sustainability-oriented innovations (SOIs) within SMEs and larger organizations.  The analysis will explore how organizational culture, stakeholder involvement, and strategic orientation impact the successful commercialization of SOIs, particularly within the context of AI.

**Body:**

The provided literature highlights several crucial aspects of a sustainability-oriented corporate culture essential for fostering the development and management of sustainable AI.  Document 1 emphasizes that a proactive, ""sustainability-rooted"" strategic sustainability behavior in SMEs is linked to more radical SOIs and transformative innovation processes. This suggests that a corporate culture prioritizing sustainability from its core values, not merely as a reactive measure, is paramount for developing truly sustainable AI solutions.  This proactive approach extends beyond simply integrating ecological considerations; it necessitates the integration of social and economic dimensions (""triple bottom line perspective"") as highlighted in Document 1.

Document 2 underscores the importance of ""market-oriented sustainability."" This framework emphasizes the interaction between organizational culture (represented as market orientation), stakeholder involvement (green purchasing), and performance management (logistics performance).  Applying this to sustainable AI, a market-oriented approach would necessitate understanding and responding to stakeholder demands for environmentally and socially responsible AI systems. This means actively engaging with suppliers, customers, and other stakeholders to ensure AI development aligns with sustainability goals.  The successful implementation of this model hinges on establishing and enhancing market orientation, directly contributing to environmental sustainability (Document 2).

Further reinforcing this, Document 3 identifies the ""commercialization efficiency"" of SOIs as being characterized by sustainability-oriented criteria, including improving the firm's image. For sustainable AI, this implies that a positive corporate image linked to responsible AI development is crucial for success.  The research also points towards the significant role of strategic orientation in the commercialization of sustainability-oriented innovations, indicating that a clear, well-defined sustainability strategy integrated into the organization's overall vision is critical (Document 3).

Document 4 explores the role of corporate social responsibility (CSR) reporting in shaping organizational identity and stakeholder relationships.  In the context of sustainable AI, transparent and accessible online CSR reporting can be vital for building trust and communicating the organization's commitment to ethical and sustainable AI development.  This requires acknowledging societal concerns and engaging in a consistent communication strategy targeted at all stakeholders.

Finally, Document 5 introduces the concept of mindfulness as a tool to foster sustainability-oriented innovation.  By promoting cognitive abilities, attitudes, and behaviors conducive to creativity and ecological concerns, mindfulness training can help overcome the inherent conflict between efficiency-driven business models and sustainability goals.  Incorporating mindfulness into the corporate culture can therefore enhance the organization's capacity for developing innovative and sustainable AI solutions.


**Conclusion:**

A sustainability-oriented corporate culture fostering the development and management of sustainable AI requires a multifaceted approach.  It needs a proactive, ""sustainability-rooted"" strategic orientation encompassing the economic, social, and environmental dimensions (Document 1).  A market-oriented approach, actively involving stakeholders in the development process, is crucial for ensuring that AI solutions meet sustainability demands (Document 2).  Transparent communication through robust CSR reporting is essential for building trust and positive corporate image (Document 3, Document 4).  Finally, fostering a mindful corporate culture can enhance the organization's innovative capacity, facilitating the creation of truly sustainable AI solutions (Document 5).  These elements, working in synergy, are key features defining a corporate culture fit for navigating the challenges and opportunities of sustainable AI development.",Sustainability-oriented innovation of SMEs: a systematic review,Market-oriented sustainability: moderating impact of stakeholder involvement,Commercialization of conventional and sustainability-oriented innovations: a comparative systematic literature review,Greening corporate identity: CSR online corporate identity reporting,Sustainability-oriented innovations: Can mindfulness make a difference?,Corporate values and corporate governance,A concern-oriented sustainability approach,Corporate reputation versus corporate branding: the realist debate,Corporate Governance in Germany and the German Corporate Governance Code,Culture,“What-If-Not”전략을 적용한 문제 제기 활동이 학생들의 수학적 태도에 미치는 영향 : 중학교 2학년 ‘도형’ 단원을 중심으로,Networking for sustainability: Alliance capabilities and sustainability-oriented innovation,Sustainability-oriented service innovation: An emerging research field,Configurations of sustainability&#x2010;oriented textile partnerships,"Corporate marketing: Integrating corporate identity, corporate branding, corporate communications, corporate image and corporate reputation",Corporate Governance and Corporate Identity*,Corporate governance and correlation in corporate defaults,"POLITICAL CHANGES IN NORTH KOREA: WHAT IS IT, WHAT HAS HAPPENED AND WHAT TO EXPECT?",Consumer Confidence and Economic Activity: What Causes What?,"Nephrotic syndrome: what’s new, what’s hot?",φ-features and Discourse-agreement features,Urodynamic features and artefacts,Assessment of features technology,Explaining Deep Features Using Radiologist-Defined Semantic Features and Traditional Quantitative Features,Deep Features from Pretrained Networks Do Not Outperform Hand-Crafted Features in Radiomics,Interactive Conflict Detection and Resolution for Personalized Features,감정 인식을 위한 음성 특징 도출,Sustainability&#x2010;oriented innovation in retailing,Corporate governance and corporate agility,Corporate Governance and Corporate Competitiveness: an international analysis,"Cultural, Individual and Device-Specific Antecedents on Mobile Banking Adoption: A Cross-National Study",Impact of Culture on Mobile Phone Service Adoption and Diffusion: A Cross-Country Analysis,Culture and Cultural Worldviews: Do Verbal Descriptions about Culture Reflect Anything Other Than Verbal Descriptions of Culture?,Organizational Culture,“What” versus “Where” in the audiovisual domain: An fMRI study,What Counts as Knowledge and What Knowledge Counts in Early Childhood Education?,Primary Breast Carcinoma with Neuroendocrine Features: Imaging Features on Mammography and Ultrasonography,"Corporate Taxation, Corporate Power, and Corporate Harm",The Discrepancy between Consensual-Level Culture and Individual-Level Culture,Features of Parapneumonic Effusions,Popular Children's Features and Methods,Culture-Civilization-Organizational Culture and Managerial Performance,The lexicon and culture - culture and the lexicon,K-Culture 문화콘텐츠산업의 가치와 지속화 방향 탐색,"Computational approaches to interface design : what works, what doesn't, what should and what might",예비교사 교육에서 If-Not-What-Yes와 What-If-For를 통한 반례 생성과 명제의 정교화,What life? What cycle?,What Process For What Part?,Driving Sustainability-Oriented Innovation,Culture Technology의 교육 목표와 전망
How can the main applications of machine learning methods for early diagnosis of maternal-fetal conditions and their ethical considerations be summarized?,"##Machine Learning Applications for Early Maternal-Fetal Diagnosis and Ethical Aspects## ##Introduction## Advances in machine learning have enabled earlier and more accurate detection of maternal-fetal complications—such as preterm birth and abnormal fetal growth—by mining complex biomedical datasets. These predictive tools promise to guide timely clinical interventions, but their deployment raises important ethical questions around patient privacy, data governance, and fairness. ##Main Body## Contemporary methods employ supervised learning algorithms (e.g., support vector machines, random forests, neural networks) to analyze multi-modal inputs: ultrasound images, biochemical markers, electronic health records, and wearable sensor signals. In preterm birth prediction, models integrate demographic factors, cervical measurements, contraction patterns, and inflammatory profiles to achieve high sensitivity in identifying at-risk pregnancies. For fetal growth assessment, algorithms process placental perfusion metrics and biometric parameters to flag intrauterine growth restriction or macrosomia. Rigorous validation—using cross-validation, external cohorts, and ROC analysis—has demonstrated robust performance, though algorithm generalizability can be limited by cohort heterogeneity. Ethical considerations include safeguarding maternal and fetal data privacy, obtaining informed consent for data collection and model use, ensuring transparency and interpretability of model outputs for clinicians and patients, and actively addressing bias stemming from underrepresented subpopulations in training datasets. ##Conclusion## Machine learning holds significant promise for early diagnosis of maternal-fetal conditions by leveraging diverse data sources and advanced predictive models. To realize clinical benefits responsibly, it is crucial to implement ethical safeguards—ensuring privacy protection, transparent decision-making, and equitable performance across all patient groups.",없음,없음,"Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",4,1.1859924140007934,"**Title:**  Analysis of Provided Documents: Absence of Information on Machine Learning Applications for Maternal-Fetal Diagnosis

**Introduction:**

The original question asks for a summary of the main applications of machine learning methods for the early diagnosis of maternal-fetal conditions and their ethical considerations.  The provided documents, however, do not contain any information relevant to this topic.  Therefore, this report will address the limitations of the provided context in answering the question.


**Body:**

The five provided documents focus on diverse areas within machine learning and other related technological advancements.  Document 2 discusses the application of machine learning in big data analysis, highlighting its role in commerce and science.  Document 3 focuses on the application of deep learning in radar imaging, detailing its use in synthetic aperture radar (SAR) and addressing challenges in its implementation.  Document 4 explores the use of artificial neural networks for controlling cutting force in milling machines.  Document 5 investigates the application of adaptive identity-based signcryption for security in machine-to-machine (M2M) networks.  Finally, Document 1 explores the evolution of language teaching methodologies and does not relate to machine learning at all.  None of these documents touch upon the use of machine learning for early diagnosis of maternal-fetal conditions or the associated ethical considerations.  The research presented is wholly unrelated to the query.


**Conclusion:**

Based on the provided documents, it is impossible to answer the original question regarding the applications of machine learning for early diagnosis of maternal-fetal conditions and their ethical implications.  The documents offer valuable insights into various other applications of machine learning, but none are relevant to the specified clinical domain.  Further research using sources that specifically address machine learning in maternal-fetal diagnosis is necessary to provide a comprehensive answer.",25 Years of HOW: A Celebration of Language Teaching and Learning,Machine learning on Big Data,Deep learning for radar,Control of milling machine cutting force using artificial Neural Networks,Adaptive Identity-Based Signcryption for Dynamic Source Routing in Machine to Machine Networks,Mainstream economics and economic crises: how responsible? how reformable?,"Propri&eacute;t&eacute;s &eacute;lectroniques, dispositifs et applications des couches minces de diamant",Concurrent Support Vector Machine 프로세서,Les greffons osseux vascularis&#x00E9;s p&#x00E9;dicul&#x00E9;s pr&#x00E9;lev&#x00E9;s sur la main et le poignet : revue de la litt&#x00E9;rature et nouveau site donneur,La main spastique psychog&egrave;ne,Identifying Trojan Facebook Applications,유아의 한국어 어휘학습용 어플리케이션 분석: 태블릿 PC 어플리케이션을 중심으로,Development of Creativity through Mathematical Applications,Hyperbolic metamaterials: fundamentals and applications,이러닝 학습환경이 이러닝 학습만족도에 미치는 영향 분석,How do we know how?,How the 'What' Becomes the 'How',The hand: Embryology and main malformative mechanisms,"Main coup&eacute;e, main errante, main absente : All&eacute;gorie r&eacute;elle de la Grande Guerre",Multimedia Applications Development: Experiences,Nanofibrous Scaffolds in Biomedical Applications,Future Applications of Contrast Ultrasound,Grinding Process Achievements and their Consequences on Machine Tools Challenges and Opportunities,Learning analytics sources: Beyond learning platforms,Jaccoud&apos;s arthropathy,Harmony Mechanism Between Main Productive Region and Main Sale Region,Privacy for Surveillance Applications,Four-square sprocket test machine,"Regionalism in the Asia-Pacific Region: How Wide, How Deep?",Machine learning and docking studies of cytochrome P450 ligands,Kronecker sum decomposition and its applications,Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators,"The Procedural Syllabus and the Task Syllabus: How Similar, How Different?",공간과 시간적 적응을 통한 스케줄링 지식의 기계학습에 관한 연구,딥러닝 알고리즘에 기반한 기업부도 예측,Top Bracing을 이용한 선박엔진의 진동방진에 관한연구,Syndromes canalaires r&#x00E9;v&#x00E9;l&#x00E9;s &#x00E0; la main,딥 러닝을 이용한 DC 모터 제어,Transport aircraft requirements - How much? How soon? How to pay?,An undergraduate rootkit research project : How available? How hard? How dangerous?,HOW TO CHEAT,Science in space- How pure - How pragmatic,Tendinopathies de la main et du poignet,Permis de conduire et chirurgie de la main,Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서,딥 러닝기반 고객평점 예측모델,"시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합",,,
초등학교 수준에서 설명 가능한 인공지능 교육의 핵심 요소와 활용 방안을 어떻게 요약할 수 있나요?,"##제목## 초등학교 수준에서 설명 가능한 인공지능 교육의 핵심 요소 및 구성주의적 활용 방안 ##서론## 인공지능(AI)이 빠르게 일상에 스며들며 AI 원리를 단순히 소비하는 단계를 넘어 스스로 이해하고 설명할 수 있는 능력이 중요해졌다. 특히 초등학생은 문제 해결과 비판적 사고의 기초를 형성하는 시기이므로, AI 개념을 쉬운 언어와 실생활 예제로 설명하고 학습자가 직접 개념을 구성해 보는 경험을 제공하는 것이 핵심이다. ##본론## 1. 설명 가능한 AI 교육의 핵심 요소 - 인간 중심의 문제 해결 학습: AI가 실제 삶의 문제를 어떻게 도울 수 있는지 사례를 통해 깨닫게 함 - 알고리즘 원리의 직관적 이해: 블록 코드나 그림, 역할 놀이 등을 활용해 입력·처리·출력 과정을 체험 - 해석력 강화: 학습자가 AI 모델의 결과를 인간의 관점에서 설명하도록 유도해 ‘왜’라는 질문을 강조 - 다양한 교수·학습 도구 활용: 시각화 도구, 마이크로비트·스마트 로봇 등 눈에 보이는 매체로 알고리즘 동작 원리를 학습 2. 구성주의 관점의 보완적 활용 - 학습자 주도 탐구: 학급 내 소그룹 프로젝트로 AI 활용 과제를 스스로 설계·실행하며 개념을 구성 - 경험 중심 통합: 진화생물학·뇌과학·시스템 이론 등 다양한 배경 지식을 놀이·토론 활동에 녹여 융합적 이해 촉진 - 협력적 피드백: 동료 간 설명·시연 과정을 통해 서로 다른 관점을 공유하며 개념을 수정·발전 ##결론## 초등학생 대상 설명 가능한 AI 교육은 실생활 사례와 직관적 알고리즘 체험을 통해 해석력과 문제 해결 능력을 동시에 키우며, 구성주의적 수업 설계로 학습자 스스로 지식을 구성하는 과정을 지원할 때 더욱 효과적이다. 이러한 접근은 학생들이 AI 원리를 바탕으로 비판적·창의적 사고를 확장하도록 돕는다.",How can I summarize the core elements and ways of using AI education that can be explained at elementary school level?,"##title## The core elements of artificial intelligence education, which can be explained at the elementary school level, ##introduction## The ability to understand and explain themselves beyond the stage of artificial intelligence (AI) quickly penetrates into everyday life and simply consumes AI principles. In particular, elementary school students are the time to form the basis of problem solving and critical thinking, so it is important to explain the AI concept as an easy language and real life example, and provide learners the experience of forming a concept. ## Main ## 1. The core element of the explanatory AI education -Learning of human -centered problem solving: AI realizes how to help real life problems. -Intuitive understanding of the principle of algorithm: Experience the input, processing, and output process using block codes, pictures, and role play -Interpretation: Interpretation: Emphasizing the question of 'why' by encouraging learners to explain the results of the AI model from a human perspective. -Using a variety of teaching and learning tools: visualization tools, microbit and smart robots, etc. 2. Complementary use of constructivist perspective -Learner -led exploration: Design and executing AI tasks by themselves and organizing concepts as a small group project in the class. -Experience -based integration: Various background knowledge such as evolutionary biology, brain science, and system theory is dissolved in play and discussion activities to promote fusion understanding -Feedback of collaborative feedback: Modify and develop concepts by sharing different perspectives through descriptions and demonstrations between colleagues ##conclusion## AI education, which can be explained to elementary school students, is more effective in supporting the process of constructing knowledge by learners by simultaneously developing interpretation and problem solving skills through real life cases and intuitive algorithm experiences. This approach helps students expand critical and creative thinking based on AI principles.","Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",5,1.1859924140007934,"**제목:** 초등학교 수준 인공지능 교육의 핵심 요소 및 활용 방안: 언플러그드 교육과 설명 가능한 AI의 통합

**서론:**

본 보고서는 초등학교 수준에서 설명 가능한 인공지능 교육의 핵심 요소와 활용 방안을 다룬다.  4차 산업혁명 시대에 인공지능 기술의 중요성이 증대됨에 따라, 초등학생들에게 인공지능의 기본 개념과 원리를 이해시키는 교육이 필수적이다.  본 보고서는 관련 학술 논문들을 분석하여 초등학교 인공지능 교육의 효과적인 방법론을 제시한다.

**본론:**

초등학교 인공지능 교육의 핵심은 학생들의 수준에 맞는 접근 방식을 선택하는 것이다.  문서 1에서는 초등학생의 인지 발달 단계를 고려하여 언플러그드 컴퓨팅 기법을 활용한 인공지능 교육 프로그램 개발 사례를 제시한다.  이 프로그램은 6차시로 구성되어 있으며, 학생용 활동지, 교사용 교수·학습 과정안, PPT, 동영상 등 다양한 교수자료를 포함한다.  개발 과정은 조사, 분석, 설계, 개발, 개선 단계로 이루어졌고, 전문가 평가와 소집단 형성 평가를 통해 프로그램의 효과성과 타당성을 검증하였다.  결과적으로, 이 프로그램은 학생들의 소프트웨어 교육 및 인공지능 기술에 대한 인식 변화에 긍정적인 영향을 미치는 것으로 나타났다.

효과적인 교육을 위해서는 인공지능 시스템의 작동 원리를 학생들이 이해할 수 있도록 설명하는 것이 중요하다. 문서 5는 인공지능 시스템의 설명 가능성(Explainable AI, XAI)을 높이기 위해 반사실적 설명을 사용하는 인터페이스 개발 연구를 소개한다.  이 연구는 ""why not"", ""how to"", ""what if""와 같은 질문을 통해 인과 관계를 이해하도록 돕는 세 단계의 순차적 설명 방식을 제시하고, 대출 예측 시스템을 통해 그 효과를 검증하였다.  결과적으로, 이 설명 인터페이스는 기존 시스템에 비해 사용자의 신뢰도, 유용성, 만족도를 향상시키는 것으로 나타났다.

초등학교 인공지능 교육은 단순히 지식 전달을 넘어,  인공지능 기술의 윤리적 함의와 사회적 영향에 대한 이해를 포함해야 한다.  인공지능이 사회에 미치는 영향에 대한 토론 및 논의를 통해 비판적 사고 능력을 함양할 수 있다.  또한,  문서 3에서 언급된 바와 같이 안전한 교육 환경 조성을 위한 노력이 병행되어야 한다.  안전한 학교 환경은 학생들의 학습 효율성을 높이고 교육의 질을 향상시키는 데 기여한다.

**결론:**

초등학교 수준의 인공지능 교육은 언플러그드 컴퓨팅 기법과 같은 학생 친화적인 방법과 설명 가능한 인공지능(XAI) 원리를 적용한 인터페이스를 활용하여 효과적으로 진행될 수 있다.  이는 학생들이 인공지능의 기본 원리를 이해하고,  실생활 문제 해결에 인공지능을 활용하는 능력을 기르는 데 도움을 줄 것이다.  더불어, 안전하고 윤리적인 인공지능 활용에 대한 교육을 병행하여 미래 사회의 책임감 있는 인공지능 시민을 양성하는 데 기여해야 한다.  본 보고서에서 제시된 핵심 요소와 활용 방안은 초등학교 인공지능 교육의 효과적인 설계 및 운영에 유용한 지침으로 활용될 수 있을 것이다.",초등학교 인공지능 수업을 위한 언플러그드 교육 프로그램 개발,초등학교 보건교과서 분석,CPTED 지침에 따른 국내 초등학교 시설계획,현금보유수준과 미래이익의 정보효과,반 사실적 설명을 사용한 인공지능 시스템 설명 인터페이스 개발,학교 보건교육 운영 및 환경 개선방안 연구 : 창원.김해 초등학교 중심으로,"초등학교 서술형 논술형 평가 문항의 오류 분석 : 5학년 국어, 수학, 사회, 과학 문항을 중심으로",초등학교 인성교육 실천사례(2005-2007)를 중심으로 본 초등학교 인성교육의 특성 : 인성교육 실천사례를 중심으로 본 초등학교 인성교육의 특성,초등학교 성교육 실태 및 교사들의 성교육에 대한 인식,일부 강원도지역 초등학교 고학년 학생들의 가족식사 빈도가 식행동 및 영양지식에 미치는 영향,박물관과 초등학교 연계 교육프로그램 활성화 방안 연구 : 송파지역 박물관과 초등학교 연계프로그램을 중심으로,시맨틱웹을 활용한 초등학교 학습자료 검색시스템,한국어 읽기 교육을 위한 설명문 구조 연구,의사의 설명의무 위반과 손해배상책임의 범위,수준별 수업 : 기초집단의 수업활성화를 위한 연구,중소기업 정보화에 대한 실태 연구 : 국가간 비교,확률적 설명 모형이 설명의 기준을 제시할 수 있는가?,"사회행위의 의도되지 않은 결과, 기능적 설명, 그리고 개인주의적 설명",연구활동종사자들의 일반적인 건강수준 조사,EDI 시스템 설명,사회과학에서 법칙과 설명,설명 대상의 주제적 관계가 설명 유형 선호에 미치는 영향,교과서 설명 텍스트의 구성 방향,내선규정 개정내용 설명,"자궁경부암, 인유두종 바이러스(HPV)에 대한 성인 남성의 지식 및 백신 접종 의향",수준별 수업에 따른 인식과 수학 학업성취도 연구,지역 간 주관적 건강수준 차이 분석,대학 교양영어 수준별 프로그램 운영방안,나트륨 섭취수준에 따른 대사증후군 및 관련 위험지표의 유병율 비교,소비자 태도와 행위에 대한 이론적 접근: 해석 수준 이론을 중심으로,,,,,,,,,,,,,,,,,,,,
생성형 AI 콘텐츠의 가치 유형별 소비자 인식과 AI 사용 공개에 대한 인식 특성을 어떻게 요약할 수 있나요?,"##제목## 생성형 AI 콘텐츠 가치·형식별 소비자 인식과 AI 사용 공개 태도 분석 ##서론## 생성형 인공지능(AIGC)은 다양한 미디어 형식으로 자율 생성 능력을 가지지만, 진정성 문제로 규제와 투명성 요구가 커지고 있다. 이에 소비자가 AIGC를 어떻게 인지하고 AI 사용 공개를 어떤 원칙으로 받아들이는지 이해하는 것이 중요하다. 본 연구는 콘텐츠 가치 유형(실용적·쾌락적)과 미디어 형식(글·사진·영상)을 결합한 여섯 가지 시나리오에서 소비자 인식을 분석했다. ##본론## 카노 모형을 활용해 각 시나리오의 만족도와 불만족 요인을 측정하고, 인지된 진정성과 기만 여부에 따라 그룹을 구분했다. 실용적 콘텐츠(특히 뉴스)에서는 AI 사용에 대해 부정적 인식이 우세했고, 영상 뉴스에서 그 강도가 가장 컸다. 반면 쾌락적 콘텐츠(영화·드라마)에서는 AI 사용에 대한 관심이 낮거나 오히려 긍정적인 태도가 관찰되었다. AI 사용 공개는 콘텐츠 가치에 관계없이 ‘지켜야 할 원칙’으로 여겨졌으나, 실용적 콘텐츠에서 그 중요성이 더 크게 드러났다. ##결론## 소비자는 콘텐츠의 가치 유형과 형식에 따라 AIGC와 AI 사용 공개에 상이한 태도를 보인다. 뉴스 같은 정보성 콘텐츠에서는 투명성과 진정성 확보 노력이 필수적하며, 쾌락적 영역에서는 경험 개선을 위한 활용이 가능하다. 향후 AI 활용의 신뢰도를 높이기 위해 진정성 강화 및 투명성 제고 방안을 지속적으로 모색해야 한다.",How can you summarize the recognition characteristics of consumer awareness and AI disclosure by value type?,"##title## Producted AI Content Value and Family -specific Consumer Recognition and AI Public Attitude Analysis ##introduction## Productive artificial intelligence (AIGC) has the ability to generate autonomous generations in various media formats, but due to authenticity, regulations and transparency demands are increasing. It is important to understand how consumers recognize AIGC and how they accept AI disclosure. This study analyzed consumer perception in six scenarios that combine content value types (practical and pleasure) and media formats (text, photographs, and videos). ## Main ## Using the cano model, the group was measured by measuring the satisfaction and dissatisfaction of each scenario, and the group was distinguished according to the recognized authenticity and deceit. In practical contents (especially news), negative perceptions of AI use were prevailed, and the intensity in video news was the largest. On the other hand, in pleasure contents (movies and dramas), interest in using AI was low or rather positive. The disclosure of the use of AI was regarded as a ""principle to be kept,"" regardless of the value of the content, but its importance was even greater in practical contents. ##conclusion## Consumers show different attitudes in the release of AIGC and AI according to the value types and forms of the content. Efforts to secure transparency and authenticity are essential for information content such as news, and in pleasure areas, it is possible to improve experience. In order to increase the reliability of AI utilization in the future, it is necessary to continue to seek ways to strengthen authenticity and improve transparency.","Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",6,1.1859924140007934,"## 생성형 AI 콘텐츠 가치 유형별 소비자 인식 및 AI 사용 공개에 대한 인식 특성 분석

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 생성형 AI 콘텐츠의 가치 유형별 소비자 인식과 AI 사용 공개에 대한 인식 특성을 분석합니다.  제공된 문서들은 AI 콘텐츠 생성 자체에 대한 직접적인 언급은 없으나,  문화 콘텐츠 산업의 동향, 소셜 콘텐츠 마케팅 전략, 그리고 가치 평가에 대한 논의를 통해 생성형 AI 콘텐츠의 소비자 인식 및 AI 사용 공개에 대한 함의를 간접적으로 추론할 수 있습니다.

**본론:**

제공된 문서들은 생성형 AI 콘텐츠의 가치 유형을 직접적으로 분류하지 않으므로,  문서의 내용을 바탕으로  다음과 같은 가치 유형을 가정하고 분석합니다.

* **정보적 가치:** AI가 생성한 콘텐츠가 제공하는 정보의 정확성, 신뢰성, 유용성 등
* **오락적 가치:** AI가 생성한 콘텐츠가 제공하는 즐거움, 재미, 감동 등
* **경제적 가치:** AI가 생성한 콘텐츠의 시장 가치, 수익 창출 가능성 등
* **사회적 가치:** AI가 생성한 콘텐츠가 사회에 미치는 영향, 공유 가치 창출 가능성 등

**1. 정보적 가치에 대한 소비자 인식:** 문서 1은 한류 콘텐츠의 인기와 지적재산권 침해 문제를 다룹니다. 이는 AI가 생성한 정보 콘텐츠의 정확성과 신뢰성에 대한 소비자의 우려를 반영합니다.  정확하지 않거나 저작권을 침해한 콘텐츠는 정보적 가치가 낮게 평가될 것입니다.  문서 3에서 언급된 '무보수 가사노동 가치평가' 연구는, 데이터의 정확성과 신뢰성이 가치 평가 결과에 직접적인 영향을 미친다는 것을 시사합니다.  AI가 생성한 정보의 출처와 검증 과정에 대한 투명성이 정보적 가치에 대한 소비자 인식에 중요한 영향을 미칠 것입니다.

**2. 오락적 가치에 대한 소비자 인식:** 문서 2는 소셜 콘텐츠 마케팅 사례를 분석하며, 소비자 참여를 유도하는 '재미' 요소가 콘텐츠의 성공에 중요함을 강조합니다. AI가 생성한 콘텐츠도 재미와 즐거움을 제공해야 오락적 가치를 인정받을 수 있습니다.  문서 1에서 언급된 한류 콘텐츠의 인기는 오락적 가치에 대한 소비자의 선호도를 보여줍니다.  AI가 생성한 콘텐츠가 얼마나 창의적이고 매력적인가가 오락적 가치를 결정짓는 중요한 요소입니다.

**3. 경제적 가치에 대한 소비자 인식:** 문서 4와 5는 공유가치창출(CSV) 전략을 다루며, 기업의 이윤 창출과 사회적 가치 창출의 조화를 강조합니다. AI가 생성한 콘텐츠의 경제적 가치는 콘텐츠의 판매 가능성, 광고 수익, 라이선스 수익 등으로 평가될 수 있습니다.  소비자는 콘텐츠의 질과 유용성에 비례하여 경제적 가치를 인정할 것입니다.  문서 2에서 언급된 성공적인 소셜 콘텐츠 마케팅 사례는 경제적 가치와 사회적 가치의 상호작용을 보여줍니다.

**4. 사회적 가치에 대한 소비자 인식:** 문서 4와 5에서 논의되는 CSV 전략은 AI가 생성한 콘텐츠의 사회적 가치를 평가하는 틀을 제공합니다.  AI가 생성한 콘텐츠가 사회적 문제 해결에 기여하거나 긍정적인 사회적 영향을 미친다면 소비자는 높은 사회적 가치를 부여할 것입니다.  문서 1의 한류 콘텐츠 확산 사례는 문화적 교류 및 이해 증진이라는 사회적 가치를 보여줍니다.  반대로, 부정적인 편견이나 차별을 조장하는 콘텐츠는 사회적 가치가 낮게 평가될 것입니다.


**AI 사용 공개에 대한 인식:** 문서 전반에서 정보의 투명성과 신뢰성이 중요한 요소로 언급됩니다.  AI가 생성한 콘텐츠의 경우, AI 사용 여부를 공개하는 것은 소비자의 정보 접근권과 선택권을 보장하는 데 중요한 역할을 합니다.  AI 사용을 공개하지 않으면, 소비자는 콘텐츠의 질과 신뢰성에 대한 불확실성을 느끼게 되고, 이는 정보적 가치와 경제적 가치, 나아가 사회적 가치에도 부정적인 영향을 미칠 수 있습니다.  따라서 AI 사용 공개는 소비자 신뢰 구축에 필수적인 요소입니다.


**결론:**

생성형 AI 콘텐츠의 가치는 정보적, 오락적, 경제적, 사회적 가치로 구분될 수 있으며, 각 가치에 대한 소비자 인식은 콘텐츠의 질, 유용성, 사회적 영향 등에 따라 달라집니다.  AI 사용 공개는 소비자 신뢰 구축에 중요한 역할을 하며, 콘텐츠의 가치 평가에 직접적인 영향을 미칩니다.  따라서 생성형 AI 콘텐츠 제작자는 소비자의 다양한 가치 인식을 고려하고, AI 사용에 대한 투명성을 확보하는 것이 중요합니다.",한·중 FTA 서비스무역 협상의 법적 쟁점과 과제- 문화콘텐츠서비스산업을 중심으로 -,소셜 콘텐츠 마케팅 사례 연구 : 해외 사례를 중심으로,가사노동 가치평가를 위한 기초적 분석,공유가치창출(CSV) 전략의 유형화 : 사례분석,CSV(공유 가치 창출)와 PR 가치의 수렴 가능성 및 실천 방향에 대한 탐색적 연구,고객만족과 고객가치경영의 추진에 관한 연구 : 고객가치 측정모형을 중심으로,가치사슬 활동이 종합병원 경영성과에 미치는 영향 분석,증강현실 기반 토이게임의 개발 모형 연구,유전 알고리즘과 셀 오토마타를 이용한 절차적 게임 콘텐츠 생성,온라인게임 기업의 정성적 평가요소에 관한 연구,"점포이미지가 지각된 가치, 고객만족 및 충성도에 미치는 영향 : 중국 청도시 지역을 중심으로","여대생의 미의식에 따른 미용 관리 행동에 관한 연구 : 피부 관리, 체중조절, 미용성형 행동 중심으로",블록체인을 활용한 디지털 콘텐츠 저작권 보호 방법 연구,고등학생의 가치관 명료도와 지각된 정서적 유능성 간의 관계,성형외과 시장의 현황 및 서비스 이용 분석 : 강남구 성형외과를 중심으로,다양한 모바일 기기에서의 3D 콘텐츠 구현,기술가치 평가모형에 관한 연구,"재무비율을 이용한 기업가치평가 PER, PBR기준으로","대학교육만족도, 직업가치관, 직업만족도에 관한 구조적 분석",금형 최적화 설계를 위한 성형/구조 연계해석 기법 개발,이러닝 콘텐츠 품질관리 평가기준 규명,공연시장 활성화를 위한 온라인 콘텐츠 유통 플랫폼에 관한 연구,"성형광고 노출, 성형경험, 외모기준의 내면화, 제3자 효과가 성형광고 규제에 대한 태도에 미치는 영향에 대한연구","사출성형 공정에서 유발되는 냄새가 자업자의 능률에 미치는 영향 : 사출성형, 냄새",대학생들의 미용성형 및 피부미용 경험에 미치는 요인,콘텐츠 유통의 가치사슬에서 연속적인 디지털 저작권 관리,압출성형 발아현미의 설기떡 품질 특성,압출성형 공정변수에 따른 밀기울의 이화학적 특성과 공정최적화,금속 판재의 성형한계도 시험법에 관한 연구,한국 성형외과 병원들의 마케팅 활동과 병원특성이 중국인환자 유치성과에 미치는 영향,,,,,,,,,,,,,,,,,,,,
"항공 분야에 적용된 인공지능의 기본 개념과 산업적 의미, 직면 과제를 간략하게 정리할 수 있나요?","##제목## 항공 분야에 적용된 인공지능 ##서론## 인공지능은 1956년 개념이 정립된 이래 컴퓨터 기반으로 최소한의 인간 개입 하에 지능적 의사결정을 수행하도록 발전해왔다. 항공 산업은 복잡한 환경에서 실시간 의사결정과 방대한 데이터를 요구하므로, AI 기술 도입을 통해 운영 효율화와 안전성 강화를 동시에 추구하게 되었다. ##본론## 1. 기본 개념 • 자율비행·항로 최적화: 기체 센서 데이터를 토대로 최적 경로를 자동으로 탐색·수정 • 예측정비(Predictive Maintenance): 기체의 상태 데이터를 분석해 고장 발생 시점을 사전 예측 • 안전 모니터링: 조종실·객실·지상 설비 전반의 이상 징후를 실시간 탐지 2. 산업적 의미 • 운항 효율성 제고: 최적 경로 산출과 정비 간격 단축으로 연료비 및 운영비 절감 • 안전성 향상: 조종사 경로 지원 및 위험 상황 조기 경고를 통해 사고 위험 감소 • 서비스 품질 강화: 승객 탑승 경험 개선 및 정시 운항률 상승에 따른 고객 만족도 제고 3. 직면 과제 • 윤리·법적 이슈: 자율결정 과정의 책임 주체 규명 및 국제 규제 체계 정립 • 전문인력 역할 변화: 조종사·정비사 등 기존 전문가와 AI 간 협업 모델 설계 • 기술 신뢰성 확보: AI 알고리즘의 설명 가능성과 검증된 안전성 입증 • 데이터 관리·보안: 항공기·탑승객 정보의 프라이버시 보호와 사이버 공격 대비 ##결론## 인공지능은 항공 산업의 운항 효율, 안전성, 서비스 품질을 획기적으로 개선할 잠재력을 지닌다. 다만 윤리·법적 규제 정비, 전문가 협업 체계 구축, 기술 검증 및 보안 확보 등의 과제를 해결해야만 보다 광범위한 상용화와 지속 가능한 발전이 가능하다.","Can I briefly summarize the basic concepts, industrial meanings, and face tasks of artificial intelligence applied to the aviation field?","##title## Artificial intelligence applied to aviation ##introduction## Since the establishment of the concept in 1956, artificial intelligence has been developing to carry out intelligent decisions with minimal human intervention based on computers. Since the aviation industry requires real -time decision -making and vast data in a complex environment, the introduction of AI technology has been pursued at the same time. ## Main ## 1. Basic concept • Autonomous flight and route optimization: automatically exploring and modifying the optimal path based on gas sensor data • Predictive Maintenance: Analyze the state data of the gas and predict the failure time. • Safety monitoring: real -time detection of abnormal signs of control room, room, and ground facilities 2. Industrial meaning • Enhancement of operating efficiency: Reduction of fuel and operating costs by calculating optimal routes and shortening maintenance intervals • Improved safety: Reduced accident risks through pilot path support and early warning of dangerous situations • Strengthening service quality: Enhancement of customer satisfaction due to improving passenger boarding experience and increasing on -time operating rate 3. Facial task • Ethics and legal issues: identifying responsibility for autonomous decision -making process and establishing international regulatory system • Changes in professional manpower role: Designed for collaborative models between existing experts such as pilots and mechanics and AI • Securing technology reliability: The possibility of explanation of AI algorithms and proven proven safety • Data management and security: Privacy protection and cyber attacks of aircraft and passenger information ##conclusion## Artificial intelligence has the potential to dramatically improve the efficiency, safety and service quality of the aviation industry. However, it is necessary to solve the tasks such as ethics and legal regulatory maintenance, establishment of expert collaboration system, technical verification and security secure.","Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",7,1.1859924140007934,"**제목: 항공 분야 인공지능 적용: 개념, 산업적 의미, 그리고 과제**

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 항공 분야에 적용된 인공지능(AI)의 기본 개념, 산업적 의미, 그리고 직면 과제를 분석합니다. 제공된 문서들은 항공 산업의 다양한 측면 (저가 항공 모델, 안전 관리, 승무원 교육)을 다루고 있으나, AI의 직접적인 언급은 없습니다. 따라서,  문서에 제시된 내용을 바탕으로 항공 산업의 특징과 당면 과제를 분석하여 AI 적용 가능성 및 그 의미를 간접적으로 추론합니다.


**본론:**

제공된 문서는 인공지능 자체를 다루지는 않지만, 항공 산업의 효율성 향상 및 안전 개선을 위한 데이터 분석의 중요성을 강조하고 있습니다.  문서 1에서는 easyJet의 성공 전략으로 인터넷 예약 시스템 도입을 통해 비용 절감을 이룬 사례를 제시합니다. 이는 AI 기반의 예약 시스템 및 수요 예측 시스템을 통해 더욱 고도화될 수 있음을 시사합니다.  AI는 실시간 수요 변동에 따른 동적 가격 책정, 개인 맞춤형 여행 상품 추천 등에 활용되어 수익 증대 및 고객 만족도 향상에 기여할 수 있습니다.

문서 4는 항공 안전 분야에서 빅데이터 분석 기법의 활용 방안을 연구합니다.  항공 사고는 막대한 인명 및 재산 피해를 야기하므로,  AI 기반의 예측 시스템은 매우 중요한 의미를 가집니다. 텍스트 마이닝 등의 기법을 통해 항공 사고 및 준사고 데이터를 분석하여 잠재적 위험 요인을 사전에 파악하고 예방 조치를 취할 수 있습니다.  AI는 비행기의 상태 정보, 기상 데이터, 조종사의 행동 패턴 등 다양한 데이터를 분석하여 안전 운항을 지원하고 사고 발생 가능성을 예측하는 데 활용될 수 있습니다.  이를 통해 항공 안전을 강화하고 운항 효율성을 높일 수 있습니다.

문서 5는 항공 승무원의 감정노동과 CS 교육의 관계를 분석합니다.  AI 기반의 감정 인식 시스템은 승무원의 감정 상태를 실시간으로 파악하여 필요한 지원을 제공하는 데 활용될 수 있습니다. 또한, AI 기반의 교육 시스템은 승무원들에게 개인 맞춤형 교육을 제공하여 서비스 품질 향상에 기여할 수 있습니다.  AI는 고객과 승무원 간의 상호작용 데이터를 분석하여 고객 만족도를 높이는 데 필요한 교육 내용을 개선하는데 활용될 수 있습니다.

하지만, AI 기술의 항공 분야 적용에는 과제도 존재합니다.  데이터의 양과 질, AI 시스템의 신뢰성 확보, 그리고 윤리적 문제 등을 고려해야 합니다.  특히, 안전과 직결된 분야인 만큼 AI 시스템의 오류로 인한 위험을 최소화하는 것이 중요합니다.  또한, AI 시스템의 투명성을 확보하고, 데이터 프라이버시 문제를 해결하는 것도 중요한 과제입니다.


**결론:**

AI는 항공 산업의 다양한 분야에서 효율성 향상, 안전 증대, 고객 만족도 제고 등에 기여할 수 있는 잠재력을 가지고 있습니다.  하지만,  데이터 관리, 시스템 신뢰성, 윤리적 문제 등의 과제를 해결해야 성공적인 AI 도입이 가능합니다.  향후, 이러한 과제들을 해결하기 위한 연구와 투자가 지속적으로 이루어져야 할 것입니다.",항공 산업에서의 와해성 기술과 혁신 : easyJet 사례를 중심으로,"한국 기록문화유산 정보시각화 연구 방안 : 천문류초, 천상열차분야지도 중심으로",질적 연구 방법의 내용과 적용전략: 양적인 질적 연구와질적인 질적 연구,항공 안전 분야 빅 데이터 분석 기법 활용 방안에 대한 연구,CS교육훈련의 프로그램 특성이 항공 승무원의 감정노동에 미치는 영향,항공 정비 근로자의 직무 스트레스에 관한 연구,항공 정비자원관리를 통한 정비안전문화 발전방안 제시,航空運送産業의 環境變化와 低價 航空社의 發展方案,저가항공사 취항이 제주 항공수요에 미치는 영향,세계 항공산업 분석과 한국 항공산업의 발전전략,무인 항공기 활용 전략에 관한 연구,ESP 특수 목적 영어 연구 : 항공 승무원 영어를 중심으로,성공적인 메이크업 아티스트에 관한 탐색적 연구 : 심층면접법을 중심으로,빅데이터를 활용한 헤어 미용분야 패러다임 변화 연구,조선초기 천문관측 기구의 이해와 교육적 활용방안,사물인터넷 적용을 통한 건설 안전관리 시스템 개선방안,"재직근로자의 훈련 참여동기와 훈련만족도, 학업성취도 및 현업적용 예상도의 관계",소규모 IT 운영조직을 위한 ITSM 운영방안 연구,"카올린, 아데노신 및 식물복합추출물등이 함유된 안면팩의 피부 개선효과에 관한 인체적용시험 연구",발전설비에 적용되는 보수용접 조건 및 사례분석,PRECEDE 모형을 적용한 초등학교 안전교육의 진단적 연구,건강신념 모델을 적용한 고혈압 영양교육프로그램 개발 및 효과 평가,로이의 적응 모델을 적용한 동종 조혈모세포이식 환자의 삶의 질 변화,인듐틴옥사이드에서의 자기조립박막 형성과 유기전기발광소자로의 응용,국제비즈니스계약에 적용되는 법,자기결정성이론과 현장 적용 연구,부동산분야 국가직무능력표준(NCS)에 관한 고찰,『天象列次分野之圖』 圖說의 문헌학적 연구,2020년 압축기 분야 연구동향,2020년 환경기계 분야 연구동향,,,,,,,,,,,,,,,,,,,,
구성주의 관점에서 인공지능 연구가 확장한 지능 이해의 지평과 주요 기술 동향을 어떻게 요약할 수 있나요?,"##제목## 구성주의 관점의 인공지능 지능 이해 지평 확장과 주요 기술 동향 ##서론## 구성주의는 데카르트적 이성주의를 넘어 진화생물학·진화심리학·뇌과학·시스템 이론·복잡계 이론 등 여러 학문적 성과를 통합하여 지능을 환경과 상호작용하며 능동적으로 형성되는 현상으로 이해한다. 이러한 관점은 전통적 상징처리 모델과 달리 경험적이고 맥락적이며 다층적인 학습 과정을 강조한다. ##본론## 첫째, 구성주의적 접근은 에이전트가 자신의 지식 구조를 환경과의 지속적 상호작용을 통해 스스로 재구성하도록 설계된 인공생명(Artificial Life)과 군집지능(Swarm Intelligence) 연구를 활성화시켰다. 둘째, 심층강화학습과 예측부호화(Predictive Coding) 같은 기술은 에이전트 기반 프레임워크로 전환되어, 맥락 인식과 적응 능력을 강화하며 구성주의 이론을 실현하고 있다. 셋째, 구성주의는 인지적·정서적 요소를 함께 다루는 설명 가능한 AI 및 인간-기계 협업 시스템 설계에도 적용되어, 신뢰형 AI와 교육·심리치료 등 다양한 분야에서 혁신적 접근을 가능하게 한다. ##결론## 구성주의 관점은 지능을 단순 정보 처리 능력 이상으로 보고, 분산 에이전트와 상호작용 기반 학습을 핵심 원리로 제시함으로써 AI 연구의 지평을 넓힌다. 이는 범용지능 실현과 인간 수준의 협업형 AI 개발을 위한 중요한 이론적 토대를 제공한다.",How can we summarize the horizon and major technical trends that have expanded by artificial intelligence research from the perspective of components?,"##title## The extension of the horizon of artificial intelligence understanding in terms of constructivist and major technology trends ##introduction## Configurationism is understood as a phenomenon in which intelligence interacts with the environment by integrating various academic achievements such as evolutionary biology, evolutionary psychology, brain science, system theory, and complexity theory beyond Descartic rationalism. This perspective emphasizes emphasis on empirical, contextual, and multilayer, unlike traditional symbolism models. ## Main ## First, the constructive approach activated the study of artificial life and swarm intelligence designed to reconstruct their knowledge structure through continuous interaction with the environment. Second, technologies such as in -depth enhancement learning and predictive coding are converted into agent -based frameworks, enhancing context recognition and adaptation ability and realizing constructivism theory. Third, constructivism is also applied to the designable AI and human-machine collaboration system design that deals with cognitive and emotional elements, enabling innovative approaches in various fields such as trust AI and education and psychological therapy. ##conclusion## Configuration's perspective seeks the horizon of AI research by viewing intelligence beyond simple information processing ability and presenting interaction -based learning with distributed agents as a key principle. This provides an important theoretical foundation for the realization of general intelligence and the development of human -level collaborative AI.","Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",8,1.1859924140007934,"**제목: 구성주의 관점과 무관한 인공지능 연구의 지능 이해 지평 및 기술 동향 요약**

**서론:**

제시된 문서들은 인공지능 연구와 직접적으로 관련이 없으며, 구성주의 관점에서 인공지능 연구가 확장한 지능 이해의 지평과 주요 기술 동향을 다루지 않습니다. 따라서 원본 질문에 대한 직접적인 답변은 불가능합니다.  다만, 제공된 문서들이 다루는 주제들 – 고령화 사회에서의 지식 전파, 구성주의 미술 교육, 중년 남성의 진로 구성, 좋은 수업에 대한 관점, 강점 관점의 집단 사회복지 실천 –  은 지능, 학습, 성장 등의 개념과 관련되어 있으며, 이러한 개념들이 인공지능 연구와 간접적으로 연관될 수 있다는 점을 고려하여, 관련성이 있는 부분을 추론하여 보고서를 작성합니다.  이는 원본 질문에 완벽하게 답하지 못하지만, 제공된 자료 내에서 최대한 관련성 있는 정보를 활용한 분석을 시도하는 것입니다.


**본론:**

제공된 문서들은 인공지능 기술의 발전이나 지능의 정의에 대해 직접적으로 언급하지 않습니다. 그러나 문서들은 다양한 학습 및 성장 모델을 보여주고 있습니다. 예를 들어, 문서 1은 고령화된 노동력의 지식 전파를 위한 HR 제도의 중요성을 강조하며, 이는 지식 습득과 전파라는 측면에서 인공지능의 기계 학습과 유사한 점을 가지고 있습니다.  문서 2는 구성주의 교육의 관점에서 북 아트를 활용한 교육 방안을 제시하는데, 이는 학습자 중심의 학습 방식과 자기주도적 학습에 대한 강조로, 인공지능 분야에서 개인 맞춤형 학습 시스템 개발과 관련이 있습니다. 문서 3은 한 중년 남성의 진로 구성 과정을 통해 'work'의 개념 변화를 제시하며, 이는 인공지능 시대에 필요한 인간의 역할 재정의와 관련될 수 있습니다.  문서 4는 좋은 수업에 대한 교사와 학생의 관점을 제시하며, 이를 통해 효과적인 지식 전달 방식에 대한 이해를 도울 수 있습니다. 이러한 효과적인 지식 전달 방식은 인공지능 기반 교육 시스템 개발에 활용될 수 있습니다. 마지막으로 문서 5는 강점 관점의 집단 사회복지 실천 프로그램의 효과를 분석하며, 이는 개인의 강점을 활용한 성장 지원이라는 측면에서 인공지능이 개인의 잠재력을 극대화하는 방향으로 활용될 수 있음을 시사합니다.

그러나 이러한 유추는 제공된 문서에서 직접적으로 인공지능에 대한 언급이 없다는 점을 고려해야 합니다.  따라서 구성주의 관점에서 인공지능이 지능 이해의 지평을 어떻게 확장했는지,  구체적인 기술 동향을 분석하는 것은 불가능합니다.

**결론:**

제공된 문서들은 인공지능 연구와 직접적으로 관련된 정보를 포함하지 않습니다. 따라서 구성주의 관점에서의 인공지능 연구에 대한 지능 이해의 지평 확장 및 주요 기술 동향에 대한 요약은 불가능합니다.  제공된 문서의 내용을 바탕으로 인공지능 연구와 관련된 개념들을 유추해볼 수 있으나, 이는 추론에 불과하며, 명확한 사실을 바탕으로 한 분석이 아님을 명시합니다.  인공지능 연구에 대한 심층적인 이해와 구성주의적 관점의 통합적인 분석을 위해서는 관련 연구 논문을 추가로 참고해야 합니다.",고령화-조직성과 관계에 있어 지식 전파 HR 제도의 역할- 지식경영 관점을 중심으로 -,구성주의 관점에서 본 북 아트의 교육적 활용 방안 연구,한 중년남성의 진로구성 과정,좋은 수업에 대한 관점과 개념: 교사와 학생 면담 연구,강점관점 집단사회복지실천 프로그램이 초등돌봄교실 아동의 자기효능감과 학교생활적응에 미치는 효과,빈곤여성의 역경극복과정 : 강점관점 사례관리 참여자 중심으로,결혼 이주여성의 임신·출산과 문화적응,자본주의 발전 및 붕괴와 공황에 관한 연구 : 재생산 표식 논쟁을 중심으로,초등학교도서관의 대출현황과 장서구성에 관한 분석적 연구,행정윤리의 본질과 관점,신자유주의 정부역할에 대한 한국인의 태도,고등학교도서관 장서구성 현황분석 및 영향 요인에 관한 연구,초등학교 고학년을 위한 식품구성자전거를 활용한 영양교육 프로그램의 개발 및 적용,사회복지사가 경험한 강점관점 해결중심 사례관리 실천 과정에 관한 연구,XML 관점 명세를 이용한 관점지향 프로그래밍의 개선,행동주의 심리학과 도덕적 사고와 실천 : 고등학교 〈윤리와 사상〉을 중심으로,포스트식민주의 이론의 이해와 수용,한국에서 채식주의자 되기 : 집단주의 문화에서의 채식주의 전략,복지권의 구성과 성격,관광학 전공 대학생의 직무역량 구성 타당성 연구,통신산업 민영화의 효익 : 사회적 관점 대 대리인 관점,영양적 관점(하),공산주의 붕괴에 관한 통일사상적 연구,현대 공리주의 동향에 대한 연구,선별주의와 보편주의를 둘러싼 지방복지정책의 갈등 분석 : 서울특별시 무상급식정책을 중심으로,"복지다원주의, 시장 그리고 한국적 모델",보편주의 복지담론 연구,교사들이 구성하는 아동중심교육의 의미,경기 일부지역 초등학생의 식품구성자전거와 식생활지침에 대한 이해도와 실천도의 연구,전자계산일반 학습용 멀티미디어 타이틀의 설계 및 구현 : 컴퓨터의 구성과 원리를 중심으로,,,,,,,,,,,,,,,,,,,,
"컴퓨터과학자들이 제안한 인공지능 정의에 내재된 지능, 뇌, 그리고 컴퓨터 모의 사이의 논쟁적 쟁점을 어떻게 요약할 수 있나요?","##제목## 인공지능 정의에 담긴 지능·뇌·컴퓨터 모의의 핵심 논쟁 ##서론## 인공지능 연구에서 지능, 뇌, 그리고 컴퓨터 모의 사이의 관계를 어떻게 설정하느냐는 정의 자체의 방향을 가르는 중요한 쟁점이다. AI 연구자들은 인간 지능의 본질을 과학적으로 분석하면서 동시에 이를 컴퓨터 시스템으로 구현·복제하려는 목표를 공유한다. 이 과정에서 드러나는 주요 논쟁은 경험적 기술 발전의 문제를 넘어 논리적·개념적 선험성에 관한 것이다. ##본론## 1. 지능의 개념화: - 일부 정의는 지능을 문제 해결 능력이나 정보처리 효율로 환원하지만, 다른 입장에서는 창의성·맥락 이해 등 비계산적 요소를 강조한다. - 이처럼 지능의 범위를 어떻게 설정하느냐에 따라 AI 목표와 평가 기준이 달라진다. 2. 지능과 뇌의 관계: - 기계적 모의가 가능한가라는 물음은 뇌의 기능을 얼마나 정밀하게 수학·논리 모델로 환원할 수 있는지와 직결된다. - 신경망, 복잡계 이론 등 뇌과학 성과를 차용한 접근이 존재하지만, 생물학적 뇌가 지니는 비선형·동적 특성을 모두 모방하기에는 한계가 명확하다. 3. 컴퓨터 모의의 논리 구조: - 컴퓨터 시뮬레이션은 기호 처리(symbolic processing)와 계산 모델에 기반하지만, 이론적 비판론자들은 의미 부여·상향식 학습 등을 처리하지 못한다고 지적한다. - 따라서 AI 정의는 기술적 능력과 더불어 개념적 명료성, 즉 어떤 ‘지능’을 왜·어떻게 모의하는지에 대한 논리적 근거 확보가 필수적이다. 4. 경험적 진보 vs 선험적 분석: - 하드웨어·알고리즘 발전이 보여주는 성과에도 불구하고, AI 탐구의 핵심은 개념·논리적 쟁점에 대한 선험적 고찰에서 비롯된다. - 지능과 뇌, 그리고 컴퓨터 모의 간의 논의를 명확히 구축해야만 지속 가능한 이론적 토대를 마련할 수 있다. ##결론## 인공지능의 정의를 둘러싼 논쟁은 기술적 성취를 넘어 지능의 본질과 뇌 모사의 논리적 근거를 엄밀히 따지는 개념적 과제를 요구한다. 이를 통해 AI 연구는 단순 시뮬레이션 수준을 넘어, 인간 지능의 다양한 특성을 정교하게 반영하고 설명할 수 있는 방향으로 진화할 수 있다.","How can you summarize the controversial issue between intelligence, brain, and computer simulation inherent in the definition of artificial intelligence proposed by computer scientists?","##title## Intelligence, brain, and computer mock core arguments contained in artificial intelligence definition ##introduction## How to set up the relationship between intelligence, brain, and computer mock in AI research is an important issue that divides the direction of the definition itself. AI researchers scientifically analyze the essence of human intelligence and at the same time share their goals to implement and replicate them with their computer systems. The main debate revealed in this process is to go beyond the problem of empirical technology and relate to logical and conceptual priorities. ## Main ## 1. Conceptualization of Intelligence: Some definitions reduce intelligence with problem -solving ability or information processing efficiency, but other perspectives emphasize non -calculated factors such as creativity and context. -The AI goal and evaluation criteria depend on how to set the scope of intelligence. 2. The relationship between intelligence and brain: The question of whether mechanical simulation is possible is directly related to how precisely the brain's function can be reduced to mathematics and logical models. Although there are approaches to brain science, such as neural networks and complex theory, there is a clear limit to imitating all nonlinear and dynamic characteristics of biological brain. 3. Computer mock logic structure: Computer simulations are based on symbolic processing and calculation models, but theoretical criticisms point out that they do not process meaning and bottom -up learning. Therefore, AI definition is essential to secure a logical basis for the technical ability, the conceptual clarity, that is, what kind of intelligence, and how to simulate what intelligence. 4. Empirical Progress vs priority analysis: Despite the achievements of the development of hardware and algorithms, the core of the AI exploration comes from a priori consideration of concept and logical issues. -The discussion between intelligence, brain, and computer mocks can be clearly established to lay the foundation for sustainable theoretical theoretical theoretical theoretical. ##conclusion## The debate over the definition of artificial intelligence goes beyond technical achievements and requires a conceptual task that strictly determines the essence of intelligence and the logical basis of brain simulation. Through this, AI research can go beyond simple simulation levels, and evolve in a way that can be delicately reflected and explained the various characteristics of human intelligence.","Title: 인공지능(Artificial Intelligence)과 대학수학교육, Abstract: 첨단 정보통신기술(ICT)인 인공지능(AI), 사물인터넷(IoT), 빅데이터(Big Data) 등이 사회와 경제 전반에 융합돼 혁신적인 변화가 일어나는 요즘, 헬스케어, 지능형 로봇, 가정용 인공지능 시스템(스마트홈), 공유자동차 등은 이미 우리 생활에 깊이 영향을 미치고 있다. 이미 오래전부터 공장에서는 로봇이 사람 대신 일을 하고 있으며(FA, OA), 인공지능 의사도 병원에서 활동을 하고 있고(Dr. Watson), 인공지능 스피커(기가지니)와 인공지능 비서인 구글 어시스턴트가 자연어생성을 하며 우리를 돕고 있다. 이제 인공지능을 이해하는 것은 필수가 되었으며, 인공지능을 이해하기 위해서 수학의 지식은 선택이 아니라 필수가 되었다. 따라서 이런 일들을 가능하게 해주는 수학지식을 설명하는 역할이 수학자들에게 주어졌다. 이에 본 연구진은 인공지능과 머신러닝(Machine Learning, 기계학습)을 이해하기 위해 필요한 수학 개념을 우리의 실정에 맞게 한 학기(또는 두 학기) 분량으로 정리하여, 무료 전자교과서 '인공지능을 위한 기초수학'을 집필하고, 인공지능 분야에 관심이 있는 다양한 전공의 대학생과 대학원생을 대상으로 하는 강좌를 개설하였다. 본 논문에서는 그 개발과정과 운영사례를 공유한다. http://matrix.skku.ac.kr/math4ai/, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014151762669,","Title: 초등 인공지능 교육을 위한 설명 가능한 인공지능의 교육적 의미 연구, Abstract: 본 연구는 문헌 연구 통해 설명 가능한 인공지능의 개념과 문제해결과정을 탐구하였다. 본 연구를 통하여 설명 가능한 인공지능의 교육적 의미와 적용 방안을 제시하였다. 설명 가능한 인공지능 교육이란 인간과 관련된 인공지능 문제를 다루는 사람 중심의 인공지능 교육으로 학생들은 문제 해결 능력을 함양할 수 있다. 그리고, 알고리즘 교육을 통해 인공지능의 원리를 이해하고 실생활 문제 상황과 관련된 인공지능 모델을 설명하며 인공지능의 활용분야까지 확장할 수 있다. 이러한 설명 가능한 인공지능 교육이 초등학교에서 적용되기 위해서는 실제 삶과 관련된 예를 사용해야 하며 알고리즘 자체가 해석력을 지닌 것을 활용하는 것이 좋다. 또한, 이해가 설명으로 나아가기 위해 다양한 교수학습방법 및 도구를 활용해야 한다. 2022년 개정 교육과정에서 인공지능 도입을 앞두고 본 연구가 실제 수업을 위한 기반으로써 의미 있게 활용되기를 바란다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202132238500768,","Title: 구성적 인공지능, Abstract: 서양철학의 근간을 이루는 데카르트의 이성주의적 인간이해의 반성으로부터 등장한 구성주의는 지능을 포함한 인간이해의 새로운 대안이 될 수 있을 것으로 생각한다. 구성주의는 진화생물학, 진화심리학, 뇌과학, 시스템이론, 복잡계 이론의 성과뿐만 아니라 나아가 인문사회학의 경향과도 설명을 공유할 수 있는 많은 부분이 있다. 또한 인공지능 분야에서도 구성주의적 방법이라고 할 수 있는 연구가 진행되고 있다. 이 글에서는 구성주의적 관점에서 인공지능에서 다루는 지능에 대한 이해의 지평을 넓히고 이를 기반으로 한 방법론에 대한 검토와 그러한 경향에 있는 일부 인공지능 기술을 살펴보고자 한다. 이러한 논의를 통하여 여러 가지 관점의 마음에 대한 이론과 기술을 상호보완적으로 이해하고 다소 등한히 되고 있는 인공지능의 보편지능(general intelligence)의 토대로 삼고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200430710415942,","Title: 마음,지능,인공지능, Abstract: 최근 여러 학문 분야에서는 논의되고 있는 인공지능(AI)의 문제는 과학적 문제임과 동시에 중요한 철학적 문제이다.본고는 컴퓨터과학자 혹은 인지과학자들이 내리고 있는 AI의 정의들을 분석함으로써 그 속에 함축되어 있는 논쟁점들을 발굴하고,관련된 논변들을 검토함 으로써 AI탐구가 지니는 의의를 명확히 해보려는 데 그 목적이 있다.AI에 대한 정의들은 AI연구가들의 관심과 목표 그리고 그 주장의 강도에 따라 여러 유형으로 분류될 수 있지만 대개가 인간지능을 어떻게 파악하고 있는지,지능과 뇌의 관계가 무엇인지,그리고 그것을 컴퓨터를 통해서 모의하고 복제한다는 것의 논리적 구조가 무엇인지에 대한 이해와 밀접한 관계가 있다.이점에서 AI연구에 있어서 관건이 되는 것은 컴퓨터 기술의 발전과 같은 경험상의 문제라기 보다는 오히려 논리나 개념분석과 같은 선험적인 문제와 밀접하게 연관되어 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO198911920276086,","Title: 인공지능 생성 콘텐츠(Artificial Intelligence Generated Content)와 인공지능 사용 공개(Artificial Intelligence Disclaimer)에 대한 소비자 인식 연구: 콘텐츠 가치와 형식을 중심으로, Abstract: 최근 생성형 인공지능(Artificial Intelligence)은 다양한 형식의 미디어를 포함하여 자율적으로 콘텐츠를 생성할 수 있는 능력으로 주목받고 있다. 그 잠재력에도 불구하고 AI가 생성한 콘텐츠(AI-Generated Content, AIGC)의 진정성(Authenticity) 이슈가 제기됨에 따라 각국에서 AI 사용과 투명성에 대한 규제가 수립되고 있다. 하지만, AIGC와 AI 사용 공개(AI Disclaimer)에 대한 소비자의 이해라는 근본적인 주제는 여전히 탐색되지 않고 있다. 본 연구는 생성형 AI가 제작한 콘텐츠를 실용적, 쾌락적 가치유형으로 구분하고 각각 글, 사진, 영상의 미디어 형식을 적용한 6가지의 경우에 대한 소비자의 인식을 카노 모형을 통해 분석하였다. 나아가, 도출된 결과를 인지된 진정성과 기만으로 그룹을 구분해 인식의 차이가 이에 따라 드러나는지 추가적으로 살펴보았다. 연구 결과, AI가 생성한 콘텐츠에 대한 소비자 인식은 만족도에 큰 영향을 미치지 않았으나, 뉴스로 대표되는 실용적 콘텐츠에서는 AI 사용에 대한 부정적 인식이 확인되었으며, 특히 뉴스 영상 제작에 있어 부정적 인식이 강하게 드러났다. 반면, 영화와 드라마로 대표되는 쾌락적 콘텐츠에서는 생성형 AI 사용에 대한 인식이 무관심하거나 오히려 긍정적이었다. AI 사용 여부의 공개에 대해서는 콘텐츠 가치유형에 관계없이 지켜야 할 원칙으로 인식되었으나, 실용적 콘텐츠에 대해 그러한 인식이 더 강하게 드러났다. 본 연구는 AI 활용의 투명성과 진정성을 제고하는 방안이 필요함을 시사하며, 향후 AI의 발전과 활용이 소비자 인식에 미치는 영향을 지속적으로 연구할 필요가 있음을 강조한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408436007069,","Title: Artificial Intelligence, Language Intelligence, and Mathematics, Abstract: Artificial neural networks(ANN) has provided a theoretical framework on the study of human behavior/cognition and artificial intelligence. This article aims to introduce ANN and its mathematical principle to the field of applied linguistics. An ANN consists of input, hidden, and output vectors and the vectors are connected to one another by weight matrices. Mapping from input to output is accounted for by simple matrix multiplication., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002391816,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: Crowdsourcing platforms such as Amazon Mechanical Turk have become popular for a wide variety of human intelligence tasks; however, quality control continues to be a significant challenge. Recently, we propose TurKontrol, a theoretical model based on POMDPs to optimize iterative, crowd-sourced workflows. However, they neither describe how to learn the model parameters, nor show its effectiveness in a real crowd-sourced setting. Learning is challenging due to the scale of the model and noisy data: there are hundreds of thousands of workers with high-variance abilities. This paper presents an end-to-end system that first learns TurKontrol's POMDP parameters from real Mechanical Turk data, and then applies the model to dynamically optimize live tasks. We validate the model and use it to control a successive-improvement process on Mechanical Turk. By modeling worker accuracy and voting patterns, our system produces significantly superior artifacts compared to those generated through nonadaptive workflows using the same amount of money. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120023140,","Title: Sustainable artificial intelligence: A corporate culture perspective, Abstract: AbstractIn recent years, various studies have highlighted the opportunities of artificial intelligence (AI) for our society. For example, AI solutions can help reduce pollution, waste, or carbon footprints. On the other hand, there are also risks associated with the use of AI, such as increasing inequality in society or high resource consumption for computing power. This paper explores the question how corporate culture influences the use of artificial intelligence in terms of sustainable development. This type of use includes a normative element and is referred to in the paper as sustainable artificial intelligence (SAI). Based on a bibliometric literature analysis, we identify features of a sustainability-oriented corporate culture. We offer six propositions examining the influence of specific manifestations on the handling of AI in the sense of SAI. Thus, if companies want to ensure that SAI is realized, corporate culture appears as an important indicator and influencing factor at the same time., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122671508,","Title: The Importance of Artificial Intelligence to Economic Growth, Abstract: The rapid development of artificial intelligence technology has exerted a great influence on all fields of the world, which of course also affects the world economy. This has also aroused a large number of economists' interest in this proposition. Since the definition of artificial intelligence is not unified yet, the results from previous researches are not reliable enough. At present, most scholars use the neoclassical growth model or task-based model to explore the path of artificial intelligence on economic variables. There into, most of them use the degree of automation to represent the artificial intelligence. They find that the degree of automation can change the proportion of industries. This only verifies that artificial intelligence can affect the economic variables. But the magnitude of artificial intelligence on economic variables can not be correctly estimated. Therefore, in order to have a better understanding on the impact of artificial intelligence on economic growth, this paper systematically reviews and collates previous literature on this topic. The results of this paper indicate that both in theoretical and empirical studies, artificial intelligence has a positive effect on economic growth. Then, some suggestions and limitations have also been put forward accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201934651404424,","Title: Artificial intelligence in obstetrics, Abstract: This study reviews recent advances on the application of artificial intelligence for the early diagnosis of variousmaternal-fetal conditions such as preterm birth and abnormal fetal growth. It is found in this study that variousmachine learning methods have been successfully employed for different kinds of data capture with regard to earlydiagnosis of maternal-fetal conditions. With the more popular use of artificial intelligence, ethical issues should alsobe considered accordingly., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002820289,","Title: Exploring Artificial Intelligence Futures, Abstract: Artificial intelligence technologies are receiving high levels of attention and ‘hype’, leading to a range of speculation about futures in which such technologies, and their successors, are commonly deployed. By looking at existing AI futures work, this paper surveys, and offers an initial categorisation of, several of the tools available for such futures-exploration, in particular those available to humanities scholars, and discusses some of the benefits and limitations of each. While no tools exist to reliably predict the future of artificial intelligence, several tools can help us expand our range of possible futures in order to reduce unexpected surprises, and to create common languages and models that enable constructive conversations about the kinds of futures we would like to occupy or avoid. The paper points at several tools as particularly promising and currently neglected, calling for more work in data-driven, realistic, integrative, and participatory scenario role-plays., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002678073,","Title: Trends of Artificial Intelligence Product Certification Programs, Abstract: With recent advancements in artificial intelligence (AI) technology, more products based on AI are being launched and used. However, using AI safely requires an awareness of the potential risks it can pose. These concerns must be evaluated by experts and users must be informed of the results. In response to this need, many countries have implemented certification programs for products based on AI. In this study, we analyze several trends and differences in AI product certification programs across several countries and emphasize the importance of such programs in ensuring the safety and trustworthiness of products that include AI. To this end, we examine four international AI product certification programs and suggest methods for improving and promoting these programs. The certification programs target AI products produced for specific purposes such as autonomous intelligence systems and facial recognition technology, or extend a conventional software quality certification based on the ISO/IEC 25000 standard. The results of our analysis show that companies aim to strategically differentiate their products in the market by ensuring the quality and trustworthiness of AI technologies. Additionally, we propose methods to improve and promote the certification programs based on the results. These findings provide new knowledge and insights that contribute to the development of AI-based product certification programs., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202326943334293,","Title: Human- versus Artificial Intelligence, Abstract: AI is one of the most debated subjects of today and there seems little common understanding concerning the differences and similarities of human intelligence and artificial intelligence. Discussions on many relevant topics, such as trustworthiness, explainability, and ethics are characterized by implicit anthropocentric and anthropomorphistic conceptions and, for instance, the pursuit of human-like intelligence as the golden standard for Artificial Intelligence. In order to provide more agreement and to substantiate possible future research objectives, this paper presents three notions on the similarities and differences between human- and artificial intelligence: 1) the fundamental constraints of human (and artificial) intelligence, 2) human intelligence as one of many possible forms of general intelligence, and 3) the high potential impact of multiple (integrated) forms of narrow-hybrid AI applications. For the time being, AI systems will have fundamentally different cognitive qualities and abilities than biological systems. For this reason, a most prominent issue is how we can use (and &ldquo;collaborate&rdquo; with) these systems as effectively as possible? For what tasks and under what conditions, decisions are safe to leave to AI and when is human judgment required? How can we capitalize on the specific strengths of human- and artificial intelligence? How to deploy AI systems effectively to complement and compensate for the inherent constraints of human cognition (and vice versa)? Should we pursue the development of AI &ldquo;partners&rdquo; with human (-level) intelligence or should we focus more at supplementing human limitations? In order to answer these questions, humans working with AI systems in the workplace or in policy making have to develop an adequate mental model of the underlying &lsquo;psychological&rsquo; mechanisms of AI. So, in order to obtain well-functioning human-AI systems, Intelligence Awareness in humans should be addressed more vigorously. For this purpose a first framework for educational content is proposed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117581301,","Title: Artificial Intelligence in Pharmacy, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART125829488,","Title: What's Humanity for Artificial Intelligence Humane Artificial Intelligence and Artificial General Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661543,","Title: Artificial Intelligence for Artificial Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09810052,","Title: Artificial Agential Intelligence, Abstract: Since artificial intelligence (AI) emerged in the mid-20th century, it has incurred many theoretical criticisms (Dreyfus, H. [1972] What Computers Can&rsquo;t Do (MIT Press, New York); Dreyfus, H. [1992] What Computers Still Can&rsquo;t Do (MIT Press, New York); Searle, J. [1980] Minds, brains and programs, Behav. Brain Sci.3, 417-457; Searle, J. [1984] Minds, Brains and Sciences (Harvard University Press, Cambridge, MA); Searle, J. [1992] The Rediscovery of the Mind (MIT Press, Cambridge, MA); Fodor, J. [2002] The Mind Doesn&rsquo;t Work that Way: The Scope and Limits of Computational Psychology (MIT Press, Cambridge, MA).). The technical improvements of machine learning and deep learning, though, have been continuing and many breakthroughs have occurred recently. This makes theoretical considerations urgent again: can this new wave of AI fare better than its precursors in emulating or even having human-like minds? I propose a cautious yet positive hypothesis: current AI might create human-like mind, but only if it incorporates certain conceptual rewiring: it needs to shift from a task-based to an agent-based framework, which can be dubbed &ldquo;Artificial Agential Intelligence&rdquo; (AAI). It comprises practical reason (McDowell, J. [1979] Virtue and reason, Monist62(3), 331-350; McDowell, J. [1996] Mind and World (Harvard University Press, Cambridge, MA)), imaginative understanding (Campbell, J. [2020] Causation in Psychology (Harvard University Press, Cambridge, MA)), and animal knowledge (Sosa, E. [2007] A Virtue Epistemology: Apt Belief and Reflective Knowledge, volume 1 (Oxford University Press, Oxford, UK); Sosa, E. [2015] Judgment and Agency (Oxford University Press, Cambridge, MA)). Moreover, I will explore whether and in what way neuroscience-inspired AI and predictive coding (Hassabis, D., Kumaran, D., Summerfield, C., &amp; Botvinick, M. [2017] Neuroscience-inspired artificial intelligence, Neuron95(2), 245-258) can help carry out this project., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032000,","Title: Artificial Intelligence Memoranda 1958-1979: MIT AI Laboratory., Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART92637077,","Title: Artificial intelligence, Abstract: AI has been well supported by government research and development dollars for decades now, and people are beginning to ask hard questions: What really works? What are the limits? What doesn't work as advertised? What isn't likely to work? What isn't affordable? This article holds a mirror up to the community, both to provide feedback and stimulate more self-assessment. The significant accomplishments and strengths of the field are highlighted. The research agenda, strategy, and heuristics are reviewed, and a change of course is recommended to improve the field's ability to produce reusable and interoperable components.(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART03644772,","Title: Artificial Intelligence in Personalized ICT Learning, Abstract: Artificial Intelligence has stimulated every aspect of today's life. Human thinking quality is trying to be involved through digital tools in all research areas of the modern era. The education industry is also leveraging artificial intelligence magical power. Uses of digital technologies in pedagogical paradigms are being observed from the last century. The widespread involvement of artificial intelligence starts reshaping the educational landscape. Adaptive learning is an emerging pedagogical technique that uses computer-based algorithms, tools, and technologies for the learning process. These intelligent practices help at each learning curve stage, from content development to student's exam evaluation. The quality of information technology students and professionals training has also improved drastically with the involvement of artificial intelligence systems. In this paper, we will investigate adopted digital methods in the education sector so far. We will focus on intelligent techniques adopted for information technology students and professionals. Our literature review works on our proposed framework that entails four categories. These categories are communication between teacher and student, improved content design for computing course, evaluation of student's performance and intelligent agent. Our research will present the role of artificial intelligence in reshaping the educational process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213042334203,","Title: Swarm Intelligence and Artificial Life, Abstract: Swarm intelligence and artificial life have been developed rapidly in the last decade. As two artificial intelligence patterns, they open out the living phenomena and evolutive rules in different hierarchies by simulating natural living phenomena , and provide a new kind of thought for complicated behaviors modeling and simulation The origin and development of swarm intelligence and artificial life are reviewed in this paper. The difference and relation between them are analysed and the future of them is also speculated about., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART38029073,","Title: Artificial Intelligence in Nephrology: How Can Artificial Intelligence Augment Nephrologists’ Intelligence?, Abstract: Background: Artificial intelligence (AI) now plays a critical role in almost every area of our daily lives and academic disciplines due to the growth of computing power, advances in methods and techniques, and the explosion of the amount of data; medicine is not an exception. Rather than replacing clinicians, AI is augmenting the intelligence of clinicians in diagnosis, prognosis, and treatment decisions. Summary: Kidney disease is a substantial medical and public health burden globally, with both acute kidney injury and chronic kidney disease bringing about high morbidity and mortality as well as a huge economic burden. Even though the existing research and applied works have made certain contributions to more accurate prediction and better understanding of histologic pathology, there is a lot more work to be done and problems to solve. Key Messages: AI applications of diagnostics and prognostics for high-prevalence and high-morbidity types of nephropathy in medical-resource-inadequate areas need special attention; high-volume and high-quality data need to be collected and prepared; a consensus on ethics and safety in the use of AI technologies needs to be built., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100039851,","Title: Qualia, Consciousness and Artificial Intelligence, Abstract: It is noted that there are many different definitions of and views about qualia, and this makes qualia into a vague concept without much theoretical and constructive value. Here, qualia are redefined in a more general way. It is argued that the redefined qualia will be essential to the mind-body problem, the problem of consciousness and also to the symbol grounding problem, which is inherent in physical symbol systems. Then, it is argued that the redefined qualia are necessary for Artificial Intelligence systems for the operation with meanings. Finally, it is proposed that robots with qualia may be conscious., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART123032001,","Title: 항공분야의 인공지능, Abstract: Artificial Intelligence (AI) born in 1956 is a general term that implies the use of a computer to make intelligent machines with minimal human intervention. AI is a topic dominating diverse discussions on the future of professional employment, change in the social standard and economic performance. In this paper, I describe fundamental concepts underlying AI and their significance to various fields including aviation and medicine. I highlight issues involved and describe the potential impacts and challenges to the industrial fields. While many benefits are expected in human life with AI integration, problems are needed to be identified and discussed with respect to ethical issues and the future roles of professionals and specialists for their wider application of AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129066302,","Title: ARTIFICIAL INTELLIGENCE, Abstract: This article reports on Fujitsu's Artificial Intelligence (AI) research and development activities. Starting with research on a machine translation system around 1978, Fujitsu has introduced several AI-related products, including machine translation systems, expert system shells, and AI machines. Numerous different expert systems are now being implemented both by Fujitsu and its users. Long-range AI research activities are now under way at Fujitsu. Fujitsu is also participating in several projects, including the Fifth Generation Computer Systems project (FGCS project) being promoted by the Institute for New Generation Computer Technology (ICOT).(Author abstract), Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17953056,","Title: Artificial intelligence in manufacturing: Forecasts for the use of artificial intelligence in the USA, Abstract: The use of artificial intelligence in manufacturing has finally emerged as a reality in the United States. Buoyed by the general growth of trained computer scientists, the lower cost hardware and software designed for easier use input, a number of experimental programs are under way to exploit artificial intelligence for manufacturing purposes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16517887,","Title: European Supranational Governance of Artificial Intelligence, Abstract: The EU has established a robust foundation of the internal market that contains not only the traditional ways of transactions, involving goods, services, labour, and capital, but also the digital single market, relating to the new economy of artificial intelligence. Importantly, the historical development of supranational governance of the EU in the field of economic regulations, which covers various business practices and includes laws of competition and data protection, highlights its role in the global marketplace. Because the digital economy has become important around the world, the EU’s guidance in the area of artificial intelligence may influence overall policies on the new economy in other countries, particularly in Korea, and it is timely to discuss future policies on the digital economy and market, by looking at the recent approaches of the EU., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002608278,","Title: Artificial Intelligence Issues in Korean Music, Abstract: Since Artificial Intelligence (AI) emerged as an essential technology over the last decade, numerous concerns have surfaced questioning its application. These issues are primarily due to copyright infringement problems, which arise when the AI is trained on copyrighted content without obtaining authorisation. The music industry is one of the numerous sectors that started to be profoundly impacted by the implementation of AI. South Korea is unquestionably an interesting case study involving the use of AI in the music field. The country has devoted considerable resources to advancing and developing AI technology, with substantial government support, and it has been at the forefront of emerging developments in AI and music, particularly in terms of composition and visuals. These advancements gave rise to many questions regarding AI, ranging from copyright concerns to ethical dilemmas. This paper aims to examine and assess some of the most notable advancements related to artificial intelligence in the Korean music industry.It will begin with the emergence of innovative virtual idols, such as 에스파(Aespa), that incorporate AI and technology in the creation of their concepts. Additionally, it will cover other uses of AI in Korean popular music. For example, this technology can be utilised to strengthen the bond between international fans and artists, as in the case of MIDNATT, who sang multilingual versions of the same song through an AI process.This work will next examine the issues related to AI composers and producers through the case of이봄(EvoM), one of the three most significant AI-based composers globally. For a certain period, EvoM was granted royalties by the Korea Music Copyright Association (KOMCA), which is currently involved in discussions regarding the implementation of a compulsory AI labelling law in the country.Alongside the prospect of Korean regulations, this work also aims to highlight other recent advancements in the field, particularly concerning musical compositions and the use of copyrighted works for training artificial intelligence in the music industry. It focuses on the cases of the new European Union regulations on AI and copyright infringement cases involving music companies in the United States. By examining these cases, this paper provides a comprehensive overview of the current global efforts to address the challenges posed by technological advancements in Artificial Intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003093136,","Title: A Study on Artificial Intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107534134,","Title: Artificial Intelligence for the Fourth Industrial Revolution, Abstract: Artificial intelligence is one of the key technologies of the Fourth Industrial Revolution. This paper introduces the diverse kinds of approaches to subjects that tackle diverse kinds of research fields such as model-based MS approach, deep neural network model, image edge detection approach, cross-layer optimization model, LSSVM approach, screen design approach, CPU-GPU hybrid approach and so on. The research on Superintelligence and superconnection for IoT and big data is also described such as 'superintelligence-based systems and infrastructures', 'superconnection-based IoT and big data systems', 'analysis of IoT-based data and big data', 'infrastructure design for IoT and big data', 'artificial intelligence applications', and 'superconnection-based IoT devices'., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201810866006526,","Title: Artificial Intelligence in a historical perspective, Abstract: The paper tells the story of the beginnings of Artificial Intelligence (AI) as a scientific venture from a European perspective. The story is embedded into three main steps of history. In view of a sustainable future of our globe it is deemed necessary to vigorously advance the initiated third step. Assuming AI's due role in this process would mean a change in its long-term goal: enhancing rather than simulating human intelligence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67561805,","Title: ARTIFICIAL INTELLIGENCE IN TRANSITION, Abstract: In the past fifteen years artificial intelligence has changed from being the preoccupation of a handful of scientists to a thriving enterprise that has captured the imagination of world leaders and ordinary citizens alike. While corporate and government officials organize new projects whose potential impact is widespread, to date few people have been more affected by the transition than those already in the field. The author reviews some aspects of this transition, and poses some issues for AI researchers, developers, and leaders., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART18102261,","Title: Artificial intelligence-driven radiomics: developing valuable radiomics signatures with the use of artificial intelligence, Abstract: AbstractThe advent of radiomics has revolutionized medical image analysis, affording the extraction of high dimensional quantitative data for the detailed examination of normal and abnormal tissues. Artificial intelligence (AI) can be used for the enhancement of a series of steps in the radiomics pipeline, from image acquisition and preprocessing, to segmentation, feature extraction, feature selection, and model development. The aim of this review is to present the most used AI methods for radiomics analysis, explaining the advantages and limitations of the methods. Some of the most prominent AI architectures mentioned in this review include Boruta, random forests, gradient boosting, generative adversarial networks, convolutional neural networks, and transformers. Employing these models in the process of radiomics analysis can significantly enhance the quality and effectiveness of the analysis, while addressing several limitations that can reduce the quality of predictions. Addressing these limitations can enable high quality clinical decisions and wider clinical adoption. Importantly, this review will aim to highlight how AI can assist radiomics in overcoming major bottlenecks in clinical implementation, ultimately improving the translation potential of the method., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART135159628,","Title: Artificial intelligence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART20606948,","Title: Artificial Intelligence in Neuroimaging: Clinical Applications, Abstract: Artificial intelligence (AI) powered by deep learning (DL) has shown remarkable progress in image recognition tasks. Over the past decade, AI has proven its feasibility for applications in medical imaging. Various aspects of clinical practice in neuroimaging can be improved with the help of AI. For example, AI can aid in detecting brain metastases, predicting treatment response of brain tumors, generating a parametric map of dynamic contrast-enhanced MRI, and enhancing radiomics research by extracting salient features from input images. In addition, image quality can be improved via AI-based image reconstruction or motion artifact reduction. In this review, we summarize recent clinical applications of DL in various aspects of neuroimaging., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002821818,","Title: Artificial Intelligence and William Butler Yeats, Abstract: William Butler Yeats’s and George Hyde-Lees’s automatic writing offers great turning points in Yeats’s poetics. Before his automatic writing, Yeats’s poems were mainly based on Ireland and his love, such as Irish culture and history and his love for Maud Gonne. But with automatic writing his poetics was extended into the history and culture of the world and the Universe. Moreover, Yeats and his wife’s automatic writing is similar to the condition of superintelligence. This paper compares and analyzes similarities between the Yeatses’ automatic writing and the condition of superintelligence of artificial intelligence and tries to trace and compare his ideas and the condition in his poems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002804250,","Title: Engineering artificial intelligence, Abstract: Current Artificial Intelligence can be used to good effect in engineering systems for emulating some high-level mental functions of humans but is not suitable for coping with many other difficult tasks, especially those involving combined perception and cognition. Neural-net computing on the other hand seems to be better suited to meeting the demands of those types of tasks. These matters are discussed in this paper and it is suggested that the type of Artificial Intelligence appropriate for use in an engineering system will be an evolved one combining the strengths of symbolic processing and neural-net computing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16562453,","Title: Understanding the Structure of Artificial Intelligence Conscience, Abstract: Purpose This study aims to construct a structure for application to artificial intelligence by analyzing the characteristics of conscience that act as an element of moral behavior. It focuses on enhancing understanding of the structure of artificial intelligence conscience and providing insights for future development of conscience algorithms. Method This study examines in detail the academic concepts and structural properties of conscience. Reviewing the academic literature and the latest data, we propose the structure of artificial intelligence conscience. Results Through the phrase, we found that in order to construct the conscience of artificial intelligence, an algorithm must be constructed by considering the cognitive and emotional aspects. And in the process of constructing an artificial intelligence conscience algorithm, we confirmed that differentiated characteristics should be reflected depending on the situation and the object. Conclusion The value judgment of artificial intelligence is already being realized on universal standards. At the AGI level, in order to achieve value judgment, an algorithm that reflects conscience must be constructed to be close to human value judgment. For this, it is necessary to construct data and algorithms on the situation of value judgment and the relationship with the object., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003173924,","Title: Measuring Intelligence in Natural and Artificial Systems, Abstract: A systematic understanding of the relationship between intelligence and consciousness can only be achieved when we can accurately measure intelligence and consciousness. In other work, I have suggested how the measurement of consciousness can be improved by reframing the science of consciousness as a search for mathematical theories that map between physical and conscious states. This paper discusses the measurement of intelligence in natural and artificial systems. While reasonable methods exist for measuring intelligence in humans, these can only be partly generalized to non-human animals and they cannot be applied to artificial systems. Some universal measures of intelligence have been developed, but their dependence on goals and rewards creates serious problems. This paper sets out a new universal algorithm for measuring intelligence that is based on a system&rsquo;s ability to make accurate predictions. This algorithm can measure intelligence in humans, non-human animals and artificial systems. Preliminary experiments have demonstrated that it can measure the changing intelligence of an agent in a maze environment. This new measure of intelligence could lead to a much better understanding of the relationship between intelligence and consciousness in natural and artificial systems, and it has many practical applications, particularly in AI safety. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114737671,","Title: Logic and artificial intelligence, Abstract: The theoretical foundations of the logical approach to artificial intelligence are presented. Logical languages are widely used for expressing the declarative knowledge needed in artificial intelligence systems. Symbolic logic also provides a clear semantics for knowledge representation languages and a methodology for analyzing and comparing deductive inference techniques. Several observations gained from experience with the approach are discussed. Finally, we confront some challenging problems for artificial intelligence and describe what is being done in an attempt to solve them., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323583,","Title: Information retrieval and artificial intelligence, Abstract: AbstractThis paper addresses the relations between information retrieval (IR) and AI. It examines document retrieval, summarising its essential features and illustrating the state of its art by presenting one probabilistic model in detail, with some test results showing its value. The paper then analyses this model and related successful approaches, concentrating on and justifying their use of weak, redundant representation and reasoning. It goes on to other information management tasks and considers how the concepts and methods developed for retrieval may be applied to these, concluding by arguing that such ways of dealing with information may also have wider relevance to AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART08255400,","Title: What's Humanity for Artificial Intelligence Jindo Intelligence &#x2014; Dawning of Artificial Intelligence &#x2014;, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76661538,","Title: Application of artificial intelligence in hypertension, Abstract: Hypertension is an important modifiable risk factor for morbidity and mortality associated with cardiovascular disease. The incidence of hypertension is increasing not only in Korea but also in many Western countries due to the aging of the population and the increase in unhealthy lifestyles. However, hypertension control rates remain low due to poor adherence to antihypertensive medications, low awareness of hypertension, and numerous factors that contribute to hypertension, including diet, environment, lifestyle, obesity, and genetics. Because artificial intelligence (AI) involves data-driven algorithms, AI is an asset to understanding chronic diseases that are influenced by multiple factors, such as hypertension. Although several hypertension studies using AI have been published recently, most are exploratory descriptive studies that are often difficult for clinicians to understand and have little clinical relevance. This review aims to provide a clinician-centered perspective on AI by showing recent studies on the relevance of AI for patients with hypertension. The review is organized into sections on blood pressure measurement and hypertension diagnosis, prognosis, and management. Graphical Abstract, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003078226,","Title: Artificial Intelligence Tools for Undergraduate Students, Abstract: Background: The rate at which technology is adopted in the education sector is rapid. More so, artificial intelligence is gaining wide adoption as it aims to enhance the learning outcomes of students. The purpose of the current research paper was to find out the best artificial intelligence tools for undergraduate students that may be used to enhance their learning results and also discover what students use AI tools for. Method: The purpose was achieved by adopting a survey design to collect data that was analyzed statistically using percentages and pie charts. Findings: The study found out that undergraduate students use ChatGPT, Grammarly, Meta AI, ELSA Speak, Notion AI, BlackBox, Tome.APP, Tabnine, Microsoft Copilot, Perplexity, AI Notes, Phatomath, Midjourney, StarryAI, Murf, Runway, Copy.AI, Durable or Soundful in their learning process. Such AI tools help them gain a better understanding of the topics related to their study, do assignments, create content faster, write a certain piece of content, get feedback on a given content, and do its translation. The AI tools also organize tasks, review answers, and instruct how to go about answering given tasks. Conclusion and Recommendation: The use of numerous AI tools by undergraduate students enhances learning. The upscaling of AI tool usage requires universities to focus their efforts on integrating AI into their curricula and offering regular training sessions, and workshops. They should also foster continuous research and development in AI and continuous monitoring and evaluation of AI tools and their impact on the performances of students., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202510536006489,","Title: Artificial intelligence, Abstract: AbstractArtificial intelligence (AI) is the Science and Engineering domain concerned with the theory and practice of developing systems that exhibit the characteristics we associate with intelligence in human behavior. Starting with a brief history of artificial intelligence, this article presents a general overview of this broad interdisciplinary field, organized around the main modules of the notional architecture of an intelligent agent (knowledge representation; problem solving and planning; knowledge acquisition and learning; natural language, speech, and vision; action processing and robotics) which highlights both the main areas of artificial intelligence research, development and application, and also their integration. WIREs Comput Stat 2012, 4:168-180. doi: 10.1002/wics.200This article is categorized under: Software for Computational Statistics > Artificial Intelligence and Expert Systems, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80927998,","Title: Synthesizing cellular intelligence and artificial intelligence for bioprocesses, Abstract: AbstractMicrobial processes operated under realistic conditions are difficult to describe by mechanistic models, thereby limiting their optimization and control. Responses of living cells to their environment suggest that they possess some &ldquo;innate intelligence&rdquo;. Such responses have been modeled by a cybernetic approach. Furthermore, the overall behavior of a bioreactor containing a population of cells may be described and controlled through artificial intelligence methods. Therefore, it seems logical to combine cybernetic models with artificial intelligence to evolve an integrated intelligence-based strategy that is physiologically more faithful than the current approaches. This possibility is discussed, together with practical considerations favoring a hybrid approach that includes some mathematical modeling., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART27398607,","Title: Classification of Beef by Using Artificial Intelligence, Abstract: This paper aims to develop an application that classifies the quality of beef via Artificial Intelligence technology, which has experienced rapid technological growth in recent years. The application will allow users to obtain information including, but not limited to, cuts of beef, freshness, and marbling of the beef they are about to purchase. Deep learning image classification was used to classify the cuts of beef, and OpenCV technology was used to determine the freshness and marbling of the beef. The application was developed in a client-server system for real-time action. The mobile phone of the user (the client) will take a photo of the beef and send it to the server, and the server will analyze the received image to identify and determine the cuts of beef, freshness, and marbling of the beef. The results will then be sent back to the client from the server. Artificial Intelligence technology is used to develop applications with these functions. Image classification technology is used for the classification function of beef parts, and OpenCV's clustering technology is used to determine the freshness and marbling grade of beef. Also, Flask web server is used to apply the client-server structure. The developed system worked well for tenderloin, sirloin, and ribs. It provided high confidence over 75% for these cuts. However, it worked poor for other beef cuts. This is simply a learning problem for image classifiers., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117816967,","Title: Artificial intelligence and robotics, Abstract: Since Robotics is the field concerned with the connection of perception to action, Artificial Intelligence must have a central role in Robotics if the connection is to be intelligent. Artificial Intelligence addresses the crucial questions of: what knowledge is required in any aspect of thinking; how should that knowledge be represented; and how should that knowledge be used. Robotics challenges AI by forcing it to deal with real objects in the real world. Techniques and representations developed for purely cognitive problems, often in toy domains, do not necessarily extend to meet the challenge. Robots combine mechanical effectors, sensors, and computers. AI has made significant contributions to each component. We review AI contributions to perception and reasoning about physical objects. Such reasoning concerns space, path-planning, uncertainty, and compliance. We conclude with three examples that illustrate the kinds of reasoning or problem-solving abilities we would like to endow robots with and that we believe are worthy goals of both Robotics and Artificial Intelligence, being within reach of both., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART16323871,","Title: Digital Skills, Transmedia, and Artificial Intelligence, Abstract: Communication has been the basis for “key competencies” in every period of history. In the digital age, these competencies cross over lines of disciplines, modalities, approaches, media, and platforms. This paper shows the evolution of communicative competences, and explores the ramifications of the fourth industrial revolution, also known as Industry 4.0, for teaching and learning. In this revolutionary era, transmedia connects directly with changing educational needs, not only to help students learn to use tools driven by artificial intelligence, but to live in a world where we will be communicating with these agents in hybrid communities that include human and digital agents alike. The author approaches the role of the teacher in guiding students through this complex learning space, where plurilingualism and interculturality are prerequisites for success, and offers two simple activities that are easy to reproduce in the classroom that call upon emerging technologies. The activities present different learning situations that integrate reflection about technology and society while building language competencies. The paper also looks at content, its delivery, data and metadata, and the implications for a better world built on the principles of the Sustainable Development Goals (SDG’s) for 2030 enacted in 2015 by the United Nations (UN)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002526105,","Title: Artificial Intelligence, Abstract: The field of artificial intelligence is reviewed. The work of George Stiny and myself on design and criticism is discussed briefly in terms of a paradigm of artificial intelligence research. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104653659",9,1.1859924140007934,"**제목: 인공지능 정의 내재된 지능, 뇌, 컴퓨터 모의 간 논쟁적 쟁점 분석**

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 컴퓨터과학자들이 제안한 인공지능 정의에 내재된 지능, 뇌, 컴퓨터 모의 사이의 논쟁적 쟁점을 분석합니다.  문서들은 인공지능의 다양한 측면, 특히 사용자 경험, 응용 분야, 그리고 인공지능 시대의 역사적 성찰을 다루고 있으나,  컴퓨터과학자들의 인공지능 정의에 대한 직접적인 논의는 포함하지 않습니다. 따라서, 제공된 문서의 내용을 바탕으로 인공지능의 본질에 대한 암묵적인 논쟁적 쟁점들을 추론하여 분석합니다.


**본론:**

제공된 문서들은 인공지능의 기능과 한계, 그리고 그에 대한 인간의 경험을 다양한 각도에서 조명합니다.  문서 1은 인공지능 기반 대화형 서비스의 사용자 경험을 유용성, 사용성, 감성 차원에서 분석하며,  인공지능이 대화의 맥락을 제대로 파악하지 못해 사용자 기대를 충족시키지 못하는 현실적 한계를 지적합니다. 이는 인공지능이 인간의 지능과 동일한 수준으로 사고하고 학습하는 데에는 여전히 한계가 있음을 시사합니다.  인간의 지능을 컴퓨터로 모의하려는 시도가 완벽하지 않다는 점을 보여주는 것입니다.

문서 2는 메타버스 플랫폼에서의 인공지능 기반 메이크업 기능을 제안합니다.  이는 인공지능 기술이 특정한 기능을 모사하는 데에는 성공적일 수 있지만,  인간의 창의성이나 감각적인 판단력까지 완벽하게 재현하는 것은 아직 어렵다는 점을 암시적으로 보여줍니다.  컴퓨터가 인간의 뇌와 같은 방식으로 창조적 기능을 수행할 수 있는지에 대한 의문을 제기합니다.

문서 3은 초등 컴퓨터 교육 과정에 컴퓨터 과학을 도입할 것을 제안하면서 기존의 소프트웨어 기능 학습 중심 교육의 한계를 지적합니다.  이는 단순한 기능 수행을 넘어,  인간의 사고 과정과 유사한 논리적 사고와 문제 해결 능력을 함양하는 인공지능 개발의 어려움을 간접적으로 보여줍니다.  컴퓨터가 인간의 뇌와 같은 추론 능력을 갖추는 것이 얼마나 어려운지를 시사합니다.

문서 4는 인공지능 시대의 역사의 역할을 고찰합니다.  급변하는 지식 환경 속에서 인간은 과거의 경험에서 무엇을 배울 수 있는지 질문하며,  인공지능 시대에 역사가 존재해야 하는 이유를 탐구합니다.  이는 인공지능이 인간의 지능을 뛰어넘는 시대에도 인간의 경험과 지혜를 담은 역사의 중요성을 강조하며,  인간의 지능과 컴퓨터 모의 간의 차이점, 즉 인간 고유의 경험과 지혜가 컴퓨터 모의로 완전히 대체될 수 없는 부분이 존재함을 시사합니다.

문서 5는 인공지능 학습 데이터의 효율적인 활용 방법을 연구합니다.  인공지능의 성능 향상을 위해서는 방대한 데이터가 필요하지만,  데이터 확보의 어려움과 효율적인 활용의 필요성을 강조합니다. 이는 인공지능의 발전이 데이터의 양과 질에 크게 의존적이라는 것을 보여주는 동시에,  인간의 뇌가 데이터에 의존하지 않는 다양한 학습 방식을 갖고 있음을 암시적으로 비교합니다.


**결론:**

제공된 문서들을 종합적으로 분석해 볼 때, 컴퓨터과학자들이 제안한 인공지능 정의에 내재된 논쟁적 쟁점은 인간의 지능과 뇌의 복잡성을 컴퓨터가 얼마나 정확하게 모의할 수 있는가에 대한 것입니다. 문서들은 인공지능이 특정 기능은 모사할 수 있지만,  인간의 창의성, 감성,  맥락 이해, 추론 능력, 그리고  인간 고유의 경험과 지혜까지 완벽하게 재현하는 데에는 한계가 있음을 다양한 측면에서 보여줍니다.  이는 지능, 뇌, 컴퓨터 모의 간의 본질적인 차이와 그 한계에 대한 끊임없는 논의가 필요함을 시사합니다.  인공지능은 인간의 지능을 보완하고 증강하는 도구로서의 역할에 집중해야 할 필요성을 강조합니다.",인공지능 기반 대화형 인터랙션에 대한 사용자 경험 연구,메타버스 디지털 플랫폼의 메이크업 기능 제안 - 제페토를 중심으로 -,컴퓨터과학 도입을 위한 초등컴퓨터 교육과정 연구,"인공지능 시대 “Historia, Quo Vadis?”",인공지능 학습데이터의 효율적인 활용방법에 관한 연구,人工知能에서 不確實性 管理 技法의 必須要件 分析,컴퓨터과학교육을 위한 중학교 컴퓨터교육과정 연구,컴퓨터과학 도입을 위한 초등컴퓨터 교육과정 연구,미세먼지 자료동화 및 통합예보모형 개발연구,인공장기 이식과 개발에 관한 비판적 연구,인공지능에 관한 법적 규율방안 : - 인공지능 알고리즘과 빅데이터의 법적규율을 중심으로 -,인공신경망 이론을 이용한 팽창지수 예측,인공습지 증설에 따른 유역 수질개선 효과 분석,인공지능 인사담당자와 인간 인사담당자에 대한 잠재적 입사지원자들의 인식 비교 연구,컴퓨터 바이오과학과 바이오 컴퓨터과학,생명과학과 컴퓨터과학,실리콘밸리의 컴퓨터과학 방과후 교육 운영 실태,"통합에서 독립으로, 이스라엘 컴퓨터과학 교과의 진화","통합에서 독립으로, 이스라엘 컴퓨터과학 교과의 진화",[컴퓨터 과학 산책]<컴퓨터이론> 小考</컴퓨터이론>,제안서에 나타난 레이아웃 유형과 시각적 중심에 관한 연구 : 데이터정보 전달 위주의 제안서 중심으로,자격검정제도의 제안,창의적 문제해결력 신장을 위한 초등정보재량활동 교육자료 개발,소송비용제도의 개선에 관한 제안,기독교교육과 커리큘럼의 진단과 제안－A 대학교 기독교교육과 사례를 중심으로－,Digital Genealogy Design,PMSM 설계 프로세스 제안,염색 기법을 응용한 넥타이 디자인 제안,VE제안 유형의 제도적 다양화 및 범위기준 제안,한국 문화교육으로 태권도 사상 고찰과 제안,,,,,,,,,,,,,,,,,,,,
"How would you summarize the proposed enabling framework for achieving the second Sustainable Development Goal, emphasizing the role of data sharing and near real-time analytics?","##Enabling Data-Driven Framework for SDG2## ##Introduction## This framework addresses the urgent goal of eradicating hunger and securing safe, nutritious food for all by outlining a connected platform that spans the entire food network. It builds on the Sustainable Development Solutions Network’s recommendation for a generic enabling mechanism adaptable to any country’s development status. ##Main Body## At its core, the framework establishes clear information flows and feedback loops among farmers, suppliers, policymakers, researchers, and consumers to coordinate interventions across production, distribution, and consumption. Free exchange of data—ranging from crop yields and market prices to nutritional indicators—is coupled with near real-time analytics to detect emerging risks, optimize resource allocation, and guide policy decisions. The incorporation of IoT sensors and Big Data technologies ensures continuous monitoring of environmental conditions, supply chain performance, and food safety metrics. Case studies illustrate how rapid data sharing and analytics have enhanced responsiveness in both developing and western economies, improving resilience against climate shocks, price volatility, and supply disruptions. ##Conclusion## By leveraging open data and instantaneous analytics, this enabling framework creates a dynamic, knowledge-driven environment essential for achieving SDG2’s vision of a hunger-free, sustainable, and equitable global food system.",없음,없음,"Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",10,1.1859924140007934,"**Title:** Enabling Frameworks for Achieving SDG 2: A Focus on Data Sharing and Near Real-Time Analytics

**Introduction:**

The second Sustainable Development Goal (SDG 2) focuses on ending hunger, achieving food security and improved nutrition, and promoting sustainable agriculture.  Achieving this goal necessitates a multifaceted approach, including efficient resource allocation, effective policy implementation, and proactive responses to emerging challenges.  This report examines potential enabling frameworks for achieving SDG 2, with a particular emphasis on the crucial roles of data sharing and near real-time analytics.  The analysis is based on the provided documents, which offer insights into sustainable development strategies across various sectors.

**Body:**

While none of the provided documents directly address a specific framework for SDG 2,  several offer relevant perspectives. Document 2, ""Analysis of Sustainable Health Development in Indonesia (Sustainable Development Goal's),"" highlights the significant challenges faced by governments in addressing health issues, including malnutrition. The lack of efficient regulations and resources underscores the need for improved data collection and analysis to inform effective policy interventions.  Effective resource allocation and efficient policymaking, vital for SDG 2, hinge on access to comprehensive and timely data.

Document 1, ""Are Smart Cities Sustainable? Toward the Integration of the Sustainable and Smart City,"" emphasizes the importance of integrating sustainability pillars (economic, environmental, and social) with good governance for urban development.  Applying this to SDG 2, a sustainable food system requires comprehensive data on food production, distribution, consumption, and waste. Real-time data on crop yields, market prices, and nutritional intake can inform targeted interventions to prevent food insecurity and malnutrition.  The effective use of such data requires robust data sharing mechanisms and the capability for near real-time analysis.

Document 3, ""How the 'What' Becomes the 'How',"" discusses systems for opportunistic service access in dynamic environments.  This concept is transferable to the context of SDG 2.  A system that can dynamically adjust food aid distribution based on real-time data on need, using near real-time analytics to predict future needs and preemptively address potential crises, would represent a highly effective approach.  Such a system requires integrated data sharing between various stakeholders, including government agencies, NGOs, and agricultural producers.

Document 4, ""Can Education for Sustainable Development Change Entrepreneurship Education to Deliver a Sustainable Future?"", highlights the importance of education in achieving sustainable development goals.  In the context of SDG 2, educating farmers about sustainable agricultural practices and providing access to market information through data sharing platforms can empower them to improve their livelihoods and contribute to food security.  Near real-time analytics can help identify areas for improved efficiency and resource allocation within the agricultural sector.

**Conclusion:**

While no single document provides a complete framework for achieving SDG 2, the provided texts collectively suggest a vital role for data sharing and near real-time analytics.  An enabling framework should encompass robust data collection mechanisms, secure and transparent data sharing platforms, and sophisticated analytical tools to facilitate timely and effective decision-making.  This data-driven approach should inform targeted interventions to improve agricultural practices, enhance food distribution networks, address nutritional deficiencies, and promote sustainable food systems, ultimately contributing to the achievement of SDG 2.  The integration of these technological capabilities with good governance and education, as suggested in multiple documents, is crucial for sustainable and equitable outcomes.",Are Smart Cities Sustainable? Toward the Integration of the Sustainable and Smart City,Analysis Of Sustainable Health Development In Indonesia (Sustainable Development Goal's),How the 'What' Becomes the 'How',Can Education for Sustainable Development Change Entrepreneurship Education to Deliver a Sustainable Future?,25 Years of HOW: A Celebration of Language Teaching and Learning,Does Proposed CESL Still Matter?,Understanding the Role of National Development Experts in Development Ethnography,"Putting the Goal Back into Grit: Academic Goal Commitment, Grit, and Academic Achievement",Quality Management System Proposed to JENDL Evaluation Project,Mainstream economics and economic crises: how responsible? how reformable?,How do we know how?,Sustainable Buildings - or Sustainable Cities?,Sustainable Professional Sports Facilities,Making sustainable development sustainable,Sustainable development vs. sustainable redevelopment,Sustainable Development and the SDGs: A Note on Current Development,Articulating Uneven Regional Development: artificial intelligence as a tool in development planning,Neonatal drug development,Post-Development Alternative Ideas Regarding Saemaul Rural Development as an International Development Practice,"Regionalism in the Asia-Pacific Region: How Wide, How Deep?",Towards the sustainable city,Towards sustainable product development,Human pancreas development,DEVELOPMENT - Principles for integral human development in,An assessment of goal-free evaluation: Case studies of four goal-free evaluations,The effects of goal orientation on goal pursuit,Goal motives and multiple-goal striving in sport and academia: A person-centered investigation of goal motives and inter-goal relations,"Goal Missed, Self Hit: Goal-Setting, Goal-Failure, and Their Affective, Motivational, and Behavioral Consequences",Proposed Architecture for U-Healthcare Systems,A Proposed Technique for Gray Image Colorization,Unconflicted Goal Striving : Goal Ambivalence as a Mediator Between Goal Self-Concordance and Well-Being,When goals loom darker: Goal ambivalence moderates the effect of goal proximity on goal&#x2010;related motivation,"The Procedural Syllabus and the Task Syllabus: How Similar, How Different?",A Strategic Model Proposed for Formulating the Christian Culture,Sustainable Buildings with Their Sustainable Facades,Transport aircraft requirements - How much? How soon? How to pay?,An undergraduate rootkit research project : How available? How hard? How dangerous?,HOW TO CHEAT,Science in space- How pure - How pragmatic,목표지향성(Goal Orientation)이 구성원의 태도에 미치는 영향에 관한 연구,Proposed MENC Constitutional Revisions : Proposed Revisions,Proposed,Proposed,Proposed legislation,Proposed Amendment,Osuzuyama Distillery,Welding Visual Monitoring System,iLS-YC Series IHI-YAG Laser System,Goal-Pareto 기반의 NSGA 최적화 알고리즘,Goal Programming을 이용한 홍수기 저수지 최적 운영
Can you outline the main advances and challenges in applying artificial intelligence and Big Data to medical imaging in neurology?,"##Artificial Intelligence and Big Data in Neurology## ##Introduction## Recent technological developments have enabled the collection and analysis of vast amounts of clinical and imaging data in neurology. These resources—including electronic health records, population registries, and advanced neuroimaging databases—offer unprecedented opportunities to enhance diagnosis and treatment of neurological disorders. ##Main Body## Key advances include the deployment of machine learning models that automate lesion detection and segmentation on MRI and CT scans, improving both speed and consistency compared to manual interpretation. Deep learning frameworks have demonstrated high accuracy in classifying complex patterns associated with stroke, multiple sclerosis, Alzheimer’s disease, and other conditions, leveraging convolutional neural networks trained on large annotated datasets. Integration of real-world data (RWD) and multi-modal analytics has supported the development of predictive models for disease progression and treatment response, while large-scale collaborative initiatives are standardizing data formats and promoting federated learning to protect patient privacy. Despite these successes, challenges persist: variability in image acquisition protocols compromises model generalizability, data heterogeneity and missing labels hamper robust training, and ensuring data quality and provenance remains difficult. Ethical concerns around informed consent, algorithmic bias, and data security further complicate deployment in clinical settings, and regulatory frameworks are still evolving to address accountability and transparency of AI‐driven decisions. ##Conclusion## Artificial intelligence and Big Data analytics are transforming medical imaging in neurology by enabling more accurate, efficient, and personalized care, yet overcoming data quality issues, ethical considerations, and implementation barriers is essential to fully realize their clinical potential.",없음,없음,"Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",11,1.1859924140007934,"**Title:** Advances and Challenges in Applying Artificial Intelligence and Big Data to Medical Imaging in Neurology: A Review Based on Provided Documents

**Introduction:**

This report addresses the advances and challenges in applying artificial intelligence (AI) and Big Data to medical imaging in neurology, based solely on the provided documents.  While the provided texts do not directly address neurological imaging, they offer insights into the application of AI and Big Data in other medical fields, which can be extrapolated to inform the discussion.

**Body:**

The provided documents highlight several advancements in AI and Big Data applications within medicine, although not specifically in neurological imaging.  Document 3, focusing on keratoconus diagnosis and treatment, showcases the significant role of AI in enhancing diagnostic efficiency and guiding treatment.  It explicitly states that ""Artificial intelligence has been exploited in a multitude of ways to enhance diagnostic efficiency and to guide treatment,"" demonstrating AI's capacity to improve medical decision-making processes.  This suggests a similar potential for AI in neurological imaging, where AI algorithms could analyze medical images (like MRIs or CT scans) to detect anomalies and assist in diagnosis.

Furthermore, the use of Big Data is implied in several documents.  Document 1 emphasizes the importance of ""the availability and free exchange of data, together with near real-time analytics"" for achieving sustainable development goals, including improvements in healthcare.  Document 4 highlights the challenges of storing and querying large RDF datasets, noting the cost implications of processing large amounts of data related to healthcare information. This suggests that handling the vast amounts of data generated by neuroimaging technologies requires efficient data management and storage solutions like those discussed in Document 4.  Document 2 discusses the use of Hadoop and MapReduce for efficient processing of large datasets from connected cars, implying that similar Big Data frameworks could be used to manage and analyze the large datasets generated by neuroimaging.

However, the provided documents do not directly address the specific challenges related to applying AI and Big Data to neurological imaging.  Challenges could potentially include: the need for high-quality, labeled datasets for training AI algorithms; the computational demands of processing high-resolution neuroimages; ensuring data privacy and security; and the need for robust validation and regulatory approval of AI-based diagnostic tools.

**Conclusion:**

Based on the provided documents, the application of AI and Big Data to medical imaging shows significant promise, as evidenced by the use of AI in keratoconus diagnosis.  The successful implementation of Big Data techniques in other fields, as discussed in the context of efficient data management and processing, suggests that similar approaches could be adapted for managing and analyzing large neurological imaging datasets.  While the provided documents don't directly address the specific challenges in neurology, it is plausible to infer that common challenges in AI and Big Data applications across medicine would also apply to this domain. Further research is needed to fully understand and address the specific challenges and limitations in applying these technologies to neurological imaging.","Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal",Integration of big data for querying CAN bus data from connected car,Advances in the diagnosis and treatment of keratoconus,Efficient Dictionary Compression for Processing RDF Big Data Using Google BigQuery,How to make data migration processes more efficient by using TOGAF: Best practice data migration approach applied to SAP Financial Services-Policy Management,Recent Advances in Nuclear Cardiology,칸트의 첫째 이율배반과 대폭발 우주론,Linked Open Data (LOD) for Library Special Collections,Data center cooling management and analysis - a model based approach,Recent advances in pediatric interventional cardiology,Radiotherapy: basic principles and technical advances,History and Recent Advances in Microsurgery,Untangling Amyloidosis: Recent Advances in Cardiac Amyloidosis,Data center design of optimal reliable systems,The hand: Embryology and main malformative mechanisms,Les greffons osseux vascularis&#x00E9;s p&#x00E9;dicul&#x00E9;s pr&#x00E9;lev&#x00E9;s sur la main et le poignet : revue de la litt&#x00E9;rature et nouveau site donneur,Jaccoud&apos;s arthropathy,"Main coup&eacute;e, main errante, main absente : All&eacute;gorie r&eacute;elle de la Grande Guerre",La main spastique psychog&egrave;ne,Harmony Mechanism Between Main Productive Region and Main Sale Region,Advances in stochastic simulation of Hydrology,Recent advances in dairy goat products,AL amyloidosis: advances in diagnosis and management,Plant Molecular Phylogeography and Its Research Advances,Non-Random CAN Fuzzing을 통한 효율적인 ECU 분석 기술,Data mining 기법을 이용한 자동차보험 손해율 분석,TCP/IP 상에서 CAN 데이터 프레임 송수신이 가능한 가상 CAN 버스 소프트웨어의 구현,Big-BOE: Fusing Spanish Official Gazette with Big Data Technology,효율적 데이터 마이닝 분석을 위해 특정 도메인 별 다량의 축적 데이터집합에 대한 데이터 중심 관리 기법 연구,Top Bracing을 이용한 선박엔진의 진동방진에 관한연구,Syndromes canalaires r&#x00E9;v&#x00E9;l&#x00E9;s &#x00E0; la main,FreeRTOS상에서의 CAN통신 보안 설계,FPGA 기반 CAN Spoofing 공격 탐방지 장치,The Big Student Big Data Grab,Tendinopathies de la main et du poignet,Permis de conduire et chirurgie de la main,CAN 통신을 이용한 차량 상태 모니터링 시스템 개발,CAN Protocol을 이용한 CAN 통신 시스템 설계 및 구현,CAN 네트워크에서의 Starvation Free 프로토콜,차량용 CAN-FD 제어기의 구현 및 검증,Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로,DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구,Why Big Data = Big Deal,"CAN, CAN FD, FlexRay를 이용한 자동차용 진단시스템에 관한 연구",키워드 검색 지원을 위한 확장 CAN 메커니즘,BIG6 모형을 적용한 국어과 도서관협력수업이 정보활용 태도에 미치는 영향,Big6 Skills 모형을 이용한 정보활용수업이 정보활용능력과 비판적 사고력에 미치는 영향,,,
What is the primary argument regarding the environmental impact of Big Data initiatives and the ethical considerations tied to data’s material presence?,"## Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives ## ## Introduction## Big Data projects often emphasize analytical capabilities while neglecting the environmental and ethical consequences of the physical infrastructures they require. Recognizing data’s materiality—servers, storage facilities, and energy consumption—is crucial to understanding the full impact of digital expansion. ## Main Body## The argument centers on three ethical concerns: first, the terminology used in data governance can obscure the environmental costs of data storage and processing; second, there is a growing tension between the rapid deployment of data centers and the goals of environmental policy aimed at reducing carbon footprints; third, unequal distribution of the ecological burdens—such as land use, energy demand, and electronic waste—raises questions of fairness and social justice. By drawing on perspectives from environmental studies and Science and Technology Studies, the authors show how the “immaterial” rhetoric of Big Data masks its concrete resource demands and spatial footprint. They advocate for a shift in governance vocabulary, alignment of data initiatives with sustainability regulations, and equitable sharing of environmental responsibilities. ## Conclusion## Acknowledging data’s physical presence and its environmental ramifications is essential for developing more sustainable, ethically informed practices in data storage, production, and governance.",없음,없음,"Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",12,1.1859924140007934,"**Title:** The Environmental Impact and Ethical Considerations of Big Data Initiatives: An Analysis Based on Provided Documents

**Introduction:** This report addresses the primary argument regarding the environmental impact of Big Data initiatives and the ethical considerations tied to data's material presence, based solely on the provided documents.  The analysis focuses on the implications of Big Data in various sectors, exploring the interplay between technological advancements, resource consumption, and ethical responsibilities.

**Body:**

The provided documents do not explicitly present a single, unified argument regarding the environmental impact of Big Data. However, they reveal several interconnected aspects that contribute to a nuanced understanding of the issue.  Document 4, ""Data center cooling management and analysis - a model based approach,"" highlights a significant environmental concern: the substantial energy consumption of data centers.  It emphasizes that cooling facilities alone can account for up to half of a data center's total energy consumption, directly impacting its carbon footprint. This underscores the environmental cost associated with the physical infrastructure required to support Big Data operations.

Document 3, ""Efficient Dictionary Compression for Processing RDF Big Data Using Google BigQuery,"" indirectly addresses the environmental impact by focusing on optimizing data storage and processing. The authors present a method to reduce the storage and query costs of RDF big data by employing efficient dictionary compression. This suggests that improvements in data management techniques can mitigate some of the environmental pressures associated with the sheer volume of data.  The implication is that more efficient data handling translates to lower energy needs and consequently, a smaller environmental footprint.

Document 1, ""Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal,"" frames Big Data within the context of achieving the second Sustainable Development Goal (SDG2), which aims to ""eradicate hunger, achieve food security and improved nutrition and promote sustainable agriculture.""  While not directly addressing the environmental impact of Big Data itself, the document highlights the potential of data-driven innovation to improve food production and distribution.  This suggests a potential for Big Data to contribute positively to environmental sustainability by optimizing resource allocation and reducing waste within the food system. However, the implementation of such initiatives presents challenges in terms of data availability, exchange, and real-time analytics, underscoring the need for careful planning and consideration of potential negative consequences.

The documents do not directly address the ethical considerations tied to data's material presence. While Document 2, ""Integration of big data for querying CAN bus data from connected car,"" and Document 5, ""How to make data migration processes more efficient by using TOGAF: Best practice data migration approach applied to SAP Financial Services-Policy Management,"" deal with data management and migration, they primarily focus on efficiency and process optimization rather than the ethical implications of data collection and storage.

**Conclusion:**

The provided documents reveal a complex picture of the environmental impact and ethical considerations surrounding Big Data initiatives.  The significant energy consumption of data centers is a clear environmental concern.  However, the potential for Big Data to contribute to environmental sustainability through optimized resource management and improved efficiency in sectors like agriculture is also suggested.  The ethical implications of data's material presence are not directly addressed in these documents.  Further research is needed to fully explore and articulate the complex interplay between the environmental and ethical dimensions of Big Data.  The documents primarily focus on the technological and logistical aspects of managing and utilizing Big Data, leaving the broader societal and environmental consequences largely implicit.","Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal",Integration of big data for querying CAN bus data from connected car,Efficient Dictionary Compression for Processing RDF Big Data Using Google BigQuery,Data center cooling management and analysis - a model based approach,How to make data migration processes more efficient by using TOGAF: Best practice data migration approach applied to SAP Financial Services-Policy Management,What do Primary Teachers Think about English Vocabulary Taught in Primary Schools?,The Primary Imagination Reviewed,“What-If-Not”전략을 적용한 문제 제기 활동이 학생들의 수학적 태도에 미치는 영향 : 중학교 2학년 ‘도형’ 단원을 중심으로,“What” versus “Where” in the audiovisual domain: An fMRI study,"POLITICAL CHANGES IN NORTH KOREA: WHAT IS IT, WHAT HAS HAPPENED AND WHAT TO EXPECT?",Consumer Confidence and Economic Activity: What Causes What?,칸트의 첫째 이율배반과 대폭발 우주론,Data center design of optimal reliable systems,Comparisons Between Normocalcemic Primary Hyperparathyroidism and Typical Primary Hyperparathyroidism,Argument Revision,Annotating Argument Schemes,"Negotiation, Persuasion and Argument",An Argument against the Rollback Argument,"Nephrotic syndrome: what’s new, what’s hot?",What Counts as Knowledge and What Knowledge Counts in Early Childhood Education?,Linked Open Data (LOD) for Library Special Collections,Primary-Backup 모델 기반 고가용성 웹 서버 구축,(The) Capabilities of Primary Education in Madagascar : MDG 2 on Universal Primary Education,GENERALIZED QUASI-PRIMARY RINGS,Primary Pulmonary Chordoid Meningioma,Argument a contrario,"Animacy, argument structure, and argument encoding",Bo&#x161;kovi&#x107;ev kozmolo&#x161;ki argument,"Justification, Discovery, Reason & Argument",The Big Student Big Data Grab,Big-BOE: Fusing Spanish Official Gazette with Big Data Technology,"Computational approaches to interface design : what works, what doesn't, what should and what might",효율적 데이터 마이닝 분석을 위해 특정 도메인 별 다량의 축적 데이터집합에 대한 데이터 중심 관리 기법 연구,Primary Decomposition of Monomial Ideals,可換인 環에서 Primary Spectrum의 構造에 關한 考察,Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로,DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구,Why Big Data = Big Deal,Data mining 기법을 이용한 자동차보험 손해율 분석,예비교사 교육에서 If-Not-What-Yes와 What-If-For를 통한 반례 생성과 명제의 정교화,What life? What cycle?,What Process For What Part?,BIG6 모형을 적용한 국어과 도서관협력수업이 정보활용 태도에 미치는 영향,Big6 Skills 모형을 이용한 정보활용수업이 정보활용능력과 비판적 사고력에 미치는 영향,환자중심의 Primary care team model 재구축 연구,Argument Search : Assessing Argument Relevance,결과논변과 수반논변,,,
How does the content describe the combination of phenomenological and mechanistic approaches through Big Data analytics to support personalized healthcare?,"##Integrating Empirical Insights and Mechanistic Models for Personalized Healthcare## ##Introduction## Personalized healthcare aims to tailor diagnosis and treatment to individual patients by combining two complementary modeling philosophies. Phenomenological approaches extract patterns directly from large-scale patient data, while mechanistic models build detailed, causal representations of physiological processes. Integrating these through Big Data analytics and Virtual Physiological Human (VPH) technologies offers a unified path toward in silico medicine. ##Main Body## Big Data analytics supplies the phenomenological component by uncovering correlations and trends across diverse, high-volume datasets. Mechanistic VPH models contribute causal understanding of tissue, organ, and whole-body dynamics. Neither approach stands alone; their fusion hinges on domain-specific technological advances. First, systems must securely manage and analyze sensitive, heterogeneous data—including nontextual formats—across distributed environments. Second, specialized analytics are needed to merge bioinformatics and systems biology insights with clinical observations at multiple scales. Finally, continuous data streams from daily life must be processed to delineate each patient’s “physiological envelope,” capturing normal variability and early signs of deviation. ##Conclusion## By addressing the challenges of data security, heterogeneity, distributed management, and multi-scale integration, Big Data technologies can bridge phenomenological and mechanistic paradigms. This synergy promises robust, patient-specific in silico medicine, marking a strategic priority for targeted research and funding in personalized healthcare.",없음,없음,"Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",13,1.1859924140007934,"**Title:** Big Data Analytics and Personalized Healthcare: An Analysis of Provided Documents

**Introduction:**

The original question asks how the provided documents describe the combination of phenomenological and mechanistic approaches through Big Data analytics to support personalized healthcare.  A review of the five provided documents reveals that none directly address personalized healthcare or explicitly combine phenomenological and mechanistic approaches within the context of Big Data analytics in this specific domain.  Therefore, this report will analyze the relevance of the provided documents to the broader application of Big Data analytics and its potential, though not explicitly stated, for personalized healthcare.

**Body:**

The provided documents focus on various aspects of Big Data applications, but none directly address personalized healthcare.  Document 1 discusses the application of Big Data and IoT in achieving the second Sustainable Development Goal (SDG2), focusing on improving global food security.  The document highlights the need for real-time data analytics to coordinate interventions across the food chain.  While not directly related to healthcare, this demonstrates the potential of Big Data to manage complex systems requiring diverse data sources and real-time analysis, a capability potentially transferable to personalized healthcare.

Document 2 explores the use of Big Data (Hadoop framework) to analyze data from connected cars, enhancing safety and driving experience. This exemplifies the application of Big Data to analyze high-volume sensor data to improve outcomes. This is analogous to the use of wearable sensors and other data sources in personalized healthcare.

Document 3 describes a best-practice approach to data migration using TOGAF, focusing on efficient management of complex data migration projects.  While not directly related to healthcare or analytics, this highlights the importance of robust data management infrastructure, crucial for large-scale data analysis applications such as those employed in personalized healthcare.

Document 4 discusses approaches to opportunistic service access in dynamic pervasive computing environments. While not directly concerning Big Data, this illustrates the need for flexible and adaptive systems capable of handling unpredictable changes in data availability and resource constraints, a requirement for any large-scale data analysis system such as one supporting personalized healthcare.

Document 5 presents an efficient dictionary compression algorithm for processing large RDF datasets using Google BigQuery.  This showcases the importance of efficient data storage and processing techniques for handling Big Data, which are essential for the economic and practical viability of personalized healthcare initiatives involving large-scale data analysis.

While none of the documents explicitly detail a combination of phenomenological and mechanistic approaches in personalized healthcare via Big Data, the underlying principles and technological components discussed are highly relevant.  The documents collectively demonstrate the feasibility and importance of large-scale data analysis, real-time processing, efficient data management, and flexible system design – all essential building blocks for a system supporting personalized healthcare.  The potential for Big Data analytics to incorporate both mechanistic (e.g., analyzing biomarkers) and phenomenological (e.g., patient-reported outcomes) data to tailor treatment plans is implied but not explicitly described.

**Conclusion:**

The provided documents, while not directly focused on personalized healthcare, showcase the various technologies and methodologies crucial for the successful implementation of Big Data analytics in complex systems.  The principles of efficient data management, real-time processing, and flexible system design discussed are directly applicable to the development of personalized healthcare systems. The absence of explicit discussion on the combination of phenomenological and mechanistic approaches in this context limits a definitive answer to the original question, but the foundational technological aspects are adequately covered within the presented documents.","Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal",Integration of big data for querying CAN bus data from connected car,How to make data migration processes more efficient by using TOGAF: Best practice data migration approach applied to SAP Financial Services-Policy Management,How the 'What' Becomes the 'How',Efficient Dictionary Compression for Processing RDF Big Data Using Google BigQuery,User-Created Content Recommendation Using Tag Information and Content Metadata,Linked Open Data (LOD) for Library Special Collections,Concentration and content,Predicting content consumption from content-to-content relationships,한국형 Combination Store의 패러다임에 관한 연구,Combination Radioimmunotherapy Approaches and Quantification,칸트의 첫째 이율배반과 대폭발 우주론,Data center cooling management and analysis - a model based approach,Mineral content analysis of root canal dentin using laser-induced breakdown spectroscopy,Content Validation of CALT Design Focusing on Content Balancing,Load combination in codes,On Convex Combination of Local Constant Regression,"이식형 흡수성 융복합 의료제품 규제 비교 연구 -미국, 유럽, 한국을 중심으로-",Combination Vaccines,Automatic combination of forest subcompartment polygons,Mainstream economics and economic crises: how responsible? how reformable?,25 Years of HOW: A Celebration of Language Teaching and Learning,How do we know how?,"Regionalism in the Asia-Pacific Region: How Wide, How Deep?",Data center design of optimal reliable systems,Combination vaccines against diarrheal diseases,"The Procedural Syllabus and the Task Syllabus: How Similar, How Different?",The Big Student Big Data Grab,Big-BOE: Fusing Spanish Official Gazette with Big Data Technology,Transport aircraft requirements - How much? How soon? How to pay?,HOW TO CHEAT,Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로,DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구,Why Big Data = Big Deal,효율적 데이터 마이닝 분석을 위해 특정 도메인 별 다량의 축적 데이터집합에 대한 데이터 중심 관리 기법 연구,Data mining 기법을 이용한 자동차보험 손해율 분석,세포노화에서의 mitochondrial content 증가 기전,An undergraduate rootkit research project : How available? How hard? How dangerous?,Science in space- How pure - How pragmatic,BIG6 모형을 적용한 국어과 도서관협력수업이 정보활용 태도에 미치는 영향,Big6 Skills 모형을 이용한 정보활용수업이 정보활용능력과 비판적 사고력에 미치는 영향,무선 Content-Centric Network에서 효과적인 콘텐츠 전달 방식,SUPER SCHUR FUNCTIONS의 HOOK-CONTENT 공식,Super schur functions의 hook-content 공식,Content,Combination Weigher 개발에 관한 연구,Combination syndrome 예방을 고려한 flexible IARPD 증례,,,
What are the key findings of the socio-technical evaluation on Big Data developmental processes and the factors influencing user adoption?,"##Socio-Technical Evaluation and User Adoption in Big Data Development## ##Introduction## This study examines how Big Data practices emerge, become routinized, and integrate into organizations by applying a socio-technical lens. Using Normalization Process Theory, it analyzes the interplay between technology, organizational context, and human actors in South Korea’s Big Data ecosystem. It also investigates what drives or hinders individual users from embracing Big Data tools and insights. ##Main Body## • Developmental Processes: The evaluation identifies three core mechanisms—coherence (making sense of Big Data), cognitive participation (buy-in from stakeholders), and collective action (operational work to embed new practices). It reveals that successful integration depends on clear role definitions, shared understanding of expected benefits, and alignment with existing workflows. • Implementation Challenges: Technical complexity, insufficient training, and fragmented data governance emerged as obstacles to embedding Big Data solutions. Organizational support structures, such as cross-functional collaboration and continuous feedback channels, proved critical for sustaining adoption. • User Adoption Factors: Empirical user modeling highlights two primary drivers: cognitive motivations (perceived usefulness, ease of interpretation) and individual values (trust, data privacy concerns, alignment with personal goals). Users are more likely to adopt Big Data when interfaces communicate actionable insights and respect ethical considerations. • Design Implications: The findings underscore the need for user-centered development, where end-users participate in requirement setting, iterative prototyping, and evaluation. Tailoring data visualization and analytics to users’ domain expertise significantly enhances perceived value and motivation to engage. ##Conclusion## Achieving widespread adoption of Big Data depends on attending to both socio-technical dynamics and human factors. By embedding user-centered principles throughout the developmental lifecycle—clarifying objectives, fostering stakeholder engagement, and aligning technical functionality with cognitive and ethical user needs—organizations can ensure new Big Data practices become normalized, scalable, and impactful.",없음,없음,"Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",14,1.1859924140007934,"**Title:** Socio-Technical Evaluation of Big Data Development:  Insights from  Interconnected Systems and User Adoption Factors

**Introduction:** This report analyzes the socio-technical aspects of Big Data development processes and factors influencing user adoption, based on provided research papers.  The analysis focuses on identifying key findings regarding the challenges and opportunities associated with implementing Big Data solutions within various contexts, including sustainable development goals, connected cars, and organizational systems.

**Body:**

The provided documents offer fragmented yet interconnected insights into the socio-technical landscape of Big Data.  Document 1 highlights the crucial role of Big Data and the Internet of Things (IoT) in achieving the second Sustainable Development Goal (SDG2), focusing on ensuring food security and sustainable agriculture.  The successful implementation of SDG2 requires a robust data-driven framework that facilitates the free exchange of data and near real-time analytics to support effective knowledge flows across the entire food network [Document 1].  This emphasizes the socio-technical challenge of coordinating interventions across a complex web of stakeholders and agencies, necessitating not only technological solutions but also effective collaboration and data sharing mechanisms.

Document 2 examines a specific application of Big Data in the context of connected cars.  This study focuses on efficiently processing large volumes of Controller Area Network (CAN) bus data using the Hadoop framework, enabling improved safety and driving experience [Document 2].  The successful integration of Big Data within the connected car ecosystem depends on the efficient design and implementation of MapReduce patterns for data analysis and the development of mobile applications for data collection and transfer to cloud-based data centers. The successful implementation is shown to be highly scalable compared to traditional methods [Document 2], highlighting the technological advantages of Big Data solutions.  However, the socio-technical aspects of data privacy and security are not explicitly addressed in this context.

Documents 3 and 5 address the broader socio-technical systems (STS) framework. Document 3 explores the four dimensions of successful STS within companies: knowledge management, competitiveness, corporate entrepreneurship, and HRM practices, suggesting that institutionalizing these dimensions is crucial for organizational sustainability and transformative change [Document 3].  This implicitly emphasizes the importance of aligning technological advancements with organizational goals and human factors for successful adoption. Document 5 advocates for a more technical approach within STS research, arguing for the development of a formal design language to translate socio-technical insights into effective design specifications for improved ICT systems [Document 5]. This suggests a need to bridge the gap between socio-technical understanding and technological implementation, advocating for collaboration between social scientists and technologists in the design process.  The document further proposes that the design process itself is socio-technical, highlighting the need for a holistic approach that considers the wider implications of technology deployment.

Document 4 discusses the evolution of pervasive computing, tracing three generations of research challenges: connectedness, awareness, and smartness [Document 4]. The evolution towards ""smartness"" suggests a movement towards more intelligent and context-aware systems, highlighting the increasing complexity and sophistication of socio-technical interactions within pervasive computing environments. This evolution towards a more sophisticated understanding of the interaction between technology and its environment mirrors the call for a more technical approach to STS design outlined in Document 5.


**Conclusion:**  The socio-technical evaluation of Big Data developmental processes reveals a complex interplay between technological capabilities and human factors.  Successful implementation necessitates addressing challenges across various domains, including data sharing and coordination (SDG2), efficient data processing and integration (connected cars), alignment of technology with organizational goals (corporate STS), and the development of formal design languages to translate socio-technical insights into effective technological solutions (STS design).  Ultimately, successful user adoption of Big Data solutions requires a holistic approach that integrates technological advancements with effective organizational strategies, human-centered design, and a strong consideration of ethical and societal implications.  The evolution of pervasive computing demonstrates the ongoing challenge of developing truly user-friendly, intuitive, and context-aware systems that seamlessly integrate with the human experience.","Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal",Integration of big data for querying CAN bus data from connected car,Socio Technical Systems of a Company: The Dimensionality of Socio Technical Systems,Pervasive Socio-Technical Fabric,Putting the technical back into socio-technical systems research,Data center design of optimal reliable systems,Development of socio-technical disaster model,“What-If-Not”전략을 적용한 문제 제기 활동이 학생들의 수학적 태도에 미치는 영향 : 중학교 2학년 ‘도형’ 단원을 중심으로,Consumer Confidence and Economic Activity: What Causes What?,Efficient Dictionary Compression for Processing RDF Big Data Using Google BigQuery,Linked Open Data (LOD) for Library Special Collections,Correlation of Imaging Findings with Pathologic Findings of Sclerosing Adenosis,Colonoscopy Findings: A Single Institution Study from Pakistan,Contextual inquiry and socio-technical practice,Integrating CPS into Socio-Technical Systems,“What” versus “Where” in the audiovisual domain: An fMRI study,"POLITICAL CHANGES IN NORTH KOREA: WHAT IS IT, WHAT HAS HAPPENED AND WHAT TO EXPECT?","Nephrotic syndrome: what’s new, what’s hot?",How to make data migration processes more efficient by using TOGAF: Best practice data migration approach applied to SAP Financial Services-Policy Management,Data center cooling management and analysis - a model based approach,Extraspinal findings on lumbar spine MR imaging.,"Indications and findings at colonoscopy in Ilorin, Nigeria",A Retrospective Study of Intervertebral Disk Disease in 21 Dogs; Clinical Findings and Outcomes,Histopathological Findings in Medicolegal Autopsies with Emphasis on Rare Incidental Findings,Magnetic Resonance Imaging of the Cervical Spine: Frequency of Abnormal Findings with Relation to Age,Dynamic CT Findings of Pulmonary Hamartoma: A Comparison with Histopathologic Findings,Semi-Automating (or not) a Socio-Technical Method for Socio-Technical Systems,Generating testable socio-technical systems theory,What Counts as Knowledge and What Knowledge Counts in Early Childhood Education?,칸트의 첫째 이율배반과 대폭발 우주론,The Big Student Big Data Grab,Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로,"Computational approaches to interface design : what works, what doesn't, what should and what might",DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구,Big-BOE: Fusing Spanish Official Gazette with Big Data Technology,Data mining 기법을 이용한 자동차보험 손해율 분석,Socio-technical coordination (keynote),Why Big Data = Big Deal,효율적 데이터 마이닝 분석을 위해 특정 도메인 별 다량의 축적 데이터집합에 대한 데이터 중심 관리 기법 연구,A Review of ACIR Findings,Socio-technical Computation,예비교사 교육에서 If-Not-What-Yes와 What-If-For를 통한 반례 생성과 명제의 정교화,What life? What cycle?,What Process For What Part?,BIG6 모형을 적용한 국어과 도서관협력수업이 정보활용 태도에 미치는 영향,Big6 Skills 모형을 이용한 정보활용수업이 정보활용능력과 비판적 사고력에 미치는 영향,Findings,,,
Big Data를 이용한 Warehouse Management System 모델에서 제시된 핵심 개념과 방향을 요약해 주시겠습니까?,"##제목## Big Data를 활용한 창고관리 시스템 모델 연구: SAP S/4 HANA 중심 ##서론## 디지털 전환(Digital Transformation)은 단순히 기존 데이터를 전자화하는 단계를 넘어 실시간 데이터 처리·분석 역량을 확보하는 것을 의미한다. 특히 산업 창고관리 분야에서는 재고·입출고·물류 흐름 등 방대한 운영 데이터를 효과적으로 활용할 수 있는 모델이 필요하다. 본 연구는 SAP S/4 HANA를 기반으로 대용량 데이터를 수집·처리하는 Warehouse Management System(WMS) 모델의 핵심 개념과 향후 방향을 제안하는 데 목적이 있다. ##본론## 1. Big Data 중심 아키텍처 - 센서와 ERP로부터 생성되는 다양한 물류 데이터를 실시간 스트리밍 및 배치 처리로 통합 - Hadoop, Spark 등 분산컴퓨팅 프레임워크를 활용해 대규모 트랜잭션과 로그를 고속 처리 2. SAP S/4 HANA 플랫폼 활용 - 인메모리(in-memory) 데이터베이스로 재고 현황·입출고 기록을 즉시 조회·분석 - 표준화된 모듈을 통해 창고 레이아웃 관리, 물류 작업 지시, 자동화 설비 연동 기능 제공 3. 지능형 분석 및 예측 - 수요·재고 변동 패턴을 기계학습으로 예측해 적정 재고 수준 자동 조정 - 실시간 KPI 대시보드를 구축해 운영 현황을 시각화하고 이상 징후를 조기 감지 ##결론## Big Data 기반 WMS 모델은 실시간 의사결정과 프로세스 자동화를 가능케 하며, SAP S/4 HANA의 인메모리 처리 기술을 통해 운영 효율을 극대화한다. 향후 IoT 센서, AI 알고리즘, 로봇 물류 설비와의 연계 강화를 통해 스마트 물류 환경으로의 진화를 기대할 수 있다.",없음,"##title## Warehouse Management System Model Study using Big Data: SAP S/4 HANA Center ##introduction## Digital transformation means securing real -time data processing and analysis capabilities beyond simply electronically electronic steps. In particular, in the field of industrial warehouse management, a model is needed to effectively utilize vast operation data such as inventory, deposit, and logistics flow. This study aims to propose the core concepts and future directions of the Warehouse Management System (WMS) model, which collects and processes large data based on SAP S/4 hana. ## Main ## 1. Big Data -centric architecture -Integrate various logistics data generated from sensors and ERPs into real -time streaming and batch processing -Fall processing large -scale transactions and logs using distributed computing frameworks such as HADOOP and SPARK 2. Use SAP S/4 HANA platform -Interview and analysis of inventory status and deposit records with in-memory database -Provide warehouse layout management, logistics work instructions, automation facility interworking function through standardized modules 3. Intelligent analysis and prediction -Ex adjusting the appropriate inventory level by predicting demand and inventory change patterns with machine learning -Real -time KPI dashboards to visualize the operation status and detect abnormal signs early. ##conclusion## The Big Data -based WMS model enables real -time decision -making and process automation, and maximizes operational efficiency through the In -Memo -Memory processing technology of SAP S/4 HANA. In the future, we can expect the evolution to the smart logistics environment by strengthening the connection with IoT sensors, AI algorithms, and robot logistics facilities.","Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",15,1.1859924140007934,"**제목: 제공된 문서에서 Big Data를 이용한 Warehouse Management System 모델에 대한 정보 부재**

**서론:**

본 보고서는 제공된 다섯 개의 학술 문서를 바탕으로, Big Data를 이용한 Warehouse Management System 모델에서 제시된 핵심 개념과 방향을 요약하는 것을 목표로 합니다.  그러나 제공된 문서들은 가출 청소년에 대한 개입 방안, 문제 행동 청소년의 자기 통제력 향상, 민간 의료 보험의 영향, 평면 코일을 이용한 2축 구동 장치 개발, 그리고 대학생 모바일 러닝 사용 의도에 관한 연구 결과를 다루고 있으며, Big Data를 이용한 Warehouse Management System과 관련된 내용은 포함하고 있지 않습니다. 따라서 질문에 대한 직접적인 답변은 불가능합니다.

**본론:**

제공된 문서에는 Big Data, Warehouse Management System, 또는 이 둘의 결합에 대한 어떠한 언급도 없습니다. 문서 1은 가출 청소년 문제에 대한 과제 중심 모델 적용 사례 연구, 문서 2는 문제 행동 청소년의 자기 통제력 및 자기 효능감 향상을 위한 과제 중심 모델 적용 사례 연구, 문서 3은 민간 의료 보험 가입이 의료 이용에 미치는 영향에 대한 연구, 문서 4는 평면 코일을 이용한 2축 구동 장치 개발에 관한 연구, 문서 5는 정보 기술 수용 모델을 적용한 대학생 모바일 러닝 사용 의도 연구를 다루고 있습니다.  이러한 연구들은 각각의 분야에서 유용한 정보를 제공하지만, 질문의 핵심 주제와는 관련이 없습니다.  따라서, Big Data를 이용한 Warehouse Management System 모델의 핵심 개념과 방향을 요약하는 것은 불가능합니다.

**결론:**

제공된 문서에는 Big Data를 이용한 Warehouse Management System 모델에 대한 정보가 전혀 포함되어 있지 않습니다. 따라서 질문에 답변할 수 없습니다.  Big Data를 이용한 Warehouse Management System에 대한 정보를 얻으려면 관련된 다른 자료를 참고해야 합니다.",가출청소년에 대한 효과적인 개입방안 연구 : 과제중심모델을 적용한 사례연구를 통하여,문제행동청소년의 자기통제력과 자기효능감 제고를 위한 과제중심모델의 적용 사례연구,민간의료보험 가입이 의료이용에 미치는 영향,평면 코일을 이용한 2축 구동장치 개발에 관한 연구,정보기술수용모델을 적용한 대학생 모바일러닝 사용의도와 영향요인 간 구조적 관계 분석,이브 클렝의 모노크롬에서 제시된 '비물질성',비즈니스 모델 관점에서 바라 본 IoT,중등학교에서의 컴퓨터 통신과 인터넷 교육 모델,음절단위의 한국어 음성인식 모델 분석,비즈니스 모델 현황 진단을 위한 평가지표 개발,양자강 저염수의 시공간적 변동에 관한 수치 실험,근로소득공제제도의 효과분석 및 대안제시,해결점 제시,"순간제시 얼굴의 왜곡 현상에 대한제시 시간, 제시 개수, 얼굴 구성요소와 윤곽의 영향",수업 시나리오 제시,한일방송통역의 분석과 전략제시,"문장 제시어, 성분 제시어, 그리고 내부 제시어",새로운 도시개발의 모델 제시,인쇄산업의 새로운 트랜드 제시,가출 부랑아의 초기적응을 위한 과제중심모델 적용 사례연구,비즈니스 모델 특허를 둘러싼 벤처기업의 행태와 시장환경에 관한 연구,미세먼지 통계 예보 모델 개선에 관한 연구,수치모델을 통한 한국 남해 동부해역의 해양쓰레기 이동에 관한 연구,지속가능한 수변지역 개발을 위한 토지이용계획,다중이용업소 소방안전의 실효성 확보를 위한 방안,다중이용업소 화재피해 최소화 방안에 관한 연구 : 화재 원인 조사 분석을 중심으로,한중소비자의 여행공유경제 이용의도 비교분석 : 여행공유경제 플랫폼과 소비자 개인 특성을 중심으로,소비자들의 서비스 로봇의 이용의도 영향요인에 대한 탐색적 연구,지방자치단체의 구역 및 경계에 관한 법적 과제,화석돌말류를 통한 울릉분지와 대한해협에서의 고해양학적인 연구,,,,,,,,,,,,,,,,,,,,
DTG 실 주행데이터와 공간정보를 활용한 연료소모량 추정 모델 SBiFEM의 핵심 구성 요소를 요약해 주세요.,"##제목## DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 SBiFEM ##서론## DTG 운행기록계와 GPS 공간데이터의 대규모 축적으로 연료소모량 예측을 위한 빅데이터 분석의 필요성이 커졌다. 기존 모델은 제한된 환경에서 검증되어 실제 상용차 운행 시 정확도가 낮은 문제가 있었다. 이를 해결하기 위해 운전자 특성 및 도로 환경정보를 반영한 SBiFEM을 제안한다. ##본론## - 전처리 기술: 통계기법과 운행 패턴 분석을 결합한 필터링으로 센싱 및 GPS 데이터의 이상치(Outlier)를 제거해 신뢰성 확보 - 빅데이터 맵매칭: 대량의 GPS 궤적을 전자지도에 매칭하여 도로 유형, 경사도, 제한속도 등 공간 빅데이터 변수 추출 - 운행 패턴 생성: 속도·가속도·유휴시간 등 운전자 운행특성을 운행 패턴 변수로 정의하여 연료소모 영향 요인으로 활용 - 연료소모량 추정 모델: 공간빅데이터와 운행 패턴 변수를 회귀 기반 모델에 통합해 실제 운행 환경을 반영한 정밀 추정식 구축 - 시스템 구현 및 검증: Hadoop, HBase, MapReduce 기반 5대 분산 서버에서 분석 프로세스를 수행하고 SIDRA, VSP, VT-Micro 모델 대비 Correlation 0.9169, MAPE 0.1846을 달성해 성능 우수성 입증 ##결론## SBiFEM은 DTG 실 주행데이터와 공간 정보를 결합해 실제 운행 환경을 반영한 변수로 연료소모를 정밀하게 추정하며, 대규모 분산 처리와 비교 실험을 통해 기존 모델 대비 월등히 높은 정확도를 검증했다.","Please summarize the core components of SBIFEM, an estimated fuel cluster estimation model using DTG actual driving data and spatial information.","##title## Big Data -based fuel consumption estimation model using DTG real data and spatial information SBIFEM ##introduction## The large -scale accumulation of DTG operating records and GPS spatial data has increased the need for big data analysis to predict fuel and volume. Existing models have been verified in a limited environment and have a problem with low accuracy during actual commercial vehicles. To solve this problem, SBIFEM is proposed to reflect driver characteristics and road environment information. ## Main ## -Preating technology: Census and removing Outlier of GPS data with filtering that combines statistical techniques and operating pattern analysis to secure reliability -Big data map matching: A large amount of GPS trajectory on the electronic map to extract spatial big data variable such as road type, inclination, and limit speed -Incremental operation pattern: Using the driver's driving characteristics such as speed, acceleration, and idle time as an operation pattern variable and used as a fuel consumption impact factor -Puisotor Motor Estimation Model: Space big data and operating pattern variables are integrated into regression -based models to establish precise estimates that reflect the actual operating environment System Implementation and Verification: Hadoop, HBase, and MapREDUCE-based 5 Distributed Server performs analysis processes and achieved 0.9169, MAPE 0.1846 compared to SIDRA, VSP, VT-MICRO model to demonstrate performance excellence by achieving 0.1846 ##conclusion## SBIFEM combines DTG actual driving data and spatial information to precisely estimate fuel consumption as a variable that reflects the actual operating environment, and has verified a much higher accuracy compared to the existing model through large -scale distributed processing and comparison experiments.","Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",16,1.1859924140007934,"**제목:  DTG 실 주행 데이터와 공간정보를 활용한 연료소모량 추정 모델 SBiFEM에 대한 정보 부재 보고서**

**서론:**

제시된 질문은 DTG 실 주행 데이터와 공간정보를 활용한 연료소모량 추정 모델 SBiFEM의 핵심 구성 요소를 요약하는 것입니다.  그러나 제공된 문서 1~5에는 SBiFEM 모델에 대한 정보가 전혀 포함되어 있지 않습니다. 따라서 본 보고서는 제공된 자료만을 바탕으로 질문에 대한 답변을 제공할 수 없습니다.


**본론:**

제공된 다섯 개의 문서는 다양한 분야의 데이터 분석 및 모델링에 대한 연구를 다루고 있지만,  DTG 실 주행 데이터와 공간정보를 활용한 연료소모량 추정 모델 SBiFEM과 관련된 어떠한 정보도 포함하고 있지 않습니다.  문서 1은 양양국제공항에 대한 소비자 관심 분석, 문서 2는 조직 신뢰 지수 자동 추이 분석 모델, 문서 3은 드론을 이용한 소규모 지형 변화 분석, 문서 4는 빅데이터 기반 생체 신호 분석 플랫폼 개발, 문서 5는 자율주행 차량의 충돌 회피를 위한 제어 알고리즘 연구를 다루고 있습니다.  이들 연구는 모두 데이터 분석 및 모델링을 다루지만, 질문에서 언급된 SBiFEM 모델과는 관련성이 없습니다.  따라서 SBiFEM 모델의 핵심 구성 요소를 요약하는 것은 불가능합니다.


**결론:**

제공된 문서에는 DTG 실 주행 데이터와 공간정보를 활용한 연료소모량 추정 모델 SBiFEM에 대한 정보가 없으므로, 질문에 대한 답변을 제공할 수 없습니다.  SBiFEM 모델에 대한 추가적인 정보가 제공되어야만 질문에 대해 답변할 수 있습니다.",양양국제공항에 대한 소비자관심 성향 빅데이터 시각화 분석,데이터 마이닝 기법을 활용한 조직 신뢰 지수 자동 추이분석 모델링 방법론,드론 디지털 영상을 이용한 소규모 지형변화 분석,빅데이터 기반의 생체신호 분석 플랫폼 개발,자율주행 차량의 충돌회피를 위한 NMPC기반 제어 알고리즘 실시간 성능 연구,관광 공공데이터 기반 모바일 애플리케이션의 사용자 관심요소 분석,도시 개발 정책과 교육 공간 재구성과의 관련성 연구,공간 마케팅 관점에서 본 라이프스타일 센터의 계획방향,학교 공간의 장소적 특성에 관한 연구,지하공간 리모델링 디자인 체크리스트 개발 연구 : 서울시 공공지하공간을 중심으로,고등학교 학생들의 공간도형단원에 대한 남녀학생의 공간 지각력 차이 고찰 : Cabri 3D로 구현된 공간도형 중심으로,자율주행자동차 운행 중 사고의 법적 쟁점,자율주행 자동차를 위한 딥러닝 기반 실시간 장면 이해에 관한 연구,빅데이터 활용과 분석기법 고찰,미국 기업의 오픈데이터 활용사례와 비즈니스 네트워크 분석 : “데이터와 기술” 분야를 중심으로,공간구문론을 이용한 대형할인점 공간구조 분석,자아 공간(自我 空間) 의 상징적 표현 연구 : 본인의 채색화에 나타난 주제와 표현형식,공간빅데이터로서 소셜미디어 자료를 활용한 공간정보 추출 및 표현 시스템 개발,"자율주행 2, 3 단계에 따른 에이전트 대화수준의 효과",자율주행 자동차의 헤드업 디스플레이에 최적화된 제스처에 관한 연구,자율주행자동차 사고발생에 따른 형사책임의 귀속여부 - 레벨4단계를 중심으로 -,자율주행 차량의 전방차량 추월 및 원 경로 회귀에 관한 경로계획 알고리즘 연구,자율주행 3단계 차량의 컷-아웃 상황 사고 안전성 평가방법론,자율주행 차량의 자동화 수준에 따른 정보 제공 방법 연구 : 자동화 시스템의 신뢰 형성 이론을 중심으로,데이터 시각화를 이용한 미디어아트 : 빅 데이터 시각화 작품 <Earth>를 중심으로,데이터 마이닝 기법에 관한 연구,빅데이터 기반의 생체신호 분석 사례 및 연구,기업의 빅데이터 활용 수준 진단지표 개발 연구,공간구문론 및 지리적 가중회귀 기법을 이용한 도시공간구조 분석,자율주행 자동차의 도로 환경 지도를 이용한 3D LiDAR 센서 기반 동적 물체 추적 및 주행 차로 인식 기법 개발,,,,,,,,,,,,,,,,,,,,
빅데이터 처리 과정별 위험요인 유형과 우선순위를 간략하게 요약해 주시겠습니까?,"##제목## 빅데이터 처리 단계별 위험요인 유형과 우선순위 ##서론## 빅데이터 도입이 활발해지면서 데이터 수집부터 활용까지 전 과정에서 발생할 수 있는 다양한 위험요인을 체계적으로 분석하고, 전문가 설문을 통해 그 심각도에 따른 우선순위를 파악할 필요가 대두되었다. ##본론## 1. 수집 단계: 데이터 품질 저하와 불완전한 수집 프로세스로 인한 오류 발생 위험 2. 저장 단계: 보안 취약점과 데이터 유실·손상 위험 3. 분석 단계: 알고리즘 편향, 해석 오류 및 모델 신뢰성 저하 위험 4. 시각화 단계: 과장·왜곡된 정보 전달로 인한 오판 위험 5. 적용 단계: 잘못된 의사결정, 윤리·법적 문제 발생 위험 – 전문가 설문 결과, 먼저 해결해야 할 최우선 위험으로는 수집 단계의 품질 오류와 저장 단계의 보안 문제가 꼽혔으며, 그 다음으로 분석·시각화 과정의 해석 오류가 중요한 것으로 나타났다. ##결론## 단계별 위험요인을 명확히 파악하고 우선순위에 따라 대응 방안을 마련함으로써 빅데이터 처리 전 과정의 안정성을 높이고 효과적인 활용이 가능해진다.",Can you briefly summarize the types and priorities of risk factors for each big data processing process?,"##title## Big data processing stage type and priority ##introduction## As the introduction of big data became more active, it was necessary to systematically analyze various risk factors that can occur throughout the process from data collection to utilization, and to identify priority due to the severity through expert surveys. ## Main ## 1. Collection Stage: Data Quality Risk of Error due to Incomant Collection Processes 2. Storage Stage: Risk of security vulnerabilities and data loss and damage 3. Analysis Step: Risk of algorithm bias, analysis error and model reliability decrease 4. Visualization Stage: Odan Risk due to exaggeration and distorted information delivery 5. Application Stage: Risk of incorrect decision, ethics and legal problems - According to the expert survey, the first priority to be solved was the quality error of the collection stage and the security problem in the storage stage, followed by the analysis and visualization process. ##conclusion## By clearly identifying the risk factors of each stage and preparing a countermeasure according to priority, it enables increasing the stability of the entire big data processing process and effective utilization.","Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",17,1.1859924140007934,"**제목:** 빅데이터 처리 과정별 위험 요인 및 우선순위 분석

**서론:** 본 보고서는 제공된 학술 문서들을 바탕으로 빅데이터 처리 과정에서 발생할 수 있는 위험 요인의 유형과 우선순위를 분석합니다.  문서들은 빅데이터의 다양한 활용 분야(식량 시스템 관리, 데이터센터 모니터링, 관광 산업 분석, 개인 맞춤형 의료)를 다루며, 각 분야에서 빅데이터 처리 과정의 특징과 발생 가능한 문제점들을 제시하고 있습니다.

**본론:**

빅데이터 처리 과정은 크게 데이터 수집, 정제(Curation), 저장, 분석, 활용 단계로 나눌 수 있으며, 각 단계별로 다음과 같은 위험 요인이 존재합니다.

* **데이터 수집 단계:** 문서 3은 제주 관광 빅데이터 분석 사례를 통해 빅데이터 수집 단계에서의 대표적인 문제점으로 데이터의 **대표성 부족**을 지적합니다.  이는 빅데이터의 규모만을 중시하여 실제 현황을 제대로 반영하지 못하는 경우 발생합니다.  이 문제는 소규모 데이터(Small Data)를 보완적으로 활용하여 해결할 수 있다고 제시합니다.  또한, 문서 4는 개인 맞춤형 의료 분야에서 **민감한 데이터의 취급**을 중요한 위험 요인으로 언급합니다.

* **데이터 정제(Curation) 단계:** 문서 3에서는 빅데이터의 상관관계를 인과관계로 오인하는 문제를 지적하며, 이를 해결하기 위해 소규모 데이터를 활용한 **인과 분석**의 필요성을 강조합니다.  이는 빅데이터 분석 결과의 **해석 오류**로 이어질 수 있는 위험 요소입니다.

* **데이터 저장 단계:** 문서 3은 빅데이터 저장 과정에서 **개인정보 침해**의 위험성을 지적하고, 이를 방지하기 위한 소규모 데이터 기반의 정책 수립을 제안합니다.  이는 데이터 보안 및 프라이버시 보호 측면에서 중요한 위험 요인입니다.

* **데이터 분석 단계:** 문서 2는 대규모 데이터센터의 센서 데이터 처리에서 **실시간 처리 지연(Latency)** 문제를 주요 위험 요인으로 제시합니다.  이 문제는 이벤트 시간 기반 실시간 스트리밍 처리 모델, 필터링, 슬랙 시간, 윈도우 배가, 좌표 시간 방법 등을 통해 해결할 수 있다고 제안합니다. 문서 5 또한 데이터 스트림의 순서 혼란(Out-of-order data)으로 인한 **처리 지연 및 정확도 저하** 문제를 다루고 있으며, 데이터 스트림 분리 처리(DSSP) 모델을 제시합니다.

* **데이터 활용 단계:** 문서 1은 식량 시스템 관리에 빅데이터를 활용하는 과정에서 **데이터 접근성 및 공유의 부족**을 성공적인 구현을 위한 중요한 위험 요인으로 지적합니다. 또한,  빅데이터 분석 결과의 실제 현장 적용 과정에서 **해석 오류 및 예측 실패**의 가능성이 존재합니다.  문서 3은 이러한 문제를 해결하기 위해 빅데이터와 소규모 데이터의 **상호 보완적 활용**을 제안합니다.  문서 4에서는 개인 맞춤형 의료 분야에서 빅데이터 분석 결과의 **신뢰성 확보**가 중요한 위험 요인이라고 언급합니다.


**결론:**

빅데이터 처리 과정 전반에서 다양한 위험 요인이 존재하며, 그 우선순위는 특정 응용 분야 및 데이터 특성에 따라 달라집니다.  그러나 데이터의 대표성 부족, 개인정보 침해, 실시간 처리 지연, 분석 결과의 해석 오류 및 신뢰성 문제는 대부분의 빅데이터 활용 분야에서 공통적으로 발생할 수 있는 중요한 위험 요인으로 간주될 수 있습니다.  소규모 데이터와의 상호 보완적인 활용,  강력한 데이터 보안 및 관리 체계 구축,  정확하고 신속한 실시간 처리 기술의 개발 등이 이러한 위험 요인을 완화하고 빅데이터 활용의 성공률을 높이는 데 중요한 역할을 할 것입니다.","Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal",데이터센터 모니터링 시스템에서 대량 스트리밍 센서 데이터 처리,Compromise between Small Data and Big Data,"Big Data, Big Knowledge: Big Data for Personalized Healthcare",무질서 데이터를 위한 데이터 스트림 분리 처리 모델,브이월드 데스크톱을 위한 대용량 공간정보 데이터 지원 방안 연구,브이월드 데스크톱을 위한 대용량 공간정보 데이터 지원 방안 연구,분산환경에서 빅 데이터 처리 기법,DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구,비정형 대용량 데이터 입력 및 출력 시스템 설계 및 구현,저궤도위성 원격측정 데이터 처리를 위한 대용량 메모리 운용,블리킹을 이용한 대용량 초음파 볼륨 데이터 렌더링,GO언어를 이용한 대용량 데이터 리스트의 동시성 처리 비교,클라우드 데이터 서비스를 위한 대용량 데이터 처리 분산 파일 아키텍처 설계,"누리과정 5개 영역에 대한 교사의 인식, 실행 및 평가에 관한 연구",보육교사의「표준보육과정」인식과 운영실태,누리과정 3-4세 「교사용 지도서」의 교육과정 관련내용 분석,인터넷 기반 GPS 데이터 처리 서비스에 관한 연구,"대량 데이터 처리 소프트웨어, DIAdeM",최근 데이터 처리기술 및 전망 - 국산 데이터 처리 솔루션을 중심으로 -,ETRI신기술-공간 데이터 처리 기술,"IDL : 데이터 처리, 분석 가시화 소프트웨어",GPU를 사용한 효율적인 공간 데이터 처리,항공 안전 데이터의 혼합 데이터레이크 플랫폼에서의 저장과 처리 설계,고도처리 공정을 이용한 산업폐수의 질소 성분의 제거,영상처리 기반 도로 검출 및 차량 검출에 관한 연구,표면처리 방법에 따른 티타늄과 레진과의 전단 결합 강도 비교,음식물쓰레기 처리 개선방안에 관한 연구,초고압 처리 메밀가루와 메밀반죽의 파파인 가수분해 특성 분석,자연어 처리 기술을 활용한 문제행동 유형 분석 연구,열처리 학습을 위한 CAI의 구현 및 활용 : 탄소강의 열처리 중심으로,영상처리 알고리즘을 이용한 전선추적 시스템,열처리 공정의 생산스케줄 수립과 적용에 관한 연구,고도 산화 처리(AOPs)용 촉매의 합성 및 그 특성에 관한 연구,WCF를 이용한 대용량 데이터 전송기법,UDP 기반의 대용량 VLBI 데이터 전송 프로그램 개발,대용량 데이터 관리를 위한 병렬 입출력시스템,PARP in glycolysis and mitochondrial respiration : PARP에 의한 해당과정과 미토콘드리아 호흡 연구,분만과정 중 배우자의 지지에 대한 임산부와 배우자의 요구 및 기대효과,과정중심 평가의 현장 적용 : '교과서 재구성 - 수업 - 과정중심평가'의 적용과 효과,유아교육과정 운영에서의 프로젝트 접근법 적용에 관한 연구,단편영화 <능곡> 제작과정에 대한 연구,"간호대학생의 정보활용능력, 간호과정 수행능력과 근거기반실무 역량의 관계",고 위험군 유방암 환자의 치료과정에 따른 삶의 질의 변화,Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로,Enjeux des big data en sant&eacute;,Artificial intelligence and Big Data in neurology,Data learning from big data,Synchrotron Big Data Science,Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구
패키징 분야에서의 빅데이터 분석 기법과 소비자 인식 분석 방안을 요약해 주세요.,"##제목## 빅데이터 기반 스마트 패키징 분석 및 소비자 인식 평가 방안 ##서론## 스마트 패키징은 4차 산업혁명 시대에 IoT, 빅데이터, 클라우드 기술을 융합해 제품의 부가가치를 높이는 전략 도구입니다. 특히 소비자의 구매 결정 과정에서 패키징이 미치는 영향이 크기 때문에, 이를 정밀하게 파악하고 적용하기 위한 빅데이터 분석 기법이 요구됩니다. 본 연구는 패키징 분야에 활용 가능한 데이터 수집·저장·분석 방법을 정리하고, 소비자 인식 분석 방안을 제안합니다. ##본론## 1. 데이터 원천 및 관리 - 사유 데이터(private data)와 커뮤니티 데이터(community data)를 활용해 소비자 행동 및 반응 정보를 수집·저장합니다. 2. 패키징 요소별 영향력 도출 - 의미연결망 분석과 텍스트마이닝으로 패키징 관련 키워드와 연관성을 파악하고, 빈도 분석을 통해 주요 속성의 영향도를 계량화합니다. 3. 감정 및 선호도 심층 분석 - 저관여 제품을 대상으로 텍스트 마이닝, 오피니언 마이닝, 소셜 네트워크 분석을 결합해 소비자 감정과 선호 패키징 유형을 도출합니다. ##결론## 제안된 빅데이터 분석 기법을 통해 패키징 요소가 소비자 인식 및 감정에 미치는 영향을 객관적으로 평가할 수 있습니다. 이를 바탕으로 기업은 차별화된 디자인 전략과 제품 개선 방향을 수립해 마케팅 효율을 높일 수 있습니다. 궁극적으로 스마트 패키징 구현을 통해 소비자 만족도를 증대시키고 시장 경쟁력을 강화할 수 있습니다.",Please summarize big data analysis techniques and consumer recognition analysis in the field of packaging.,"##title## Big data -based smart packaging analysis and consumer recognition evaluation plan ##introduction## Smart packaging is a strategic tool that increases the added value of the product by combining IoT, big data, and cloud technologies in the era of the Fourth Industrial Revolution. In particular, since the impact of packaging on the purchase decision of consumers, big data analysis techniques are required to identify and apply it precisely. This study summarizes data collection, storage, and analysis methods that can be used in the field of packaging, and proposes consumer recognition analysis. ## Main ## 1. Data Source and Management -The use private data and community data to collect and store consumer behavior and reaction information. 2. Doting influence by packaging element -The significant connection network analysis and text mining understand the connection with the keywords related to packaging, and the frequency analysis weigh the effects of major attributes. 3. In -depth analysis of emotion and preference -Combine text mining, opinion mining, and social network analysis for low -corruption products to derive consumer sentiment and preferred packaging type. ##conclusion## The proposed big data analysis technique allows you to objectively evaluate the impact of packaging elements on consumer awareness and emotions. Based on this, companies can increase marketing efficiency by establishing differentiated design strategies and product improvement directions. Ultimately, smart packaging can be implemented to increase consumer satisfaction and strengthen market competitiveness.","Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",18,1.1859924140007934,"**제목: 패키징 분야에서의 빅데이터 분석 기법과 소비자 인식 분석 방안**

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 패키징 분야에서 빅데이터 분석 기법과 소비자 인식 분석 방안을 제시합니다.  제공된 문서들은 빅데이터 분석의 다양한 적용 사례를 보여주지만, 패키징 분야에 대한 직접적인 언급은 없으므로,  제공된 자료를 바탕으로 추론하고 일반화하여 답변을 구성합니다.

**본론:**

제공된 문서들은 빅데이터 분석이 다양한 분야에서 활용될 수 있음을 보여줍니다.  문서 1에서는 지속 가능한 개발 목표 달성을 위한 식량 시스템 관리에 빅데이터와 IoT 기술의 활용 가능성을 제시하며, 실시간 데이터 분석을 통한 효율적인 개입 전략 수립을 강조합니다. 이는 패키징 분야에서도 제품 유통, 재고 관리, 소비자 반응 분석 등에 적용 가능한 접근 방식입니다.  예를 들어, 스마트 패키징에 부착된 센서를 통해 수집된 데이터를 실시간으로 분석하여 제품의 신선도, 유통 과정의 온도 변화 등을 추적하고, 이를 바탕으로 유통 전략을 개선할 수 있습니다.

문서 2는 빅데이터 분석의 한계점을 지적하며, 소규모 데이터(small data)와의 결합을 통해 이를 보완할 수 있음을 제시합니다.  빅데이터의 상관관계를 인과관계로 오인하는 문제 해결을 위해 소규모 데이터를 활용한 인과 분석을 제안하는데, 이는 패키징 디자인과 소비자 선택 간의 관계를 분석하는 데 유용합니다.  소비자 선호도 조사 등 소규모 데이터를 통해 얻은 인사이트를 빅데이터 분석 결과와 결합하여 보다 정확한 소비자 인식을 파악할 수 있습니다.  예를 들어, 빅데이터 분석을 통해 특정 패키징 디자인의 판매량이 높다는 것을 알 수 있지만, 소규모 데이터 분석을 통해 그 이유가 디자인 자체의 매력 때문인지, 가격이나 프로모션 때문인지 등을 명확히 파악할 수 있습니다.

문서 3은 의료 분야에서 빅데이터 분석의 활용 가능성을 제시하며, 개인 맞춤형 의료 서비스 제공을 위한 데이터 분석 기술의 발전 필요성을 언급합니다.  이러한 개인화 전략은 패키징 분야에서도 소비자 세분화 마케팅에 적용 가능합니다.  소비자의 구매 이력, 선호도, 위치 정보 등을 분석하여 개별 소비자에게 맞춤화된 패키징 디자인이나 광고를 제공할 수 있습니다.

문서 4와 5는 데이터 센터 모니터링 및 가속기 실험 데이터 분석에서 빅데이터 처리 기술의 중요성을 강조합니다.  이는 패키징 생산 공정 모니터링 및 관리에 적용될 수 있습니다.  생산 라인에 설치된 센서에서 수집되는 데이터를 실시간으로 분석하여 생산 효율을 높이고 불량률을 감소시킬 수 있습니다.


**결론:**

빅데이터 분석은 패키징 분야에서 제품 유통 및 생산 관리, 소비자 인식 분석 등 다양한 영역에 활용될 수 있습니다.  소규모 데이터와의 결합을 통해 빅데이터 분석의 한계를 극복하고, 소비자 세분화 마케팅 및 개인 맞춤형 전략 수립에 활용할 수 있습니다.  실시간 데이터 분석은 제품 신선도 관리 및 유통 전략 개선에 기여하고, 생산 공정 모니터링을 통해 생산 효율 향상에 기여할 수 있습니다.  따라서 빅데이터 분석 기법은 패키징 산업의 경쟁력 강화에 중요한 역할을 할 것으로 예상됩니다.","Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal",Compromise between Small Data and Big Data,"Big Data, Big Knowledge: Big Data for Personalized Healthcare",데이터센터 모니터링 시스템에서 대량 스트리밍 센서 데이터 처리,Synchrotron Big Data Science,빅데이터를 활용한 헤어 미용분야 패러다임 변화 연구,성공적인 메이크업 아티스트에 관한 탐색적 연구 : 심층면접법을 중심으로,"한국 기록문화유산 정보시각화 연구 방안 : 천문류초, 천상열차분야지도 중심으로",사물인터넷 적용을 통한 건설 안전관리 시스템 개선방안,반도체 패키징 산업의 4M factor를 반영한 소요예측 시뮬레이션 시스템 구축에 관한 연구 : 반도체 H사 사례를 중심으로,DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구,건축자재용 RFID 패키징 설계,주목해야 할 패키징 디자인 &#9313; - 소비자의 마음을 사로잡는 식품 패키징 디자인키워드,ETRI신기술-공간 데이터 처리 기술,"IDL : 데이터 처리, 분석 가시화 소프트웨어",브이월드 데스크톱을 위한 대용량 공간정보 데이터 지원 방안 연구,브이월드 데스크톱을 위한 대용량 공간정보 데이터 지원 방안 연구,조선초기 천문관측 기구의 이해와 교육적 활용방안,반도체 패키징 구리 본딩 와이어의 신뢰성 향상에 관한 연구,미소유체시스템을 위한 실용적인 패키징 기술,패키징 간소화,패키징 신뢰도,단일 칩 패키징,무납 패키징 만들기,광소자 패키징 기술,분산환경에서 빅 데이터 처리 기법,WCF를 이용한 대용량 데이터 전송기법,비정형 대용량 데이터 입력 및 출력 시스템 설계 및 구현,UDP 기반의 대용량 VLBI 데이터 전송 프로그램 개발,블리킹을 이용한 대용량 초음파 볼륨 데이터 렌더링,저궤도위성 원격측정 데이터 처리를 위한 대용량 메모리 운용,GO언어를 이용한 대용량 데이터 리스트의 동시성 처리 비교,클라우드 데이터 서비스를 위한 대용량 데이터 처리 분산 파일 아키텍처 설계,대용량 데이터 관리를 위한 병렬 입출력시스템,부동산분야 국가직무능력표준(NCS)에 관한 고찰,인듐틴옥사이드에서의 자기조립박막 형성과 유기전기발광소자로의 응용,『天象列次分野之圖』 圖說의 문헌학적 연구,2020년 CFD 분야 연구동향,2020년 압축기 분야 연구동향,인터넷 기반 GPS 데이터 처리 서비스에 관한 연구,"대량 데이터 처리 소프트웨어, DIAdeM",최근 데이터 처리기술 및 전망 - 국산 데이터 처리 솔루션을 중심으로 -,무질서 데이터를 위한 데이터 스트림 분리 처리 모델,GPU를 사용한 효율적인 공간 데이터 처리,안전한 데이터 중복 처리 기술 연구 동향,Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로,Enjeux des big data en sant&eacute;,Artificial intelligence and Big Data in neurology,Data learning from big data,Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구
제조 품질 개선을 위해 제안된 식스 시그마 기반 Big Data 활용 방법의 주요 절차를 요약해 주시겠습니까?,"##제목## 빅데이터를 활용한 식스 시그마 기반 제조 품질 개선 절차 요약 ##서론## 제조 기업은 전통적인 식스 시그마 프로젝트를 통해 체계적인 품질 개선을 추진해 왔으나, 최근 빅데이터 기술을 접목함으로써 문제점 탐색과 개선 효과 검증을 더욱 신속·정밀하게 수행할 수 있는 가능성이 커졌다. 본 연구에서는 식스 시그마의 DMAIC(Define-Measure-Analyze-Improve-Control) 단계별로 빅데이터 활용 방안을 제안한다. ##본론## 1. Define(정의) - 개선 목표 및 핵심 품질 이슈를 명확히 설정 - 빅데이터 플랫폼에 연계 가능한 공정·장비·검사 데이터 범위 지정 2. Measure(측정) - 센서, 생산관리시스템, 검사 장비 등에서 대량의 실시간 데이터를 수집·통합 - 데이터 정합성·이상치 검출을 위한 전처리 적용 3. Analyze(분석) - 통계적 기법 및 머신러닝 모델을 활용해 주요 결함 원인과 공정 변수 상관관계 파악 - 멀티변량 분석을 통해 숨겨진 패턴 및 잠재적 리스크 식별 4. Improve(개선) - 분석 결과를 바탕으로 공정 조건·검사 기준을 최적화 - 시뮬레이션 및 파일럿 실험을 통해 개선안의 실효성 검증 5. Control(관리) - 실시간 모니터링 대시보드와 이상 알림 시스템을 구축해 개선 결과 지속 관찰 - 제어 차트·경고 임계치 설정으로 재발 방지 및 표준화 유지 ##결론## 식스 시그마의 DMAIC 절차에 빅데이터 수집·분석·시각화 역량을 결합함으로써 품질 문제를 더욱 빠르고 정확하게 해결할 수 있으며, 지속적인 모니터링을 통해 제조 공정의 안정성과 경쟁력을 동시에 확보할 수 있다.",Can you summarize the main procedures of the Six Sigma -based BIG DAG DAG Data?,"##title## Six Six Sigma -based manufacturing quality improvement procedures using big data ##introduction## Manufacturing companies have been pursuing systematic quality improvement through traditional Six Sigma projects, but recently, by combining big data technology, the possibility of further and precisely conducting problems search and improved effects is increased. In this study, Six Sigma's DMAIC (Define-Measure-Analyze-IMPROVE-Control) will be proposed. ## Main ## 1. Define (definition) -It clearly set improvement goals and core quality issues -Designation of process, equipment, and inspection data that can be linked to the big data platform 2. Measure (measurement) -Collect and integrate large amounts of real -time data from sensors, production management systems, inspection equipment, etc. -Condrocation for detection of data consistency and overtake value 3. Analyze (analysis) -Incrighten statistical techniques and machine learning models to identify the causes of major defects and fair variables. -It identifies hidden patterns and potential risks through multi -variable analysis 4. IMPROVE (improvement) -Intimature of process conditions and inspection standards based on analysis results. -Efficiency of improvement plan through simulation and pilot experiments 5. Control (management) -Real -time monitoring dashboard and abnormal notification system have been established to continue to observe improvement results -It prevents recurrence and standardization by setting control charts and warning thresholds ##conclusion## By combining big data collection, analysis, and visualization capabilities with Six Sigma's DMAIC procedure, quality problems can be solved faster and more accurately, and continuous monitoring can secure the stability and competitiveness of the manufacturing process at the same time.","Title: Big data를 이용한 Warehouse Management System 모델 연구 : SAP S/4 Hana를 중심으로, Abstract: 본 연구는 오늘날 산업 전반적으로 영향을 미치고 있는 디지탈 전환(Digital Transformation)의 기술 환경과 디지탈 전환의 산업적 창고관리 부분의 모델연구가 본 논문의 목적이다. &amp;#xD; &amp;#xD; 디지털 전환은 오랫동안 디지털화와 비슷하거나 또는 디지털 방식으로 저장할 수 있도록 기존 데이터 형태를 전환하는 것과 관련이 있다. 물론 이 점이 중요하긴 하지만, 이전의 디지털화는 최신 디지털 전환의 영역을 포함하지 않았었다.&amp;#xD; &amp;#xD; 특히 이번 연구에서는 Big Data를 중심으로 Warehouse Management System의 방향을 제시 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015305653,","Title: DTG 실 주행데이터 및 공간정보를 이용한 빅데이터 기반 연료소모량 추정 모델 연구, Abstract: 한국에서 교통사고를 줄이는 목적으로 디지털운행기록계(DTG) 장치가 모든 상용차량에 의무 장착이 되어 GPS 궤적을 포함한 많은 양의 운행기록 데이터가 생성되고 있다. 지금까지 이러한 DTG 데이터는 주로 교통안전운전을 유도하는 용도로 사용되어왔다. 그러나 DTG데이터는 연료소모량을 줄일 수 있는 에코드라이빙 분야 등 다양한 분야로 활용도를 확대할 수 있다. 본 연구는 실제 운행한 대규모 DTG운행 데이터를 공간 빅데이터 분석을 통해 연료소모량을 추정할 수 있는 모델을 수립하는 연구이다. 기존의 연료소모량 추정 모델은 주로 실험실 환경 또는 일부 지역에 국한되어 검증한 모델로 실제 운행되는 상용차량 대상으로 분석할 경우 수집하기 어려운 변수들이 많고, 한국의 전국을 운행한 다양한 운행기록 데이터를 적용하면 정확도가 낮아지는 문제점이 있다. 본 연구에서는 이러한 문제를 개선하기 위해 DTG데이터와 공간 빅데이터를 이용한 연료소모량 추정 모델인 SBiFEM(Spatial Big Data Fuel Estimation Model)을 제안하였다. SBiFEM은 운전자 운행특성 및 도로의 다양한 환경정보를 반영하기 위해 운행 패턴과 공간 빅데이터 맵매칭 기술을 이용해 다양한 도로정보들을 입력변수로 추가 활용하는 분석 방법이다. 본 연구에서는 전처리, 공간빅데이터, 운행 패턴 생성에 이르는 전 과정에서 빅데이터 Map Reduce를 활용하는 공간빅데이터 분석 프로세스를 다음과 같이 수립하고 구현, 검증을 하였다. 첫째로, 전처리 기술 고도화이다. 센싱 데이터 및 GPS공간데이터 특성상 많은 양의 이상치 데이터(Outlier)가 존재하고 있어 이를 정제하지 않으면 분석결과도 신뢰할 수 없다. 이를 위해 통계기법 및 운행 패턴 분석을 이용한 필터링 기법을 연구하였다. 둘째로, 대량의 GPS궤적 데이터를 이용한 공간빅데이터 분석 체계이다. 차량 이동 데이터를 분석하기 위해서는 차량이 어느 도로에 위치 했는지를 알기 위한 전자지도와 매칭하는 맵매칭 기술이 필수적이다. 대부분의 맵매칭 기술은 실시간 내비게이션 용도로 주로 사용되어왔기 때문에 빠른 분석 속도를 요하는 빅데이터 분석에 적합하지 않다. 본 연구에서는 대량의 GPS궤적데이터를 전자지도에 매칭하는 빅데이터 맵매칭 기술을 연구하였다. 셋째로, 연료소모량을 추정하는 모델이다. 기존 추정 모델과의 차별점은 실제 운행환경을 반영하기 위한 변수들을 추가했다는 것이다. 한 종류는 차량 운행특성을 반영하는 운행 패턴이고, 또 한 종류는 전국의 다양한 도로 환경 정보이다. 이러한 도로 환경정보를 반영하기 위해 맵매칭 공간빅데이터 프로세스를 이용하였다. SBiFEM 빅데이터 분석시스템 테스트 및 검증은 5대의 분산 서버에 Hadoop, HBase와 Map Reduce프로그램을 수행하여 성능 검증을 하였다. 또한 연료소모량 추정 모델 검증은 대표적인 연료소모량 및 배출가스 추정 모델인 SIDRA, VSP, VT-Micro등을 DTG데이터를 적용하여 분석한 결과와 본 연구의 모델을 적용한 결과를 비교하여 검증하였다. 비교결과 추정 값과 실제 값을 비교한 Correlation이 0.9169, MAPE(평균절대백분비오차)가 0.1846으로 본 연구의 모델 적용시 가장 우수하게 나와 본 논문에서 개발한 모델의 우수성을 검증하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013973515,","Title: Big Data 활용을 위한 제조 품질 개선 방법에 대한 연구, Abstract: 20세기 대량 생산 시대 이래로 제조 기업의 품질은 가장 중요한 요소가 되어왔다. 따라서 품질에 대한 올바른 정의와 품질 개선을 위한 다양한 도구와 방법이 개발되어 왔으며 이의 효율적 적용을 위한 노력도 병행되어 왔다. 이러한 노력은 제조 기업의 품질 제일주의, 전사적 품질 경영, 식스 시그마 등을 통하여 정형화되고 다양한 분야에 적용되고 있다. 또한 최근 Big Data의 유용성이 소개되면서 이에 대한 제조 업계의 관심이 높아지고 있으나 이에 대한 적용은 아직 미흡한 면이 있다. 본 논문은 기존의 품질 개선을 위한 프로젝트 실행 방법을 정리해 보고 대표적인 프로젝트 중심의 개선 방법인 식스 시그마의 실행 방법을 기준으로 Big Data 활용 방법을 제안해 보기로 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015505861,","Title: 패키징(Packaging) 분야에서의 빅데이터(Big data) 적용방안 연구, Abstract: 패키징 분야도 4차 산업혁명에 발 맞춰 IoT (Internet of Things), 빅데이터, 클라우드 및 소비자 기반 기술 등이 적용되어 스마트 패키징이 등장하고 있다. 정책, 예측, 마케팅, 디자인 등 다양한 분야에서 빅데이터 분석이 활용되고 있지만 패키징 분야에서의 연구는 아직 초보적 수준이다. 따라서 본 연구는 빅데이터를 패키징 분야에 적용하기 위해 선행연구과 관련서적을 통해 빅데이터의 정의와 연구에서 활용되는 데이터 수집, 저장, 분석방법을 정리하였고 패키징 분야에 적용할 수 있는 분석방법을 제시하였다. 오늘날 패키징 분야는 마케팅적 요소를 요구받고 있기 때문에 패키징에 대한 소비자의 인식을 파악할 필요가 있으며 빅데이터의 근원이 되는 5가지 데이터 중 사유데이터(private data)와 커뮤니티 데이터(community data)를 활용하여 소비자와 제품 간의 상호작용 분석하는데 활용하고자 한다. 패키징은 소비자의 관심을 끌기 위한 전략전인 도구로 사용되며 소비자의 구매위험을 줄이는 수단이 되기 때문에 패키징에 대한 소비자의 인식을 분석할 필요가 있다. 본 연구에서는 제품 개선을 위한 문제점 도출 과정에서 의미연결망 분석(Semantic Network Analysis)과 텍스트마이닝(Text mining)을 활용하여 제품을 구성하는 다양한 요소들을 파악하고 패키징 요소의 빈도분석을 거쳐 패키징의 영향력을 확인하는 방안과 저관여 제품을 대상으로 텍스트 마이닝(Text mining)과 오피니언 마이닝(Opinion Mining), 소셜 네트워크 분석(Social Network Analysis)을 통해 패키징에 대한 감정분석을 하여 동일한 제품군에서 소비자가 선호하는 패키징을 도출하는 방안을 제시하였다. 패키징은 제품을 구성하는 많은 요소들 중 하나이기 때문에 패키징이라는 단일 요소의 영향력을 파악하기란 쉽지 않지만 본 연구는 빅데이터를 활용하여 패키징에 대한 소비자의 인식과 감정을 분석하고 제품에서 패키징이 소비자에게 미치는 영향력을 분석할 수 있는 방안을 제시한 데 의의가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201708260283459,","Title: 에너지 빅데이터를 수용하는 빅데이터 시스템 개발, Abstract: 본 논문은 산업 현장과 민간에서 실시간으로 수집되는 에너지 빅데이터를 수용하는 빅데이터 시스템을 제안한다. 구축된 빅데이터 시스템은 하둡(Hadoop) 기반이며, 빅데이터 처리에 있어 인메모리(in-memory) 분산처리 컴퓨팅을 지원하는 스파크(Spark) 프레임워크가 동시에 적용되었다. 본문에서는 지역난방에 사용되는 열에너지 형태의 빅데이터에 초점을 두어, 입출력되는 에너지의 특성을 고려하며 실시간 수집되는 빅데이터를 적재, 관리, 처리 및 분석하는 방법을 다룬다. 이 때, 외부에서 유입되는 빅데이터는 시스템 내부에 설계된 관계형 데이터베이스 스키마에 따라 저장하고 관리되며, 저장된 빅데이터는 설정된 목적에 따라 처리하고 분석된다. 제안된 빅데이터 시스템과 더불어 지역난방과 관련한 복수의 실증현장으로부터 실시간으로 수집되는 열에너지 빅데이터에 대해 시스템이 활용된 사례를 기술한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201823952425544,","Title: AHP 기법을 활용한 Big Data 보안관리 요소들의 우선순위 분석에 관한 연구, Abstract: IT기술의 발전은 기존의 컴퓨터 환경과 더불어 수많은 모바일 환경 및 사물 인터넷환경을 통해 사람의 삶을 편리하게 하고 있다. 이러한 모바일과 인터넷 환경의 등장으로 데이터가 급속히 폭증하고 있으며, 이러한 환경에서 데이터를 경제적인 자산으로 활용 가능한 Big Data 환경과 서비스가 등장하고 있다. 그러나 Big Data를 활용한 서비스는 증가하고 있지만, 이러한 서비스를 위해 발생되는 다량의 데이터에는 보안적 문제점이 있음에도 불구하고 Big Data의 보안성에 대한 논의는 미흡한 실정이다. 그리고 기존의 Big Data에 대한 보안적인 측면의 연구들은 Big Data의 보안이 아닌 Big Data를 활용한 서비스의 보안이 주를 이루고 있다. 이에 따라서 본 연구에서는 Big Data의 서비스 산업의 활성화를 위하여 Big Data의 보안에 대한 연구를 하였다. 세부적으로 AHP 기법을 활용한 Big Data 환경에서 보안관리를 위한 구성요소를 파악하고 그에 대한 우선순위를 도출하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201336447760856,","Title: Keynote speech 6: Big Data, IoT and the 2nd sustainable development goal, Abstract: The risks associated with the global food system are widely acknowledged and implicate a complex nexus of factors including increasing population, changing diets, erosion of natural capital, uncertain future climate, food price fluctuations, growing economic disparity and differential access to sufficient safe and nutritious food. The second sustainable development goal (SDG2) aims to address these challenges in every country to ensure not only that we eradicate global hunger, but also that everyone has access to safe and nutritious food that is produced in an environmentally, socially and economically sustainable manner. SDG2 creates an unprecedented challenge to overcome the complexity of coordinating interventions that span the whole food chain (more accurately, `food network') and engage a bewildering breadth of individuals, stakeholders and agencies. The Sustainable Development Solutions Network recommends a generic enabling framework for SDG2 that connects the various stakeholders, and indicates the feedbacks and information flows that are needed to ensure effective execution. This platform is broadly relevant to all countries irrespective of their development status. A clear requirement for the success of this framework is the availability and free exchange of data, together with near real-time analytics on that data to create the necessary knowledge flows. The potential role of data-driven innovation in implementing the enabling framework in developing and western economies will be discussed using various case studies. The opportunities for deploying existing and new kinds of sensor and networking technologies will be explored. This will include the potential role of IoT and Big Data related technologies and an evaluation of the feasibilities and risks associated with their deployment. The presentation will conclude with a set of requirements and a summary of recommendations for future priorities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12562650,","Title: Artificial intelligence and Big Data in neurology, Abstract: ABSTRACTRecent advances in technology have allowed us access to a multitude of datasets pertaining to various dimensions in neurology. Together with the enormous opportunities, we also face challenges related to data quality, ethics and intrinsic difficulties related to the application of data science in healthcare. In this article we will describe the main advances in the field of artificial intelligence and Big Data applied to neurology with a focus on neurosciences based on medical images. Real-World Data (RWD) and analytics related to large volumes of information will be described as well as some of the most relevant scientific initiatives at the time of this writing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART120884192,","Title: Big Data, Big Waste? A Reflection on the Environmental Sustainability of Big Data Initiatives, Abstract: This paper addresses a problem that has so far been neglected by scholars investigating the ethics of Big Data and policy makers: that is the ethical implications of Big Data initiatives&rsquo; environmental impact. Building on literature in environmental studies, cultural studies and Science and Technology Studies, the article draws attention to the physical presence of data, the material configuration of digital service, and the space occupied by data. It then explains how this material and situated character of data raises questions concerning the ethics of the increasingly fashionable Big Data discourses. It argues that attention should be paid to (1) the vocabulary currently used when discussing the governance of data initiatives; (2) the internal tension between current data initiatives and environmental policies; (3) issues of fair distribution. The article explains how taking into account these aspects would allow for a more responsible behaviour in the context of data storage and production., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART103720250,","Title: Enjeux des big data en sant&eacute;, Abstract: Summary The government has commissioned a report on the topic, the Estates General on Bioethics refer to it and the Order of Doctors have published a white paper. Everybody is talking about big data and artificial intelligence but few have witnessed these innovations at work, innovations which now seem to be within reach of health professionals. This field, unknown to the general public a few years ago, has become an object of all fantasies and is bringing about a new industrial revolution., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88652485,","Title: Data learning from big data, Abstract: Abstract Technology is generating a huge and growing availability of observations of diverse nature. This big data is placing data learning as a central scientific discipline. It includes collection, storage, preprocessing, visualization and, essentially, statistical analysis of enormous batches of data. In this paper, we discuss the role of statistics regarding some of the issues raised by big data in this new paradigm and also propose the name of data learning to describe all the activities that allow to obtain relevant knowledge from this new source of information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84915659,","Title: 빅데이터 처리 프로세스에 따른 빅데이터 위험요인 분석, Abstract: Recently, as value for practical use of big data is evaluated, companies and organizations that create benefit and profit are gradually increasing with application of big data. But specifical and theoretical study about possible risk factors as introduction of big data is not being conducted. Accordingly, the study extracts the possible risk factors as introduction of big data based on literature reviews and classifies according to big data processing, data collection, data storage, data analysis, analysis data visualization and application. Also, the risk factors have order of priority according to the degree of risk from the survey of experts. This study will make a chance that can avoid risks by bid data processing and preparation for risks in order of dangerous grades of risk., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201424750260451,","Title: Big Data, Big Knowledge: Big Data for Personalized Healthcare, Abstract: The idea that the purely phenomenological knowledge that we can extract by analyzing large amounts of data can be useful in healthcare seems to contradict the desire of VPH researchers to build detailed mechanistic models for individual patients. But in practice no model is ever entirely phenomenological or entirely mechanistic. We propose in this position paper that big data analytics can be successfully combined with VPH technologies to produce robust and effective in silico medicine solutions. In order to do this, big data technologies must be further developed to cope with some specific requirements that emerge from this application. Such requirements are: working with sensitive data; analytics of complex and heterogeneous data spaces, including nontextual information; distributed data management under security and performance constraints; specialized analytics to integrate bioinformatics and systems biology information with clinical observations at tissue, organ and organisms scales; and specialized analytics to define the &#x201C;physiological envelope&#x201D; during the daily life of each patient. These domain-specific requirements suggest a need for targeted funding, in which big data technologies for in silico medicine becomes the research priority., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART72452534,","Title: Compromise between Small Data and Big Data, Abstract: Purpose: The main purpose of this work was to present the problems of big data and to present how small data can be used as a complement to big data and its effects step by step in the big data through the concept of value chain. Recently, the big data market is growing rapidly around the world because data is processed on the basis of size, diversity, speed, accuracy and value. Specifically, this study focuses on its application to Jeju tourism. Research design, data, and methodology: The problems of big data were clearly presented using various real-world examples, and the verification of the compromise with small data and its effectiveness were conducted based on research papers discussing Jeju tourism using big data. The results of the study suggested the use of small data to solve and verify the representation of big data at the collection stage of the big data value chain, and the analysis stage suggested combining the identification of behavior patterns, the strengths of small data, and the exploration of causal relationships. Results: Among various stage, in the curation phase, a cause-and-effect analysis using small data suggested a solution to the problem of mistaking the correlation of big data as causality, and in the storage phase, a policy plan using small data was proposed to solve the problem of privacy infringement. The most important part of this study was the application stage, which discussed the specific problems of big data and the possibility of compromise between small data. As well, in the utilization phase, a combination of correlation and causality, as in the curation phase, was proposed. Conclusions: As an implication of this study, we used specific examples to present synergies when big data is compromised with small data. It also showed that the compromised use of big data and small data can contribute not only in terms of research but also in terms of practicality in tourism industry. Finally, we expanded the foundation of research in terms of academic research, discussing the trade-off utilization of big and small data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002721909,","Title: Big Data cluster analysis, Abstract: In this paper, we focused on cluster analysis as the most commonly used technique for grouping different objects. By clustering data, we can extract groups of similar objects from different collections. First, we defined Big Data and clustering to follow the rest of the paper. We presented the most popular techniques for clustering data, including partitioning, hierarchical clustering, density-based clustering, and network-based clustering. Big Data describes large amounts of data. High precision of big data can contribute to decision-making confidence, and better estimates can help increase efficiency, reduce costs, and risks. Various methods and approaches are used for data processing, including clustering, classification, regression, artificial intelligence, neural networks, association rules, decision trees, genetic algorithms, and the nearest neighbor method. A cluster represents a set of objects from the same class, which means that similar objects are grouped together, and different objects are grouped separately. We described the K-means algorithm, hierarchical clustering, density-based clustering -DBSCAN algorithm, and the STING algorithm for network-based clustering., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART131203869,","Title: The Big Student Big Data Grab, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80312419,","Title: Zwangsehen und Bastarde : Wohin steuert Big Data die Wissenschaft?, Abstract: AbstractWhen the word &ldquo;science&rdquo; comes up in the context of big data, one usually thinks of scientists who make accurate predictions about future developments, events and actions by means of sophisticated analyses - or who influence behaviour with surgical precision, such as it is conveyed from Donald Trump's successful election campaign. However, scientists are no longer just agents in big data scenarios, but also objects. The measurement of science today is not only based on simple citation counts or obtained project funds: Commercial actors are creating an entire operating system with integrated tools that continuously record the behaviour of scientists and the performance of science. By describing the transformation of the former publishing house Elsevier to a research intelligence provider this article illustrates how science itself gets into focus of Big Data and what a Big Data driven science could look like., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART82089256,","Title: Les big data, g&eacute;n&eacute;ralit&eacute;s et int&eacute;gration en radioth&eacute;rapie, Abstract: Abstract The many advances in data collection computing systems (data collection, database, storage), diagnostic and therapeutic possibilities are responsible for an increase and a diversification of available data. Big data offers the capacities, in the field of health, to accelerate the discoveries and to optimize the management of patients by combining a large volume of data and the creation of therapeutic models. In radiotherapy, the development of big data is attractive because data are very numerous et heterogeneous (demographics, radiomics, genomics, radiogenomics, etc.). The expectation would be to predict the effectiveness and tolerance of radiation therapy. With these new concepts, still at the preliminary stage, it is possible to create a personalized medicine which is always more secure and reliable., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80146750,","Title: For Big Data, Big Questions Remain, Abstract: Medicare&#x2019;s release of practitioner payments highlights the strengths and weaknesses of digging into big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART70052470,","Title: Sharing Big Data, Abstract: Macromolecular Big Data provide numerous challenges and a number of initiatives that are starting to overcome these issues are discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87118245,","Title: Supporting Privacy-Preserving Big Data Analytics on Temporal Open Big Data, Abstract: Abstract Nowadays, valuable big data are generated and collected rapidly from numerous rich data sources. Following the initiatives of open data, many organizations including municipal governments are willing to share their data such as open big data regarding parking violations. While there have been models to preserve privacy of sensitive personal data like patient data for health informatics, privacy of individuals who violated parking regulations should also be protected. Hence, in this article, we present a model for supporting privacy-preserving big data analytics on temporal open big data. This temporally hierarchical privacy-preserving model (THPPM) adapts and extends the traditional temporal hierarchy to generalize spatial data generated within a time interval with an aim to preserve privacy of individuals who violated parking regulations during some time intervals at certain geographic locations. Evaluation on open big data from two North American cities demonstrates the usefulness of our model in supporting privacy-preserving big data analytics on temporal open big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117405992,","Title: Big business with Big Data Big Business mit Big Data, Abstract: Big business with Big Data Big Business mit Big Data, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART113110241,","Title: Sharing big biomedical data, Abstract: BackgroundThe promise of Big Biomedical Data may be offset by the enormous challenges in handling, analyzing, and sharing it. In this paper, we provide a framework for developing practical and reasonable data sharing policies that incorporate the sociological, financial, technical and scientific requirements of a sustainable Big Data dependent scientific community.FindingsMany biomedical and healthcare studies may be significantly impacted by using large, heterogeneous and incongruent datasets; however there are significant technical, social, regulatory, and institutional barriers that need to be overcome to ensure the power of Big Data overcomes these detrimental factors.ConclusionsPragmatic policies that demand extensive sharing of data, promotion of data fusion, provenance, interoperability and balance security and protection of personal information are critical for the long term impact of translational Big Data analytics., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART80716289,","Title: Protecting Privacy in Big Data, Abstract: In an age of big data, privacy is more essential than ever before, but if we are to protect it effectively, while continuing to enjoy the benefits that big data is already making possible, we need to evolve better, faster, and more scalable mechanisms.The following are the four core elements critical to effective governance of big data.First, a transformation of the current approach to a risk management approach that places more responsibility for data stewardship, and liability for reasonably foreseeable harms, on the users of data rather than using notice and consent to shift the burden to individuals seems critical. This is because a continuing broad reliance on notice and choice at time of collection both under-protects privacy and seriously interferes with—and raises the cost of— subsequent beneficial uses of data.Second, data protection should focus more on uses of big data as opposed to the mere collection or retention of data or the purposes for which data were originally collected. One key reason why a more use-focused approach is necessary to capture the value of big data is that the analysis of big data doesn’t always start with a question or hypothesis, but rather may reveal insights that were never anticipated. As a result, data protection based on a notice specifying intended uses of data and consent for collection based on that notice can result in blocking socially valuable uses of data, lead to meaninglessly broad notices, or require exceptions to the terms under which the individual consented. If privacy protection is instead based on a risk analysis of a proposed use, then it is possible to achieve an optimum benefit from the use of the data and optimum protection for data fine-tuned for each intended use.Third, a risk management approach guided by a broad framework of cognizable harms identified through a transparent, inclusive process is critical to ensuring that individuals are protected and enhancing predictability, accountability, and efficiency.Fourth, a risk management approach that provides meaningful transparency and redress, together with effective enforcement, not only provide remedies for current harms, but also help to prevent future ones.Moreover, it is an essential requirement for responsible use of big data.There are likely many other measures that also will be useful, but these four are critical to protecting privacy while unlocking the potential of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001996011,","Title: Demystifying big data: Anatomy of big data developmental process, Abstract: This study seeks to understand big data ecology, how it is perceived by different stakeholders, the potential value and challenges, and the implications for the private sector and public organizations, as well as for policy makers. With Normalization Process Theory in place, this study conducts socio-technical evaluation on the big data phenomenon to understand the developmental processes through which new practices of thinking and enacting are implemented, embedded, and integrated in South Korea. It also undertakes empirical analyses of user modeling to explore the factors influencing users' adoption of big data by integrating cognitive motivations as well as user values as the primary determining factors. Based on the qualitative and quantitative findings, this study concludes that big data should be developed with user-centered ideas and that users should be the focus of big data design. (C) 2015 Elsevier Ltd. All rights reserved., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76320729,","Title: O&ugrave; en est t’on du Big Data en m&eacute;decine ?, Abstract: Abstract Opening of medical datas and files is nowadays an important challenge. French Government increments new rules to allow access to these data files., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART84922598,","Title: Big Data vs. Privacy Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100455235,","Title: Big Building Data - a Big Data Platform for Smart Buildings, Abstract: Abstract Future buildings will more and more rely on advanced Building Management Systems (BMS) connected to a variety of sensors, actuators and dedicated networks. Their objectives are to observe the state of rooms and apply automated rules to preserve or increase comfort while economizing energy. In this work, we advocate for the inclusion of a dedicated system for sensors data storage and processing, based on Big Data technologies. This choice enables new potentials in terms of data analytics and applications development, the most obvious one being the ability to scale up seamlessly from one smart building to several, in the direction of smart areas and smart cities. We report in this paper on our system architecture and on several challenges we met in its elaboration, attempting to meet requirements of scalability, data processing, flexibility, interoperability and privacy. We also describe current and future end-user services that our platform will support, including historical data retrieval, visualisation, processing and alarms. The platform, called BBData - Big Building Data, is currently in production at the Smart Living Lab of Fribourg and is offered to several research teams to ease their work, to foster the sharing of historical data and to avoid that each project develops its own data gathering and processing pipeline., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78534763,","Title: Big data driven smart energy management: From big data to big insights, Abstract: Abstract Large amounts of data are increasingly accumulated in the energy sector with the continuous application of sensors, wireless transmission, network communication, and cloud computing technologies. To fulfill the potential of energy big data and obtain insights to achieve smart energy management, we present a comprehensive study of big data driven smart energy management. We first discuss the sources and characteristics of energy big data. Also, a process model of big data driven smart energy management is proposed. Then taking smart grid as the research background, we provide a systematic review of big data analytics for smart energy management. It is discussed from four major aspects, namely power generation side management, microgrid and renewable energy management, asset management and collaborative operation, as well as demand side management (DSM). Afterwards, the industrial development of big data-driven smart energy management is analyzed and discussed. Finally, we point out the challenges of big data-driven smart energy management in IT infrastructure, data collection and governance, data integration and sharing, processing and analysis, security and privacy, and professionals., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74782503,","Title: Nursing Needs Big Data and Big Data Needs Nursing, Abstract: AbstractPurposeContemporary big data initiatives in health care will benefit from greater integration with nursing science and nursing practice; in turn, nursing science and nursing practice has much to gain from the data science initiatives. Big data arises secondary to scholarly inquiry (e.g., &#8208;omics) and everyday observations like cardiac flow sensors or Twitter feeds. Data science methods that are emerging ensure that these data be leveraged to improve patient care.Organizing ConstructBig data encompasses data that exceed human comprehension, that exist at a volume unmanageable by standard computer systems, that arrive at a velocity not under the control of the investigator and possess a level of imprecision not found in traditional inquiry. Data science methods are emerging to manage and gain insights from big data.MethodsThe primary methods included investigation of emerging federal big data initiatives, and exploration of exemplars from nursing informatics research to benchmark where nursing is already poised to participate in the big data revolution. We provide observations and reflections on experiences in the emerging big data initiatives.ConclusionsExisting approaches to large data set analysis provide a necessary but not sufficient foundation for nursing to participate in the big data revolution. Nursing's Social Policy Statement guides a principled, ethical perspective on big data and data science. There are implications for basic and advanced practice clinical nurses in practice, for the nurse scientist who collaborates with data scientists, and for the nurse data scientist.Clinical RelevanceBig data and data science has the potential to provide greater richness in understanding patient phenomena and in tailoring interventional strategies that are personalized to the patient., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76701778,","Title: Optimized Data Processing Analysis Using Big Data Cloud Platform, Abstract: Recently data processing has main gained many attention both from academic and commercial industry. Their term use to tools, technical methods and frameworks made to gathering, collect, store, processing and analysis massive amounts of data. Data processing and analysis are based on structured/semi -structured/unstructured by big data, as well as is generated from various different sources in the system at various rates. For the purpose of processing with their large data and suitable way, voluminous parallelism is usually used. The general architecture of a big data system is made up a shared cluster of their machines. Nonetheless, even in very parallel environment, data processing is often very time-consuming. A various applications can take up to everytime to produce useful results, interactive analysis and debugging. Nevertheless, we have main problems that how we have a high performance requires both quality of data locality and resource. Moreover, big data analysis provide the amount of data that is processed typically large in comparison with computation in their systems. In other words, specified optimization that would relieve low-level to achieve good performance essentially. Accordingly, our main goal of this research paper provide how we have to do to optimize for big data frameworks. Our contribute approach to make big data cloud platform for easy and efficient processing of big data. In addition, we provides results from a study of existing optimization of data processing in MapReduce and Hadoop oriented systems., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002687869,","Title: Big Data in Building Energy Efficiency: Understanding of Big Data and Main Challenges, Abstract: Data generation has increased drastically over the past few years. Data management has also grown in importance because extracting the significant value out of a huge pile of raw data is of prime important thing to make different decisions. One of the important sectors nowadays is construction sector, especially building energy efficiency field. Collecting big amount of data, using different kinds of big data analysis can help to improve construction process from the energy efficiency perspective. This article reviews the understanding of Big Data, methods used for Big Data analysis and the main problems with Big Data in the field of energy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART77423550,","Title: Big data, big data quality problem, Abstract: A USAF sponsored MITRE research team undertook four separate, domain-specific case studies about Big Data applications. Those case studies were initial investigations into the question of whether or not data quality issues encountered in Big Data collections are substantially different in cause, manifestation, or detection than those data quality issues encountered in more traditionally sized data collections. The study addresses several factors affecting Big Data Quality at multiple levels, including collection, processing, and storage. Though not unexpected, the key findings of this study reinforce that the primary factors affecting Big Data reside in the limitations and complexities involved with handling Big Data while maintaining its integrity. These concerns are of a higher magnitude than the provenance of the data, the processing, and the tools used to prepare, manipulate, and store the data. Data quality is extremely important for all data analytics problems. From the study's findings, the 'truth about Big Data' is there are no fundamentally new DQ issues in Big Data analytics projects. Some DQ issues exhibit return-s-to-scale effects, and become more or less pronounced in Big Data analytics, though. Big Data Quality varies from one type of Big Data to another and from one Big Data technology to another., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12215719,","Title: Big Data Smoothing and Outlier Removal for Patent Big Data Analysis, Abstract: In general statistical analysis, we need to make a normal assumption. If this assumption is not satisfied, we cannot expect a good result of statistical data analysis. Most of statistical methods processing the outlier and noise also need to the assumption. But the assumption is not satisfied in big data because of its large volume and heterogeneity. So we propose a methodology based on box-plot and data smoothing for controling outlier and noise in big data analysis. The proposed methodology is not dependent upon the normal assumption. In addition, we select patent documents as target domain of big data because patent big data analysis is a important issue in management of technology. We analyze patent documents using big data learning methods for technology analysis. The collected patent data from patent databases on the world are preprocessed and analyzed by text mining and statistics. But the most researches about patent big data analysis did not consider the outlier and noise problem. This problem decreases the accuracy of prediction and increases the variance of parameter estimation. In this paper, we check the existence of the outlier and noise in patent big data. To know whether the outlier is or not in the patent big data, we use box-plot and smoothing visualization. We use the patent documents related to three dimensional printing technology to illustrate how the proposed methodology can be used for finding the existence of noise in the searched patent big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201626360541485,","Title: Big Data ethics, Abstract: The speed of development in Big Data and associated phenomena, such as social media, has surpassed the capacity of the average consumer to understand his or her actions and their knock-on effects. We are moving towards changes in how ethics has to be perceived: away from individual decisions with specific and knowable outcomes, towards actions by many unaware that they may have taken actions with unintended consequences for anyone. Responses will require a rethinking of ethical choices, the lack thereof and how this will guide scientists, governments, and corporate agencies in handling Big Data. This essay elaborates on the ways Big Data impacts on ethical conceptions. , Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88626207,","Title: Big Data Misuse and European Contract Law, Abstract: AbstractThe dynamics of contractual interactions have been evolving in recent years, as big data introduces new dimensions to previously conventional contracts. This development intensifies the information asymmetry between the dominant and vulnerable parties, posing increasing challenges for consumers and the entirety of European contract law. This paper offers three main contributions to this discourse. First, the utilization of big data introduces a novel form of information asymmetry between contracting parties, further empowering the already dominant party while exacerbating the vulnerability of the weaker party. Second, contemporary European case law and legal scholarship advocate for a harmonious approach in which European regulations and national remedies complement one another in protecting individuals. Lastly, there are already instances indicating the misuse of big data, where multiple individual claims may arise at both European and national levels., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART132663034,","Title: Big data? Big deal: Searching for big data’s performance effects in HR, Abstract: Abstract Big data continues to gather increasing interest in the business press as well as within the management literature. While this interest has spilled over into the realm of human resources (HR) management, solid evidence of its positive performance impacts is lacking. I explore three possibilities for this lack of evidence: (1) HR possesses big data but largely lacks the ability to use it; (2) HR does not actually possess big data; and (3) big data is generating value for HR and positively affects organizational performance, but the winners in the race to utilize big data in HR are not publicizing their successes. Following this, I discuss current forms of big data implementation, highlighting an evolutionary progression of implementations in various settings and emphasizing the importance of balancing deductive with inductive analytical approaches. Finally, I discuss conditions under which big data may hold greater value for the HR function, and I suggest ways managers and organizations can make the most of big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART112101193,","Title: &#x201e;Massendinghaltung“ oder &#x201e;Big Data“?, Abstract: SummaryThe tenor of the conference &#x201e;Massendinghaltung in der Arch&auml;ologie&ldquo; held in Berlin from 23rd to 25th May 2013 shows that many archaeologists, especially those with a theoretical orientation, are very negative towards large collections of objects and their evaluation. This was taken as an opportunity to present five examples from the Roman Period, based on the author&rsquo;s own data collection, which cannot be meaningfully processed without large collections of material. First of all, there are copper-plated iron objects, in which two already known belt boxes are joined by an Almgren group VII-fibula and a small bucket-shaped necklace pendant. They show that copper plating was also possible in germanic fine forges. A discovery of petrified sea urchins (echinites) shows that such quite rare find objects have not been worked on so far, as they seem to be of little value and the research effort for these objects might be considered too high. As a third example, vessels with button-handels (Knopfhenkelgef&auml;ße) were selectet. A type of vessel that has already been worked on. With the help of a database-supported recording of meanwhile more than 28,500 grave inventories as well as further literature research, the existing find image can be checked, supplemented and, if necessary, extended. As a fourth example the frequently occurring amber finds are presented. Apart from Tempelmann-M&aogon;czy&nacute;skas&rsquo;s work on pearls, no attempt has yet been made to deal with this object category on a supra-regional level. Due to their work, one had a rather tolerable impression of the occurrence of this find category, especially concerning Germany. The repeatedly expressed opinion that amber could not be found in cremations, because it would have been burnt, is a topos. A clear focus in the Elbe-Saale area shows a region that either appears early as a customer or even as a middleman for the period from the 3rd century onwards. Finally, thanks to a large number of settlement and especially cemetery publications, statistical analyses of population sizes and demographic changes are now possible, as can be illustrated by the two examples of eastern Holstein and the Altmark.De nombreuses publications de recueils de donn&eacute;es sont d&eacute;sormais omnipr&eacute;sentes dans l&rsquo;arch&eacute;ologie. Outre les mus&eacute;es qui rendent accessibles au public une partie de leurs collections, de nombreuses bases de donn&eacute;es sp&eacute;cialis&eacute;es, par exemple sur les terra sigillata ou les pi&egrave;ces de monnaie, sont &eacute;galement disponibles en ligne. Dans certains pays, comme la Norv&egrave;ge, une grande partie des d&eacute;couvertes arch&eacute;ologiques sont syst&eacute;matiquement publi&eacute;es dans une base de donn&eacute;es en ligne pour une exploitation ult&eacute;rieure.L&rsquo;&eacute;valuation automatis&eacute;e de grands ensembles de donn&eacute;es non tri&eacute;es, qui est associ&eacute;e &agrave; l&rsquo;expression &#x201e;Big data&ldquo;, a d&eacute;j&agrave; &eacute;t&eacute; utilis&eacute;e de mani&egrave;re judicieuse &agrave; plusieurs reprises, comme le montre le projet NEOMINE ou le projet &#x201e;ancient places&ldquo; d&rsquo;Alphabet Inc. Un rejet global de grandes collections d&rsquo;objets et de donn&eacute;es reste incompr&eacute;hensible au vu des possibilit&eacute;s et surtout des m&eacute;thodes d&eacute;j&agrave; &eacute;tablies dans les sciences naturelles et devrait &ecirc;tre reconsid&eacute;r&eacute; en faveur d&rsquo;une vision plus objective et, bien s&ucirc;r, non d&eacute;pourvue d&rsquo;esprit critique des nouvelles m&eacute;thodes de recherche., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114667343,","Title: Big data, Big bang?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART87473477,","Title: Big Data Key Challenges, Abstract: The big data term refers to the great volume of data and complicated data structure with difficulties in collecting, storing, processing, and analyzing these data. Big data analytics refers to the operation of disclosing hidden patterns through big data. This information and data set cloud to be useful and provide advanced services. However, analyzing and processing this information could cause revealing and disclosing some sensitive and personal information when the information is contained in applications that are correlated to users such as location-based services, but concerns are diminished if the applications are correlated to general information such as scientific results. In this work, a survey has been done over security and privacy challenges and approaches in big data. The challenges included here are in each of the following areas: privacy, access control, encryption, and authentication in big data. Likewise, the approaches presented here are privacy-preserving approaches in big data, access control approaches in big data, encryption approaches in big data, and authentication approaches in big data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213341752833,","Title: BIG DATA = CLEAR + DIRTY + DARK DATA, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART78685258,","Title: Statistik, Data Science und Big Data, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART76603656,","Title: Synchrotron Big Data Science, Abstract: AbstractThe rapid development of synchrotrons has massively increased the speed at which experiments can be performed, while new techniques have increased the amount of raw data collected during each experiment. While this has created enormous new opportunities, it has also created tremendous challenges for national facilities and users. With the huge increase in data volume, the manual analysis of data is no longer possible. As a result, only a fraction of the data collected during the time&#8208; and money&#8208;expensive synchrotron beam&#8208;time is analyzed and used to deliver new science. Additionally, the lack of an appropriate data analysis environment limits the realization of experiments that generate a large amount of data in a very short period of time. The current lack of automated data analysis pipelines prevents the fine&#8208;tuning of beam&#8208;time experiments, further reducing their potential usage. These effects, collectively known as the &ldquo;data deluge,&rdquo; affect synchrotrons in several different ways including fast data collection, available local storage, data management systems, and curation of the data. This review highlights the Big Data strategies adopted nowadays at synchrotrons, documenting this novel and promising hybridization between science and technology, which promise a dramatic increase in the number of scientific discoveries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91047593,","Title: Why Big Data = Big Deal, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69962531,","Title: Exploring Big Data Governance Frameworks, Abstract: Abstract The recent explosion in ICT and digital data has led organizations, both private and public, to efficient decision-making. Nowadays organizations can store huge amounts of data, which can be accessible at any time. Big Data governance refers to the management of huge volumes of an organization&rsquo;s data, exploiting it in the organization&rsquo;s decision-making using different analytical tools. Big Data emergence provides great convenience, but it also brings challenges. Nevertheless, for Big Data governance, data has to be prepared in a timely manner, keeping in view the consistency and reliability of the data, and being able to trust its source and the meaningfulness of the result. Hence, a framework for Big Data governance would have many advantages. There are Big Data governance frameworks, which guide the management of Big Data. However, there are also limitations associated with these frameworks. Therefore, this study aims to explore the existing Big Data governance frameworks and their shortcomings, and propose a new framework. The proposed framework consists of eight components. As a framework validation, the proposed framework has been compared with the ISO 8000 data governance framework., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART91115436,","Title: Big Data 2.0, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001707649,","Title: Big genetic data and its big data protection challenges, Abstract: Abstract The use of various forms of big data have revolutionised scientific research. This includes research in the field of genetics in areas ranging from medical research to anthropology. Developments in this area have inter alia been characterised by the ability to sequence genome wide sequences (GWS) cheaply, the ability to share and combine with other forms of complimentary data and ever more powerful processing techniques that have become possible given tremendous increases in computing power. Given that many if not most of these techniques will make use of personal data it is necessary to take into account data protection law. This article looks at challenges for researchers that will be presented by the EU's General Data Protection Regulation, which will be in effect from May 2018. The very nature of research with big data in general and genetic data in particular means that in many instances compliance will be onerous, whilst in others it may even be difficult to envisage how compliance may be possible. Compliance concerns include issues relating to &lsquo;purpose limitation&rsquo;, &lsquo;data minimisation&rsquo; and &lsquo;storage limitation&rsquo;. Other requirements, including the need to facilitate data subject rights and potentially conduct a Data Protection Impact Assessment (DPIA) may provide further complications for researchers. Further critical issues to consider include the choice of legal base: whether to opt for what is often seen as the &lsquo;default option&rsquo; (i.e. consent) or to process under the so called &lsquo;scientific research exception&rsquo;. Each presents its own challenges (including the likely need to gain ethical approval) and opportunities that will have to be considered according to the particular context in question., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART89948854,","Title: Big Data in der amtlichen Statistik, Abstract: The concept of 'big data' stands to change the face of official statistics over the coming years, having an impact on almost all aspects of data production. The tasks of future statisticians will not necessarily be to produce new data, but rather to identify and make use of existing data to adequately describe social and economic phenomena. Until big data can be used correctly in official statistics, a lot of questions need to be answered and problems solved: the quality of data, data protection, privacy, and the sustainable availability are some of the more pressing issues to be addressed. The essential skills of official statisticians will undoubtedly change, and this implies a number of challenges to be faced by statistical education systems, in universities, and inside the statistical offices. The national statistical offices of the European Union have concluded a concrete strategy for exploring the possibilities of big data for official statistics, by means of the Big Data Roadmap and Action Plan 1.0. This is an important first step and will have a significant influence on implementing the concept of big data inside the statistical offices of Germany., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART74180896,","Title: Big data monetization throughout Big Data Value Chain: a comprehensive review, Abstract: AbstractValue Chain has been considered as a key model for managing efficiently value creation processes within organizations. However, with the digitization of the end-to-end processes which began to adopt data as a main source of value, traditional value chain models have become outdated. For this, researchers have developed new value chain models, called Data Value Chains, to carry out data driven organizations. Thereafter, new data value chains called Big Data Value chain have emerged with the emergence of Big Data in order to face new data-related challenges such as high volume, velocity, and variety. These Big Data Value Chains describe the data flow within organizations which rely on Big Data to extract valuable insights. It is a set of ordered steps using Big Data Analytics tools and mainly built for going from data generation to knowledge creation. The advances in Big Data and Big Data Value Chain, using clear processes for aggregation and exploitation of data, have given rise to what is called data monetization. Data monetization concept consists of using data from an organization to generate profit. It may be selling the data directly for cash, or relying on that data to create value indirectly. It is important to mention that the concept of monetizing data is not as new as it looks, but with the era of Big Data and Big Data Value Chain it is becoming attractive. The aim of this paper is to provide a comprehensive review of value creation, data value, and Big Data value chains with their different steps. This literature has led us to construct an end-to-end exhaustive BDVC that regroup most of the addressed phases. Furthermore, we present a possible evolution of that generic BDVC to support Big Data Monetization. For this, we discuss different approaches that enable data monetization throughout data value chains. Finally, we highlight the need to adopt specific data monetization models to suit big data specificities., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101331280,","Title: Utilization and Analysis of Big-data, Abstract: This study reviews the analysis and characteristics of databases from big data and then establishes representational strategy. Thus, analysis has continued for a long time in the quantity and quality of data, and there are changes in the location of data in the social sciences, past trends and the emergence of big data. The introduction of big data is presented as a prototype of new social science and is a useful practical example that empirically shows the need, basis, and direction of analysis through trend prediction services. Big data provides a future perspective as an important foundation for social change within the framework of basic social sciences., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543001",19,1.1859924140007934,"## 제조 품질 개선을 위한 데이터 기반 접근법 분석 보고서

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 제조 품질 개선을 위한 식스 시그마 기반 Big Data 활용 방법의 주요 절차를 분석합니다.  제공된 문서들은 식품, 화학, 플라스틱 제조 등 다양한 분야의 품질 관리 및 개선 사례를 다루고 있으나, 식스 시그마 기반 Big Data 활용에 대한 명시적인 절차는 제시하고 있지 않습니다. 따라서 본 보고서는 각 문서에서 제시된 데이터 기반 품질 관리 및 예측 시스템 구축 방식을 분석하여, 일반적인 데이터 기반 제조 품질 개선 접근법을 유추하고자 합니다.

**본론:**

제공된 문서들은 제조 품질 개선을 위해 다양한 데이터 기반 접근법을 활용하고 있음을 보여줍니다.  구체적으로 다음과 같은 사례들이 존재합니다.

* **문서 1 (사출제품 품질 예측):** 사출 성형 공정에서 캐비티 압력과 온도를 실시간으로 모니터링하여 제품 품질(숏 샷, 휨 등)을 예측하는 시스템을 제안합니다. 이는 센서 측정, 신호 데이터 수집, 상태 모니터링의 3단계 구조로 이루어져 있으며, 일반적인 상태 기반 유지보수(CBM) 접근법을 기반으로 합니다.  이 시스템은 실시간 데이터 분석을 통해 품질 문제를 예측하고 사전에 대응하는 데이터 기반의 예측적 품질 관리 시스템입니다.

* **문서 3 (우엉가루 첨가 조청의 품질 특성):** 우엉가루 첨가량에 따른 조청의 일반 성분, 당도, 색도, 텍스처, 항산화성 등을 분석하여 최적의 우엉가루 첨가 비율을 도출합니다.  다양한 품질 특성에 대한 데이터를 수집하고 분석하여 최적의 제품 품질을 달성하는 것을 목표로 합니다.  이 연구는 실험 설계를 통한 데이터 수집 및 통계적 분석을 통해 품질 개선을 도모하는 전형적인 접근법을 보여줍니다.

* **문서 4 (흑마늘 화장품의 피부 미용 효과):** 흑마늘 및 생마늘 첨가 화장품의 안정성, 항산화, 주름 개선, 미백 효과를 다양한 실험(in vitro, in vivo)을 통해 측정하고 비교 분석합니다.  실험 결과 데이터를 바탕으로 흑마늘 화장품의 기능성을 평가하고 품질을 개선하는 방향을 제시합니다.  이 연구 또한 실험 데이터를 기반으로 제품 품질을 평가하고 개선하는 데이터 기반 접근법을 사용합니다.

* **문서 5 (김치 제조 방법에 따른 김치의 특성 비교):**  기존 포기김치와 새로운 낱개김치 제조 방법의 품질 특성을 비교 분석합니다.  pH, 산도, 미생물 수, 관능 검사, 기체 조성 등 다양한 데이터를 측정하여 두 제조 방법의 차이점과 개선 방향을 제시합니다. 이는 제조 공정 변화에 따른 품질 변화를 데이터로 분석하여 최적의 공정을 찾는 접근법을 보여줍니다.


위 사례들을 종합적으로 고려하면, 데이터 기반 제조 품질 개선은 다음과 같은 일반적인 절차를 따릅니다.

1. **데이터 수집:**  품질에 영향을 미치는 다양한 변수(원재료, 공정 변수, 환경 변수 등)를 측정하고 데이터를 수집합니다.
2. **데이터 분석:** 수집된 데이터를 통계적 방법이나 머신러닝 기법 등을 활용하여 분석하고, 품질에 영향을 미치는 주요 요인을 파악합니다.
3. **품질 예측 및 최적화:** 분석 결과를 바탕으로 품질을 예측하고, 제조 공정이나 원재료 등을 최적화하여 품질을 개선합니다.
4. **모니터링 및 관리:** 개선된 공정을 지속적으로 모니터링하고 관리하여 품질을 유지합니다.


**결론:**

제공된 문서들은 식스 시그마 기반 Big Data 활용에 대한 명시적인 절차는 제시하지 않지만, 다양한 제조 분야에서 데이터 기반의 품질 관리 및 개선 시스템을 구축하고 활용하고 있음을 보여줍니다.  데이터 수집, 분석, 예측 및 최적화, 그리고 지속적인 모니터링 및 관리라는 일반적인 절차를 통해 제조 품질을 개선하고 있습니다.  각 문서에서 제시된 구체적인 방법론은 제조 분야와 제품 특성에 따라 다르지만, 데이터 기반의 과학적인 접근법을 통해 품질 개선을 달성하고자 하는 공통된 목표를 가지고 있습니다.",사출제품의 품질 예측을 위한 상태기반의 모니터링 시스템,화학적 박리법에 의한 그래핀 제조 및 응용에 관한 연구,우엉가루를 첨가한 조청의 품질 특성,"항산화, 주름개선 및 미백 효능에 대한 흑마늘 화장품의 피부미용 효과",김치 제조 방법에 따른 김치의 특성 비교,천년초 뿌리를 이용한 맥주의 품질 특성 연구,품질보증시스템 인증 획득기업에서 품질향상 요인 분석에 관한 실증적 연구,서비스품질 측정척도 개선에 관한 연구,내열 점착 특성 폴리이미드의 제조,금속촉매를 이용한 물로부터 수소제조,계란 품질 측정 방식 비교 연구,데이터 구조 품질 평가 방안에 관한 연구 : 데이터 아키텍처 구축을 중심으로,노인장기요양보험제도 개선방안 연구,이데베논 함유 세럼의 주름개선 효과,청국장 발효용 우수 균주 선발 및 이를 이용한 기능성 청국장 제조,커피추출물을 첨가한 요거트의 품질 및 항산화 특성,동결건조 연근 분말을 첨가한 머핀의 품질특성,"기업지배구조와 감사품질, 경영성과의 관련성에 대한 실증연구","우리밀, 중국밀과 수입밀의 품질 특성 비교",간호사의 투약오류 분석 및 개선방안,노인장기요양보험제도의 개선 방안 : 동해시 재가요양기관을 중심으로,오크라(Okra)첨가 요거트(Yogert)의 최적제조에 관한 연구,다양한 반응조건에서의 키토산 제조,음식물쓰레기를 이용한 활성탄 제조 및 흡착특성,쇄상 규산염(Chain silicate) 결정화 유리의 제조 및 기계적 특성,고혈압 환자에서 생활습관 개선 프로그램의 혈압개선 효과,연잎 추출물의 여드름 피부 개선 효과,경유차 환경개선부담금제도의 개선방안 연구,전기기관차용 살사브라켓의 구조 설계를 통한 안전성 개선 연구,배수개선 사업의 효과적 추진방안,,,,,,,,,,,,,,,,,,,,
Could you summarize how deep learning techniques are envisioned to enhance radar imaging and the main challenges and proposed network architecture discussed?,"##Deep Learning for Radar## ##Introduction## Advances in deep learning offer new opportunities to improve radar imaging beyond traditional automatic target recognition. By integrating neural network models with established radar signal processing, researchers aim to capture complex non-linearities and adaptively compensate for system imperfections. ##Main Body## Deep learning is envisioned to play a central role across a wide range of radar imaging challenges, including synthetic aperture radar (SAR) image formation and autofocus. Key hurdles include the scarcity of labeled radar data, the need to respect the physics of the SAR forward model, and the requirement to mitigate phase errors caused by platform motion. To address these, a hybrid network architecture is proposed that embeds traditional SAR modeling blocks within a deep learning framework: the network learns to approximate the non-linear inversion of the SAR forward operator while leveraging analytic layers for known propagation effects. Additionally, the model is trained to predict and correct trajectory-based phase distortions, improving autofocus performance without relying solely on handcrafted algorithms. ##Conclusion## By combining deep learning’s data-driven learning with established SAR theory, the proposed approach promises enhanced image clarity and robustness to motion errors. Overcoming data limitations and ensuring model fidelity to radar physics are critical for realizing these gains in practical radar systems.",없음,없음,"Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",20,1.1859924140007934,"**Title:** Deep Learning for Enhanced Radar Imaging: Applications, Challenges, and Architectural Design

**Introduction:**

This report addresses the application of deep learning techniques to enhance radar imaging, specifically focusing on the vision presented in Document 1 (""Deep learning for radar"") and the challenges associated with its implementation.  The report will detail the proposed network architecture and the key challenges in applying deep learning to this domain.

**Body:**

Document 1 (""Deep learning for radar"") proposes a vision for leveraging deep learning to improve radar imaging, primarily within the context of synthetic aperture radar (SAR). The authors argue that deep learning's potential extends beyond automatic target recognition (ATR), significantly advancing the state-of-the-art across a broad spectrum of radar imaging problems.  A key contribution lies in their proposed network architecture designed specifically for the SAR imaging problem. This architecture integrates traditional SAR modeling with deep learning, effectively capturing the non-linearity inherent in the SAR forward model.  This approach allows for learning and compensation of trajectory-based phase errors, a significant improvement in addressing the autofocus problem. The document highlights that this framework augments learning with traditional SAR modelling.

While Document 1 focuses on the application of deep learning to radar imaging, Document 2 (""Machine learning on Big Data"") provides relevant context concerning the broader landscape of machine learning.  It emphasizes the increasing importance of scale in achieving high-quality modeling, a factor that is crucial when dealing with the potentially massive datasets involved in radar imaging. The computational models and workflows required for large-scale machine learning applications are also highlighted, suggesting a necessary consideration for the successful implementation of deep learning in this field.

The challenges associated with applying deep learning to radar imaging are not explicitly detailed in the provided documents. However, the implicit challenges are numerous.  Document 5 (""Evaluation of perineal rehabilitation techniques"") while unrelated to radar imaging, highlights the difficulties encountered in evaluating techniques due to inconsistent populations, protocols, a lack of data standardization, and methodological shortcomings in statistical analysis. These issues serve as an analog for the challenges researchers might anticipate when evaluating the efficacy and generalizability of deep learning models in the context of radar imaging.  The complexity of the SAR forward model, potentially large data requirements, and the need for robust validation methods would likely present considerable hurdles.


**Conclusion:**

Deep learning offers significant potential for enhancing radar imaging, particularly in the context of SAR.  Document 1 proposes a promising network architecture that combines traditional SAR modeling with deep learning to address the non-linearity of the forward model and compensate for phase errors. However, successful implementation requires careful consideration of the challenges related to data scale, standardization, and robust methodological evaluation, drawing parallels from experiences in other fields as highlighted in Document 5. The integration of deep learning with established SAR modeling techniques, as envisioned in Document 1, represents a key step towards advancing radar imaging capabilities.  Document 2's emphasis on scale in machine learning underscores the importance of large datasets and efficient computational methods for successful implementation.",Deep learning for radar,Machine learning on Big Data,How Algeria Could Survive the Arab Spring? Governance Perspective,Spinal Cord Injury: How Could Acupuncture Help?,Evaluation of perineal rehabilitation techniques,What Could I have Done Differently?,"Electrokinetic techniques, their enhancement techniques and composite techniques with other processes for persistent organic pollutants remediation in soil: A review",Foetal sampling techniques,Foetal sampling techniques,Could DCT Reveal Photorealistic Images?,Zebrafish toxicological screening could aid Leishmaniosis drug discovery,이러닝 학습환경이 이러닝 학습만족도에 미치는 영향 분석,Understanding Art Deco Lacquer Techniques by Jean Dunand through Japanese Regional Urushi Techniques,Imputation Techniques in Microsimulation,Learning analytics sources: Beyond learning platforms,A Study on Jazz Vocal Variation Techniques -Focusing on Jazz Ballad Style Techniques-,Techniques for pelvic ring reduction,Could Arthroscopes be Better?,딥러닝 알고리즘에 기반한 기업부도 예측,바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사,딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구,Machine learning and docking studies of cytochrome P450 ligands,Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators,Could all laboratory animal use could be ended by the year 2020?,딥 러닝을 이용한 DC 모터 제어,Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서,Could Alice equalize student learning?,What motor cars could be,What Motor Cars Could Be,Bio-textual deep web search system based on keyword networks : 키워드 네트워크에 기반한 바이오텍스트 딥웹 검색 시스템,딥 러닝기반 고객평점 예측모델,= Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어,눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식,Cartographic Techniques,Cartographic Techniques,Employee problems you never envisioned.,Hotel tower envisioned for Baghdad,New Products Envisioned,PACS re-envisioned.,Closer oversight of EELV envisioned,Fetal ovary transplant is envisioned.,Technology Envisioned: Lichtenstein's Monocularity,"Space Shuttle Revisited, Re-envisioned",Lobster-Eye X-ray Telescope Envisioned,CERAMIC MATERIALS STRONGER THAN STEEL ENVISIONED,,,,,
"Can you provide a concise overview of the comparison between deep learning and deep reinforcement learning for complex image analysis, highlighting their strengths and weaknesses?","##Comparison of Deep Reinforcement Learning and Deep Learning for Complex Image Analysis## ##Introduction## Complex image analysis tasks—such as histopathological slide interpretation—require powerful feature extraction to support accurate diagnosis. Convolutional neural networks (CNNs) have driven major advances in segmentation, detection, and tumor classification, but they depend on large, well‐annotated datasets and often lose spatial context when applied patchwise. Deep reinforcement learning (DRL) has emerged as an alternative that learns policies to navigate and analyze images without exhaustive annotations, potentially preserving contextual information. ##Main Body## Deep learning excels at hierarchical feature learning and benefits from mature frameworks and GPU acceleration; however, it struggles with gigabyte‐scale images, adversarial input variations, and the patch‐based multi‐instance learning (MIL) approach’s tendency to fragment context. DRL formulates image analysis as a sequential decision problem, enabling models to selectively attend to informative regions and learn from limited data while maintaining spatial coherence. This reinforcement approach reduces reliance on localized labels and mitigates data scarcity, though it demands careful reward function design and often incurs greater computational cost during training. ##Conclusion## While deep learning remains the primary choice for segmentation and classification when plentiful annotated data exist, deep reinforcement learning offers a promising complement in scenarios with limited labels and extremely large images, preserving contextual integrity and enabling more adaptive feature extraction.",없음,없음,"Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",21,1.1859924140007934,"**Title:**  A Comparative Analysis of Deep Learning and Deep Reinforcement Learning: Applicability to Complex Image Analysis (Based on Provided Literature)


**Introduction:**

This report addresses the comparison between deep learning (DL) and deep reinforcement learning (DRL) in the context of complex image analysis.  While the provided documents do not directly compare these two methods, they offer insights into the principles of model conciseness, dynamic system analysis, and the challenges of handling diverse and evolving data—all relevant considerations when choosing between DL and DRL for complex image tasks.


**Body:**

The provided literature focuses primarily on different aspects of model development and analysis, rather than a direct comparison of DL and DRL for image analysis.  However, we can extrapolate relevant information.  Document 1 highlights the complexities of web standardization, emphasizing the dynamic and heterogeneous nature of web data.  This characteristic mirrors the challenges in complex image analysis, where data can be diverse and evolve over time.  The need for concise models (Documents 3 and 4) is also crucial, as both DL and DRL can produce large, complex models.  Document 4's discussion of testing for concise representations directly relates to the need for efficient and interpretable models, a consideration when applying both DL and DRL.  Efficient models are particularly important in image analysis due to the often massive datasets involved.

Document 2, focusing on smart grid stability, underscores the importance of robust model design, particularly when dealing with heterogeneous agents.  In image analysis, this translates to dealing with variability in image content, styles, and quality. The methods for achieving concise and robust models—systematic assumption identification, data-mining techniques, and rigorous testing—are applicable to both DL and DRL in image analysis.  The use of decision trees to gain insights, as described in Document 2, is a model-simplification technique that could be applied in interpreting results from both DL and DRL approaches.

While Document 5 explores neural correlates of social comparison, the focus on uncovering underlying mechanisms and identifying domain-specific components is relevant to both DL and DRL approaches.  Understanding how specific neural networks (analogous to DL and DRL architectures) function allows for more targeted model development and refinement.


**Conclusion:**

Although the provided documents do not explicitly compare deep learning and deep reinforcement learning for complex image analysis, they offer key insights into the development and evaluation of machine learning models in complex, dynamic settings. The need for concise models, robust design in the face of heterogeneous data, and rigorous testing are crucial aspects of both DL and DRL applications in image analysis.  Further research directly comparing these two approaches with specific image analysis tasks is required for a more complete understanding of their respective strengths and weaknesses.  The principles of conciseness, data-driven model refinement, and systematic evaluation, as highlighted in the provided literature, are crucial regardless of the chosen approach.",Web Standardization: An Overview,Towards Concise Models of Grid Stability,Concise Equations for Rotor Dynamics Analysis,Testing for Concise Representations,The Neural Correlates of Intelligence Comparison,Periphrastic comparison in Latin,Interactions Between Two Sedimenting Particles With Different Sizes,CATAQ: Concise Answer to any Question,Financial Development in Vietnam: An Overview,"Between theatre and photography, between photography and performance, between performance and theatre",Concise Recommendations for EDitorials: Enhancing Narratives and Composition Effectively (CREDENCE),DVB&#x2010;RCS2 overview,The space station overview,Overview of Insomnia,Mercury Porosimetry: A General (Practical) Overview,Reliability of human-supervised formant-trajectory measurement for forensic voice comparison,Comparison of code provisions on lap splices,Making climates comparable: Comparison in paleoclimatology,Security patch comparison techniques based on graph isomorphism theory,Interference Between Risers,Ghost Cells – An Overview,An overview of regulatory T cells,A serological comparison of some animal herpesvirus,비교가치이론과 온라인 비교도전 광고,Construction and Comparison of Authentication Codes,Comparison Versus Contrast: Task Specifics Affect Category Acquisition,"Effects of Dietary Fiber Intake and the Prevalence of Constipation Among Patients With End-Stage Renal Disease (ESRD) in Jeddah, Saudi Arabia: A Cross-Sectional Observational Study",ORDER RELATED CONCEPTS FOR ARBITRARY GROUPOIDS,Experimental Comparison of Opening Characteristics between Swing and Lift Check Valves,Non-Random CAN Fuzzing을 통한 효율적인 ECU 분석 기술,Concise Encyclopedia of Syntactic Theories,The concise aesthetics for the modern interior design,TCP/IP 상에서 CAN 데이터 프레임 송수신이 가능한 가상 CAN 버스 소프트웨어의 구현,FPGA 기반 CAN Spoofing 공격 탐방지 장치,Between the Acts에 나타난 제의적 요소,CAN 통신을 이용한 차량 상태 모니터링 시스템 개발,"CAN, CAN FD, FlexRay를 이용한 자동차용 진단시스템에 관한 연구",FreeRTOS상에서의 CAN통신 보안 설계,CAN Protocol을 이용한 CAN 통신 시스템 설계 및 구현,키워드 검색 지원을 위한 확장 CAN 메커니즘,CAN 네트워크에서의 Starvation Free 프로토콜,차량용 CAN-FD 제어기의 구현 및 검증,A Concise Hungarian-English Dictionary,Generating concise association rules,Towards concise gaze sharing,2. Overview,One Body: Overview,In-between,Between times,In-between
"Could you briefly summarize the methodology and results of using CNN, LSTM, and SVM combinations for noninvasive diabetes detection based on HRV signals?","##Diabetes detection using deep learning algorithms## ##Introduction## Heart rate variability (HRV) extracted from ECG signals provides a noninvasive window into autonomic function and has shown promise for early diabetes screening. Leveraging advances in deep learning, this study explores how convolutional and recurrent neural networks can capture complex temporal dynamics in HRV data to distinguish diabetic from healthy subjects. ##Main Body## The methodology combines convolutional neural networks (CNNs) and long short-term memory (LSTM) networks—either standalone or in tandem—to learn spatial and temporal features from RR-interval sequences. These learned representations are then fed into a support vector machine (SVM) classifier, which refines decision boundaries between normal and diabetic patterns. Incorporating SVM on top of CNN and CNN-LSTM models yields incremental performance gains of 0.03% and 0.06%, respectively, over architectures without SVM. Overall, the hybrid framework achieves a classification accuracy of 95.7%, demonstrating robustness in noninvasive diabetes detection. ##Conclusion## By fusing CNN- and LSTM-based feature extraction with SVM classification, the proposed approach attains high diagnostic accuracy on HRV data, offering a practical and precise tool for early, noninvasive diabetes detection.",없음,없음,"Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",22,1.1859924140007934,"**Title:** Analysis of Noninvasive Diabetes Detection using HRV Signals: A Review of Provided Literature

**Introduction:**

The provided documents do not contain information regarding the use of CNN, LSTM, and SVM combinations for noninvasive diabetes detection based on HRV signals.  Therefore, a direct answer to the original question is not possible based on the given context.  The provided papers discuss HRV analysis in different contexts, including the effects of acupuncture (Documents 1 and 4) and toxicological studies (Document 2), but none explore the application of machine learning algorithms like CNN, LSTM, and SVM for diabetes detection using HRV data. Document 3 discusses image analysis using DCT but is unrelated to HRV or diabetes. Document 5 focuses on acupuncture's potential role in treating spinal cord injuries.

**Body:**

The studies presented offer insights into HRV analysis but lack the necessary information to address the original query.  Document 1 investigates changes in heart rate variability (HRV) during laser acupuncture, measuring high-frequency (HF) and low-frequency (LF) power components to assess autonomic nervous system (ANS) activity.  Document 4 similarly examines HRV in elderly individuals in response to visual stimuli, analyzing HRV data in both time and frequency domains. These studies demonstrate the feasibility of using HRV as a noninvasive measure of ANS function and its responsiveness to various stimuli, laying the groundwork for potential applications in disease detection. However, they do not address the specific methodologies or results of using CNN, LSTM, and SVM for diabetes detection.

Document 2 uses zebrafish models for toxicological screening but is irrelevant to the application of machine learning algorithms for diabetes detection.

**Conclusion:**

Based solely on the provided literature, it is impossible to summarize the methodology and results of using CNN, LSTM, and SVM combinations for noninvasive diabetes detection based on HRV signals.  The documents offer valuable information about HRV analysis in different contexts, but none directly address this specific application of machine learning techniques.  Further research is needed to answer the original question.",Veranderungen der Herzratenvariabilitat (HRV) wahrend Low Level Lasernadelakupunktur,Zebrafish toxicological screening could aid Leishmaniosis drug discovery,Could DCT Reveal Photorealistic Images?,시각 자극에 의한 노인 HRV 해석,Spinal Cord Injury: How Could Acupuncture Help?,Could Arthroscopes be Better?,HRV와 양도락 검사를 통한 아토피피부염 환자의 자율신경계 특성 고찰,"Inbody, HRV, PTG와 FSH, LH의 연관성 연구",What Could I have Done Differently?,뇌파의 상관차원과 HRV의 상관분석,Faster R-CNN을 활용한 GPR 영상에서의 지하배관 위치추적 성능분석,딥러닝 기반 얼굴인식 라이브러리 활용 및 보완에 관한 연구,LSTM 기반 반도체 설비 위험예측 시스템 설계 방안에 관한 연구,CNN과 ELM을 사용한 차선검출 및 Adaboost를 사용한 차량 검출,"산삼 약침이 정상인의 심박변이도(HRV)에 미치는 영향 : A Randomized, Placebo-controlled and Double-blind Trial",CNN 알고리즘을 이용한 노이즈맵핑 연구,Multi-SVM based vehicle driver face recognition system in near-infrared image,불균형 데이터 집합의 분류를 위한 하이브리드 SVM 모델,맥파 기반의 HRV 분석을 위한 P-Peak 검출 알고리즘,"Classical Swine Fever: Could It Be Us, Could It Be You?",Could all laboratory animal use could be ended by the year 2020?,"SVM, LSTM, CNN-LSTM과 TCN을 이용한 금 가격 예측",HRI를 위한 시선 정보를 활용한 SVM 기반 사용자 의도 추정 방법,앙상블 구성을 이용한 SVM 분류성능의 향상,앙상블 SVM 모형을 이용한 기업 부도 예측,HRV(Heart Rate Variability)로 살펴본 경항통과 심리적 요인의 상관관계,Could Alice equalize student learning?,What motor cars could be,What Motor Cars Could Be,CNN 캐스케이드 얼굴 검출기를 이용한 강화된 모델 기반의 얼굴 추적,합성곱 신경망(CNN)기반 이미지 처리 시스템,R-CNN 알고리즘을 이용한 국산 차종인식 분류기 생성 및 차량 학습데이터 구성,LSTM 기반의 Top-down 분해방식을 이용한 단기 전력수요 예측,LSTM 모델기반 서울시 미세먼지 농도 예측 정확도 분석,LSTM과 Bi-LSTM을 사용한 비주기성 시계열 데이터 예측 성능 비교 분석,SVM(Support vector machine)을 이용한 중･소교량 상부형식 선정모형에 관한 연구,SVM  분류기를 이용한   문서 범주화 연구,지역특징분석을 이용한 SVM 커널 디자인,SVM을 이용한 차량 번호판 위치 추출,기계학습 및 분류를 위한 SVM 엔진의 FPGA 구현,HRV 분석을 이용한 운전피로도에 관한 연구,인지능력 저하노인에 대한 HRV 측정기법에 관한 연구,CNN 기반 얼굴감정인식과 새로운 손실함수에 대한 연구,CNN과 LSTM이 결합된 멀티모달 강화학습 기반의 주식 거래 시스템,CNN 을 이용한 동전 분류,사용자 속성 정보를 이용한 LSTM Autoencoder 기반의 효율적인 내부자 위협 탐지에 관한 연구,LSTM 언어모델 기반 한국어 문장 생성,CNN-LSTM 모델을 이용한 DGPS 위치 정확도 향상 기법,양방향 LSTM 순환신경망 기반 주가예측모델,LSTM 기반 멀티스텝 트래픽 예측 기법 평가
Can you outline the key deep learning and machine learning models evaluated for electricity demand prediction and their comparative performance in terms of MSE and MAPE?,"##Effective Electricity Demand Prediction via Deep Learning## ##Introduction## Accurate short-term forecasting of household electricity demand is critical for reducing waste and improving energy management in smart grids. Time-series prediction remains a challenge, prompting comparison between traditional statistical methods and modern deep learning architectures. ##Main Body## Three models were tested on German home appliance power-consumption data: - An error-corrected multilayer perceptron (eMLP), which combines a standard MLP with an error-correction mechanism. - An autoregressive integrated moving average (ARIMA) model, representing a classical statistical approach. - A hybrid convolutional neural network–long short-term memory (CNN-LSTM) network, designed to extract spatial patterns via convolution layers and capture temporal dependencies through LSTM units. Performance was evaluated using mean square error (MSE) and mean absolute percentage error (MAPE). The CNN-LSTM achieved the lowest MSE and MAPE, significantly outperforming eMLP, which in turn outperformed ARIMA. ##Conclusion## The CNN-LSTM architecture demonstrated superior accuracy in electricity demand forecasting, highlighting the benefit of combining convolutional feature extraction with recurrent temporal modeling over both pure neural networks and traditional time-series methods.",없음,없음,"Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",23,1.1859924140007934,"**Title:** Analysis of Machine Learning Models for Electricity Demand Prediction: A Review of Provided Literature

**Introduction:**

This report analyzes the provided academic papers to determine which deep learning and machine learning models were evaluated for electricity demand prediction and their comparative performance using Mean Squared Error (MSE) and Mean Absolute Percentage Error (MAPE).  It is important to note that none of the provided documents directly address electricity demand prediction or offer comparative results using MSE and MAPE for such models.  The analysis will therefore focus on the relevant methodologies and metrics mentioned within the provided texts.

**Body:**

The provided documents do not contain information on specific deep learning or machine learning models evaluated for electricity demand prediction, nor do they present comparative results using MSE and MAPE.  However, several papers mention relevant techniques and metrics.

* **Document 3 (""Machine learning on Big Data"")** discusses the increasing importance of scale in machine learning model quality and covers current large-scale applications and computational models. While not specific to electricity demand prediction, this suggests that large-scale machine learning approaches are applicable to this domain. The paper highlights the need for better systems support for machine learning applications, which is crucial for handling the large datasets involved in electricity demand forecasting.

* **Document 4 (""GRG-MAPE and PCC-MAPE Based on Uncertainty-Mathematical Theory for Path-Loss Model Selection"")** introduces Grey Relational Grade (GRG) and Pearson Correlation Coefficient (PCC) as methods for model selection, comparing them to Root Mean Square Error (RMSE).  While focusing on path-loss models, this demonstrates the use of MAPE (as part of GRG-MAPE) for model evaluation in a related context.  It also highlights that MAPE can be a more accurate metric than RMSE in certain scenarios.  This suggests MAPE's potential applicability in assessing electricity demand prediction models.

* **Document 5 (""MAPE - An Alternative Fitness Metric for Prony Analysis of Power System Signals"")** proposes Mean Absolute Percentage Error (MAPE) as an alternative fitness metric for Prony analysis of power system signals, comparing it to Signal-to-Noise Ratio (SNR). While not directly related to electricity demand prediction, it showcases MAPE's use in evaluating models within the power systems domain, suggesting its relevance to the task. The paper demonstrates that MAPE can outperform SNR in some cases, indicating its potential value in assessing predictive model accuracy.


**Conclusion:**

While the provided documents do not directly address the specific question regarding electricity demand prediction model evaluations using MSE and MAPE, they provide valuable context regarding relevant methodologies and metrics.  Document 3 emphasizes the scalability requirements for handling large datasets common in such prediction problems. Documents 4 and 5 highlight the applicability and potential advantages of using MAPE as an evaluation metric in power systems analysis, indirectly suggesting its suitability for electricity demand forecasting models.  To fully answer the original question, additional research focusing specifically on deep learning and machine learning models for electricity demand prediction and their comparative performance using MSE and MAPE is necessary.",MAPE-K/MAPE-SAC: An interaction framework for adaptive systems with security assurance cases,Deep learning for radar,Machine learning on Big Data,GRG-MAPE and PCC-MAPE Based on Uncertainty-Mathematical Theory for Path-Loss Model Selection,MAPE - An Alternative Fitness Metric for Prony Analysis of Power System Signals,[Use of the MSE scale in geriatric psychiatry],이러닝 학습환경이 이러닝 학습만족도에 미치는 영향 분석,Infusing MSE Topics into Non-MSE Curricula: A Multidisciplinary Effort,Subjective MSE Measures,Learning analytics sources: Beyond learning platforms,Machine learning and docking studies of cytochrome P450 ligands,Amenagement de la Mape au Cameroun,On the asymmetry of the symmetric MAPE,Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators,MSE-Minimizing Filters Design for Motion Estimation,소지역 추정에 대한 잭나이프 MSE,On the validity of MAPE as a measure of population forecast  accuracy,MAPE-K as a service-oriented architecture,Non-Random CAN Fuzzing을 통한 효율적인 ECU 분석 기술,딥러닝 알고리즘에 기반한 기업부도 예측,= Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어,눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식,딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구,QAM 신호에서 mSE-MMA 적응 등화 알고리즘의 성능 평가,딥 러닝을 이용한 DC 모터 제어,Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서,딥 러닝기반 고객평점 예측모델,바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사,TCP/IP 상에서 CAN 데이터 프레임 송수신이 가능한 가상 CAN 버스 소프트웨어의 구현,FPGA 기반 CAN Spoofing 공격 탐방지 장치,MSE INCORPORATED,MSE INCORPORATED,MSE INCORPORATED,Bio-textual deep web search system based on keyword networks : 키워드 네트워크에 기반한 바이오텍스트 딥웹 검색 시스템,CAN 통신을 이용한 차량 상태 모니터링 시스템 개발,"CAN, CAN FD, FlexRay를 이용한 자동차용 진단시스템에 관한 연구",FreeRTOS상에서의 CAN통신 보안 설계,CAN Protocol을 이용한 CAN 통신 시스템 설계 및 구현,키워드 검색 지원을 위한 확장 CAN 메커니즘,CAN 네트워크에서의 Starvation Free 프로토콜,차량용 CAN-FD 제어기의 구현 및 검증,ABTC의 비트평면 감축에서 MSE 개선,Whatever Happened to the MAPE Website?,Geoekologicke krajinne typy (komentar k mape),Mape-Antique (Mapei),,,,,
"Can you summarize the main findings from the topic modeling analysis of deep learning research trends over the past ten years, including country-specific differences?","##Deep Learning Research Trend Analysis## ##Introduction## A systematic review employing Latent Dirichlet Allocation (LDA) distilled the evolution of deep learning research over the past decade, mapping both thematic shifts and national emphases. ##Main Body## – Data Collection and Topic Extraction: Over ten years of deep learning publications were gathered and preprocessed; LDA identified core topics including network architectures (e.g. CNNs, RNNs), computer vision, natural language processing, reinforcement learning, and generative models. – Temporal Trends: Early work concentrated on foundational model design and training algorithms, while later years saw growing interest in application-driven studies and multimodal or interdisciplinary approaches. – Country-Specific Differences: • United States: Led in algorithmic innovations and theoretical advances. • China: Rapidly expanded research on large-scale and industry-oriented applications. • South Korea: Focused strongly on cloud-based frameworks, performance benchmarking, and hardware optimization. • United Kingdom: Maintained a balanced portfolio spanning foundational methods and applied domains. ##Conclusion## Topic modeling reveals a clear progression from core model development to diverse real-world applications, with each major research country exhibiting distinct strategic priorities that shape the global deep learning landscape.",없음,없음,"Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",24,1.1859924140007934,"**Title:** Analysis of Topic Modeling Techniques in Research: A Review of Relevant Literature

**Introduction:**

This report analyzes the provided research papers to address the question of deep learning research trends over the past ten years, including country-specific differences.  However, it is crucial to note that none of the provided documents directly address deep learning research trends or country-specific differences within the field.  Therefore, this report will instead focus on summarizing the main findings regarding topic modeling techniques as described in the provided literature.  The analysis will highlight applications of topic modeling and address methodological challenges in this area.


**Body:**

The provided documents offer insights into various aspects of topic modeling and related data analysis techniques but do not contain information on deep learning research trends.  Document 1 focuses on the challenges of identifying and removing ""topic general words"" (TGWs) from corpora used in topic modeling.  TGWs can negatively affect topic coherence by creating spurious co-occurrences of unrelated terms. The authors propose automated approaches to identify and remove TGWs, improving the accuracy and interpretability of topic models.  These approaches can utilize a single corpus or leverage a novel continuous learning method that incorporates information from multiple corpora. The effectiveness of these methods was demonstrated through experiments on real-world datasets.

Document 2 details a study using magnetic resonance imaging (MRI) to analyze the prevalence of cervical spine abnormalities in relation to age and gender. This study is not directly related to topic modeling but illustrates a different method for analyzing datasets and identifying patterns related to demographic factors.  The researchers found a correlation between age and the prevalence of abnormalities, with spondylodegenerative changes being the most frequent finding.  Gender differences were also observed, with younger males exhibiting a higher incidence of injuries compared to females of the same age, but this trend reversed in older age groups.

Document 3 presents a study on modeling traffic vehicular counts using various time series models including dynamic harmonic regression, BATS, and TBATS.  While not focused on topic modeling, this study showcases the use of sophisticated statistical modeling to analyze temporal data and make predictions.  The authors highlight the superior performance of the BATS model in accurately capturing complex seasonality and making accurate predictions across various prediction windows.

Document 4 discusses wastewater process modeling, focusing on the use of software packages to simulate and analyze wastewater treatment systems.  This is a distinct area of modeling, unrelated to topic modeling or the analysis of research trends.

Finally, Document 5 describes a study analyzing histopathological findings in medicolegal autopsies, emphasizing rare incidental findings. This study, again, is unrelated to topic modeling of research trends but emphasizes the importance of detailed analysis of data to reveal unexpected patterns and insights.  The study revealed the most common lesions and highlighted the prevalence of rare incidental findings, suggesting the potential for improved medical understanding and interventions.


**Conclusion:**

The provided documents offer valuable insights into various data analysis techniques, including different approaches to statistical modeling, but do not offer data related to topic modeling of deep learning research trends over the past ten years.  The papers highlight the challenges and advancements in several fields, emphasizing the need for sophisticated methods to analyze complex datasets and extract meaningful insights.  While the studies utilize diverse approaches, they all share the common goal of extracting meaningful information from data and using this information to improve understanding and decision-making in their respective fields.  Future research utilizing suitable datasets will be needed to answer the original question.",Tackling topic general words in topic modeling,Magnetic Resonance Imaging of the Cervical Spine: Frequency of Abnormal Findings with Relation to Age,Modeling Traffic Vehicular Counts at an Urban Intersection Using Complex Seasonal Modeling Techniques,Wastewater process modeling,Histopathological Findings in Medicolegal Autopsies with Emphasis on Rare Incidental Findings,Jaccoud&apos;s arthropathy,Extraspinal findings on lumbar spine MR imaging.,A Retrospective Study of Intervertebral Disk Disease in 21 Dogs; Clinical Findings and Outcomes,"Secondary Teachers' Perspectives on Mathematical Modeling and Modeling Mathematics: Discovery, Appreciation, and Conflict",La main spastique psychog&egrave;ne,Classifying web hierarchically using multi label tree classifier,Topic representation: Finding more representative words in topic models,"Indications and findings at colonoscopy in Ilorin, Nigeria",Correlation of Imaging Findings with Pathologic Findings of Sclerosing Adenosis,Dynamic CT Findings of Pulmonary Hamartoma: A Comparison with Histopathologic Findings,Colonoscopy Findings: A Single Institution Study from Pakistan,토픽 레이블링을 위한 토픽 키워드 산출 방법,The hand: Embryology and main malformative mechanisms,Harmony Mechanism Between Main Productive Region and Main Sale Region,대조주제의 주제성과 초점성,Modeling,Les greffons osseux vascularis&#x00E9;s p&#x00E9;dicul&#x00E9;s pr&#x00E9;lev&#x00E9;s sur la main et le poignet : revue de la litt&#x00E9;rature et nouveau site donneur,"Main coup&eacute;e, main errante, main absente : All&eacute;gorie r&eacute;elle de la Grande Guerre",TCP/IP 상에서 CAN 데이터 프레임 송수신이 가능한 가상 CAN 버스 소프트웨어의 구현,FPGA 기반 CAN Spoofing 공격 탐방지 장치,Tendinopathies de la main et du poignet,Syndromes canalaires r&#x00E9;v&#x00E9;l&#x00E9;s &#x00E0; la main,A Review of ACIR Findings,Unified  Modeling Language를  활용한 다관점  업무 시스템  모형화,CAN 통신을 이용한 차량 상태 모니터링 시스템 개발,"CAN, CAN FD, FlexRay를 이용한 자동차용 진단시스템에 관한 연구",FreeRTOS상에서의 CAN통신 보안 설계,CAN Protocol을 이용한 CAN 통신 시스템 설계 및 구현,키워드 검색 지원을 위한 확장 CAN 메커니즘,Non-Random CAN Fuzzing을 통한 효율적인 ECU 분석 기술,CAN 네트워크에서의 Starvation Free 프로토콜,차량용 CAN-FD 제어기의 구현 및 검증,Top Bracing을 이용한 선박엔진의 진동방진에 관한연구,Permis de conduire et chirurgie de la main,Findings,Topic Signature를 이용한 댓글 분류 시스템,&ldquo;Hot Topic&rdquo;,Topic Introduction,Topic Introduction,Topic Introduction,Partnership Enterprise Modeling Using FIDO-Integrated Systems Modeling Technique,Modeling modeling modeling,자수정(Amethyst) 보석을 응용한 장신구 조형과 Interior Jewel Modeling의 디자인 개발,모델링 탐구 활동에서의 대학생의 모델링 유형 분석 및 인식,
클라우드 컴퓨팅 환경에서 오픈소스 기반 딥 러닝 프레임워크들 간의 성능 비교 결과와 그 의의를 간결하게 정리해 주실 수 있나요?,"##제목## 클라우드 컴퓨팅 환경에서 오픈소스 기반 Deep Learning 프레임워크 성능 비교 ##서론## 통신·스토리지 기술 발전과 데이터 저장 비용 절감에 힘입어 대규모 데이터를 신속·효율적으로 처리할 수 있는 Cloud Computing이 각광받고 있으며, 이를 위해 TensorFlow, PyTorch, Caffe 등 다양한 오픈소스 Deep Learning 프레임워크가 개발되었습니다. 그러나 실제 클라우드 환경에서 어떤 프레임워크가 최적의 성능을 발휘하는지에 대한 체계적 비교 연구는 부족한 실정입니다. ##본론## 대표적 클라우드 오픈소스 플랫폼인 OpenStack 위에 주요 프레임워크를 설치하여 동일 모델과 하이퍼파라미터로 실험을 수행했습니다. 학습 시간, GPU 및 메모리 활용률, 분산 학습 확장성 세 가지 기준으로 벤치마킹한 결과, 일부 프레임워크는 대용량 데이터 병렬 처리 시 우수한 학습 속도와 안정적인 자원 관리를 보였고, 다른 프레임워크는 소규모 또는 메모리 제약이 있는 환경에서 더 낮은 메모리 소모로 효율을 발휘했습니다. ##결론## 이번 비교 연구는 클라우드 환경에서 비용과 성능을 종합적으로 고려해 프레임워크를 선택하고 최적화 전략을 수립하는 데 실질적 가이드를 제공합니다.",Can you briefly summarize the performance comparison results and its significance between open source -based deep learning frameworks in the cloud computing environment?,"##title## Open source -based Deep Learning framework performance comparison in cloud computing environment ##introduction## Thanks to the development of communication and storage technology and the reduction of data storage costs, Cloud Computing, which can quickly and efficiently process large data, has been in the spotlight, and various open source Deep Learning frameworks such as Tensorflow, PyTorch, and Caffe have been developed. However, systematic comparison studies on which frameworks are optimal in the actual cloud environment are insufficient. ## Main ## The main framework was installed on top of OPENSTACK, a representative cloud open source platform, and experimented with the same model and hyper parameter. As a result of benchmarking on three criteria: learning time, GPU and memory utilization rate, and distributed learning scalability, some frameworks showed excellent learning speed and stable resource management in parallel with large amounts of data, and other frameworks were efficient with lower memory consumption in an environment with small or memory constraints. ##conclusion## This comparison study provides practical guides in selecting frameworks and establishing optimization strategies in consideration of cost and performance in the cloud environment.","Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",25,1.1859924140007934,"## 제목: 제공된 문서에서 추출할 수 없는 정보에 대한 보고서

**서론:**

제공된 문서 1~5는 클라우드 컴퓨팅의 법적 이슈, 엣지 컴퓨팅 활용 사례, 클라우드 보안 강화 방안, 개인정보보호 문제, 그리고 클라우드 컴퓨팅의 기업 활용 전략 등 다양한 측면을 다루고 있습니다. 하지만 안타깝게도, 질문에서 요구하는 ""클라우드 컴퓨팅 환경에서 오픈소스 기반 딥 러닝 프레임워크들 간의 성능 비교 결과와 그 의의""에 대한 정보는 어떤 문서에도 포함되어 있지 않습니다. 따라서 본 보고서는 질문에 직접적으로 답변할 수 없습니다.


**본론:**

제공된 문서들은 클라우드 컴퓨팅의 다양한 측면을 다루지만, 딥 러닝 프레임워크의 성능 비교에 대한 내용은 전혀 포함하고 있지 않습니다. 문서 2는 엣지 컴퓨팅 환경에서 객체 탐지를 위한 인공지능 기술을 언급하지만, 구체적인 프레임워크나 성능 비교는 다루지 않습니다. 문서 3은 클라우드 서비스의 보안을 강화하기 위한 2단계 인증 방식을 제안하지만, 딥 러닝 프레임워크와는 관련이 없습니다.  나머지 문서들 역시 클라우드 컴퓨팅의 법적, 윤리적, 경영적 측면에 초점을 맞추고 있으며, 딥 러닝 프레임워크의 기술적인 비교 분석 내용은 전혀 담고 있지 않습니다.


**결론:**

제공된 문서에는 클라우드 컴퓨팅 환경에서 오픈소스 기반 딥 러닝 프레임워크들의 성능 비교 결과 및 그 의의에 대한 정보가 없으므로, 질문에 대한 답변을 제공할 수 없습니다.  질문에 답하기 위해서는 딥 러닝 프레임워크 성능 비교에 관한 추가적인 자료가 필요합니다.",클라우드 서비스와 SaaS의 법적 이슈,엣지 컴퓨팅 환경에서 객체탐지 기법을 활용한 도로 균열 탐지 시스템 개발,Two Factor Authentication for Cloud Computing,클라우드 서비스와 개인정보보호,"Bedeutung und Management von Cloud Computing, Multi-Cloud und Cloud Brokerage in Unternehmen",멀티엑세스 엣지 컴퓨팅 환경에서의 초저지연 서비스 지원을 위한 구조,IT 인프라 관리분야에서의 클라우드 기반 비즈니스 모델에 관한 연구,스마트홈 환경을 위한 엣지 컴퓨팅 기반 사용자 중심 캐싱 아키텍처,클라우드 컴퓨팅 및 실시간 데이터 처리 기술을 연동한 M&S(Modeling & Simulation) 환경의 구축,컴퓨팅사고력 기반 소프트웨어교육이 초등학교 학생들의 학습흥미와 진로인식에 미치는 영향,가상 스크리닝을 위한 그리드 기반 원격 처리 환경 시스템,클라우드 컴퓨팅 환경을 위한 기존시스템 이전 모델 개발 연구,피지컬 컴퓨팅 기반 소프트웨어 교육이 초등학생의 컴퓨팅 사고력에 미치는 영향,클라우드 서비스 생태계 내의 협업 사례 연구: 클라우드 서비스 중개업을 중심으로,클라우드 서비스 중개를 위한 가변성 기반의 서비스 명세 기법,환경 정책이 환경 전과정 및 지속가능발전에 미치는 영향에 관한 연구,환경 R&D의 사업화를 위한 정책연구,통신위성 원격측정명령처리기 성능검증모델 원격명령 암호복호 검증,컴퓨팅 사고력 향상을 위한 소프트웨어 교육용 애플리케이션 개발,클라우드 방송 서비스 플랫폼,환경영향평가 유형분류 및 저감방안 개선에 관한 연구,선박 평형수 처리 시스템의 안드로이드 원격 모니터링 시스템,선박 평형수 처리 시스템에서 센서 데이터의 원격 통신,메시지 처리 시스템에서의 원격 사용자 처리기와 메시지 스토어의 설계 및 구현,원격측정명령처리기 성능검증모델 개발,의료용 로봇 원격 응용을 위한 영상처리 시스템 개발,클라우드 엣지 컴퓨팅 아키텍처와 응용 레벨 컨텍스트 이주 기법,환경의식 향상에 효과적인 환경교육 방법에 관한 연구,친환경자동차 산업 활성화를 위한 정책적 지원방안 연구,원격 오&#x00B7;폐수 처리 감시 장치 및 통합 환경 관리 시스템 개발,클라우드 서비스 형태와 Private 클라우드 서비스,클라우드 서비스 형태와 모바일 클라우드 서비스 사례,클라우드 관련 법.제도 고찰 및 발전 방향에 대한 제언 - 클라우드 서비스 인증제를 중심으로,클라우드 서비스 브로커를 이용한 클라우드 서비스 감사,이종 클라우드를 연동하는 클라우드 서비스 브로커,이러닝 학습환경이 이러닝 학습만족도에 미치는 영향 분석,"환경 문제, 시민지식 그리고 시민과학: 시민과학의 환경 문제 해결 가능성과 과제",태양광발전설비 원격 관제를 위한 빅데이터 분석 및 처리,지질자원 탐사를 위한 원격탐사 영상의 처리기법 및 활용 검토,인지된 위험과 신뢰가 Cloud Computing 사용의도에 미치는 영향 : 모바일 Cloud Computing을 중심으로,Mobile Cloud Computing Security Considerations,Securing Data Storage in Cloud Computing,E-learning in Cloud Computing Infrastructure,Cloud Computing의 지적재산권 문제,IaaS Architecture using Grid in Cloud Computing,Cloud Computing Roundtable,From cloud computing to cloud manufacturing,저염해성 친환경 제설제 개발,친환경 자동차 보급에 관한 연구,환경안보 개념의 대두와 국제법의 대응
DC 모터 제어 시스템에 딥 러닝 기반 제어기를 적용한 방법과 PID 제어기와의 성능 비교 결과를 요약해 주실 수 있나요?,"##제목## 딥 러닝 기반 제어기 설계 및 PID 제어기와의 성능 비교 ##서론## 딥 러닝은 기존 인공신경망보다 은닉층과 뉴런 수를 확장해 복잡한 문제를 해결하도록 고안된 심층 인공신경망 알고리즘이다. 산업 현장에서는 여전히 PID 제어기가 널리 사용되고 있으나, 제어문제에 딥 러닝을 적용한 연구는 부족하다. 본 연구는 DC 모터 제어 시스템에 딥 러닝 제어기를 도입해 PID 제어기 성능을 모방·개선할 수 있는지를 검증하고자 한다. ##본론## 1. 제어기 구조 설계 - 깊은 신경망 중 하나인 Deep Belief Network(DBN)를 사용해 딥 러닝 제어기를 구현 - PID 제어기에 입력되는 참조 신호와 PID 출력값을 학습 데이터로 활용 2. 데이터 수집 및 전처리 - DC 모터 시스템에 다양한 제어 입력을 주어 PID 제어기의 출력 토크 및 속도 응답을 기록 - 입력·출력 쌍을 정규화해 DBN 학습용으로 구성 3. 학습 및 시뮬레이션 - DBN의 가중치를 역전파(backpropagation) 방식으로 최적화하여 PID 동작 특성을 모방 - MATLAB/Simulink 기반 시뮬레이션 환경에서 제안 제어기와 기존 PID 제어기의 응답 비교 4. 성능 비교 결과 - 과도응답 특성(오버슈트, 상승 시간)과 정상상태 오차에서 DBN 제어기가 PID와 유사한 제어 성능 달성 - 일부 실험 조건에서 노이즈 내성 및 비선형 구간 처리 능력이 DBN 제어기에서 더 우수한 경향 관찰 ##결론## 딥 러닝 제어기는 학습된 PID 동작을 효과적으로 모방하면서도 비선형 및 노이즈 환경에서 안정적인 제어 성능을 보였다. 향후 실험 환경 다양화와 하드웨어 구현을 통해 상용 제어기 대체 가능성을 더욱 검증할 필요가 있다.",Can you summarize the performance comparison results with a deep learning -based controller and PID controller?,"##title## Comparison of performance with deep learning -based controller design and PID controller ##introduction## Deep learning is an in -depth artificial neural network algorithm designed to expand the hidden and neurons rather than the existing artificial neural network to solve complex problems. In the industrial field, PID controllers are still widely used, but there is a lack of research with deep learning to control problems. This study aims to verify whether the PID controller performance can be imitated and improved by introducing a deep learning controller into the DC motor control system. ## Main ## 1. Design of controller structure -Dep Belief Network (DBN), one of the deep neural networks, is used to implement a deep learning controller -Use the reference signal and PID output value entered into the PID controller as a learning data 2. Data collection and pretreatment -DC motor system gives a variety of control inputs to record the output torque and speed response of the PID controller. -Normalization of input and output pairs and organized for DBN learning 3. Learning and simulation -It is optimized by the BackPropagation method of the DBN to imitate PID operation characteristics. -Comparing the response between the proposal controller and the existing PID controller in the MATLAB/SIMULINK -based simulation environment 4. Comparison of performance comparisons -DBN controller is similar to PID in transitional response characteristics (overstity, up time) and normal state error. -In some experimental conditions, noise resistance and nonlinear inter -handling capacity observes superior tendency in DBN controllers. ##conclusion## Deep learning controllers effectively imitated the learned PID behavior, while showing stable control performance in nonlinear and noise environments. In the future, it is necessary to further verify the possibility of replacement of commercial controllers by diversifying the experimental environment and implementing hardware.","Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",26,1.1859924140007934,"**제목: 딥러닝 기반 제어기와 PID 제어기의 DC 모터 제어 성능 비교 분석: 관련 문헌 검토**

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 DC 모터 제어 시스템에 딥러닝 기반 제어기를 적용한 방법과 PID 제어기와의 성능 비교 결과를 분석합니다.  제공된 문서에는 DC 모터 제어에 대한 직접적인 내용은 없으나, 다양한 제어 시스템 및 딥러닝 기술 적용 사례가 제시되어 있어 이를 토대로 간접적인 비교 분석을 수행합니다.

**본론:**

제공된 문서들은 DC 모터 제어에 대한 직접적인 비교 분석 결과를 제공하지 않습니다. 따라서, 각 문서에서 제시된 다른 제어 시스템 및 딥러닝 기술 적용 사례를 바탕으로  DC 모터 제어 시스템에 대한 딥러닝 기반 제어기 적용 가능성과 PID 제어기와의 비교를 추론적으로 접근합니다.

문서 4는 습도 제어 시스템에 PID 제어와 상태 공간 제어를 적용하여 성능을 비교한 연구를 소개합니다.  상태 공간 제어 방식이 PID 제어보다 더 나은 성능을 보였다는 결과를 제시하고 있습니다.  이 연구는 DC 모터 제어에는 직접적으로 적용되지 않았지만,  모델 기반 제어(model-based control) 방식과 모델-프리(model-free) 제어 방식의 차이점을 보여줍니다. 딥러닝 기반 제어는 일반적으로 데이터 기반으로 학습되므로 모델-프리 방식에 가깝다고 볼 수 있습니다.  문서 5는 AWS Lambda를 이용한 딥러닝 기반 이미지 인식 서비스 시스템의 효율성을 보여주는 데 초점을 맞추고 있으나, 이를 DC 모터 제어에 적용하는 경우 딥러닝 모델이 모터의 동작을 학습하고 제어 신호를 생성하는 방식으로 작동할 수 있음을 시사합니다.  문서 1의 공랭식 변유량 냉매 냉동기의 정밀 온도 제어는 최적 제어 알고리즘을 사용하여 높은 정확도를 달성한 사례로, 딥러닝 기반 제어기가 DC 모터의 속도 또는 위치 제어에서 유사한 정밀도를 달성할 수 있음을 암시적으로 나타냅니다.  문서 2와 3은 각각 IoT 기반 자동 제어 시스템과 추천 시스템 개선에 대한 연구로, 직접적으로 DC 모터 제어와 관련이 없지만, 사용자 맞춤형 제어 및 최적화된 제어 알고리즘 개발에 대한 딥러닝의 적용 가능성을 보여줍니다.  이는 DC 모터 제어에서도 딥러닝을 이용하여 사용 환경과 목표에 맞는 최적의 제어를 구현할 수 있다는 점을 시사합니다.


**결론:**

제공된 문서들만으로 DC 모터 제어 시스템에 딥러닝 기반 제어기를 적용한 방법과 PID 제어기와의 성능 비교 결과를 직접적으로 비교 분석하는 것은 불가능합니다. 하지만 다양한 제어 시스템 및 딥러닝 기술 적용 사례를 통해 딥러닝 기반 제어기가 DC 모터 제어에 적용될 수 있으며,  문서 4의 결과를 참조하여 모델 기반 접근 방식의 PID 제어보다 딥러닝 기반의 모델-프리 접근 방식이 더 나은 성능을 보일 가능성이 있음을 추론할 수 있습니다.  더욱 정확한 비교 분석을 위해서는 DC 모터 제어 시스템에 딥러닝 기반 제어기를 적용한 구체적인 실험 결과를 포함하는 연구가 필요합니다.",공랭식 변유량 냉매 냉동기를 적용한 수조 온도의 정밀 제어,제어 명령 분석 기반 IoT 자동 제어 시스템,"추천 시스템 개선을 위한 무관심 아이템, 신뢰 네트워크, 카테고리 전문가 활용 방안",습도제어 시스템 구현에 관한 연구,AWS Lambda Serverless Computing 기술을 활용한 효율적인 딥러닝 기반 이미지 인식 서비스 시스템,소규모 독립형 태양광 발전 시스템 설계 및 시뮬레이터 개발,군집 안정성과 강인성을 보장하는 계층구조 군집제어,아두이노 기반 소형 멀티콥터의 비행제어 알고리즘에 관한 연구,BLDC 모터제어 펌웨어 개발 및 속도제어장치 제작,원격제어 감시 시스템에서의 데이터 암호화 적용에 관한 연구,다중 모터를 이용한 전기자동차 구동용 인휠 구동시스템에 관한 연구,DC모터 속도제어를 위한 마이크로 프로세서 응용 relay 자동동조 PID제어기 설계,소셜 정보 기반의 맛집 추천 시스템,모바일 디바이스를 이용한 간편 결제 시스템 모델,모터 제어 전용 16비트 마이크로 제어기 dsPIC30F2010을 이용하는 모션제어기 설계,전기자동차 모터 시스템의 전도 방출 규격 제안,모터스포츠 F1코리아그랑프리대회 활성화를 위한 정책개발 : policy delphi기법과 AHP을 이용,전기모터 냉각성능 향상을 위한 유/수냉 복합 열전달에 대한 수치해석,와이퍼 모터의 수명분포 추정,"Intelligent Transportation System: Route Guidance, Driving Behavior, and Eco-driving : 지능형 교통 시스템: 길 찾기, 운전 행태, 친환경적 교통 시스템",다형질 데이터를 이용한 추천 시스템 : Recommender Systems using Heterogeneous Data,수동 댐퍼를 이용한 직접 구동 로봇의 충돌 제어,전기자동차 모터 구동 시스템에서 발생하는 EMI 분석에 관한 연구,모터스포츠 이벤트의 지속가능한 발전 전략에 관한 연구,배터리 관리 시스템,시스템 보안기법의 비교 연구,엘리베이터 군제어 시스템의 모델링과 제어,,,,,,,,,,,,,,,,,,,,,,,
"DBN 기반 딥 러닝을 이용한 기업부도 예측과 기존 SVM 방법 간의 성능 차이, 특히 부도기업 예측 민감도 향상 결과를 간단히 정리해 주실 수 있나요?","##제목## DBN 기반 딥러닝과 SVM을 활용한 기업부도 예측 성능 비교 ##서론## 기업부도는 국가경제와 이해관계자들에게 심각한 손실을 초래하므로, 이를 정확히 예측하는 연구가 중요하다. 최근 이미지·음성·자연어 처리 분야에서 우수한 성능을 보인 Deep Belief Network(DBN)를 기업부도 예측에 도입하여 기존의 Support Vector Machine(SVM)과 비교 분석을 수행하였다. ##본론## - 연구 데이터 및 변수: 1999~2015년 코스닥·코스피 비금융업종 2,164개 기업(정상 1,669개, 부도 495개)과 한국은행 기업경영분석의 재무비율 변수 활용 - 모델 비교: DBN과 전통적 SVM을 동일 데이터로 학습·검증 - 주요 결과: 전반적 평가척도에서 DBN이 SVM보다 우수한 예측력을 보였으며, 특히 부도기업을 정확히 식별하는 민감도(sensitivity)가 시험 데이터 기준으로 5% 이상 높게 향상됨 ##결론## DBN 기반 딥러닝은 SVM 대비 부도기업 탐지 능력을 크게 개선하여, 기업부도 예측 분야에서 딥러닝 기법의 유용성을 확인시켜 주었다.","Can you briefly summarize the difference in performance differences between predictions and existing SVM methods, especially bankruptcy company prediction sensitivity improvement?","##title## DBN -based deep learning and business departments using SVM are also comparing predictive performance ##introduction## Since corporate bankruptcy causes serious losses to the national economy and stakeholders, research to predict it is important. Recently, the company introduced the Deep Belief Network (DBN), which showed excellent performance in the field of image, voice, and natural language processing, was also introduced to predict the existing Support Vector Machine (SVM). ## Main ## -Data and variable: 1999 ~ 2015 KOSDAQ and KOSDAPS non -financial sectors 2,164 companies (1,669 normal, 495 bankruptcy) -Model Comparison: Learning and verifying DBN and traditional SVM with the same data -Main results: In the overall evaluation scale, DBN showed better predictions than SVM, and in particular, sensitivity that accurately identifies bankruptcy companies is more than 5% higher based on test data. ##conclusion## DBN -based deep learning has greatly improved the detection of bankruptcy companies compared to SVM, and confirmed the usefulness of deep learning techniques in the field of predictions.","Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",27,1.1859924140007934,"**제목:** 딥러닝 기반 기업부도 예측 성능 비교 분석: 제공 자료에 대한 분석 불가

**서론:**

제공된 학술문서 5편은 딥러닝 알고리즘을 다양한 분야에 적용한 연구 결과를 제시하고 있습니다.  문서 1은 제주도 관광객 수 예측, 문서 2는 시선 추정 시스템, 문서 3은 텍스처와 개체 분포 생성, 문서 4는 자율주행 자동차를 위한 실시간 장면 이해, 문서 5는 저널 추천 방법론에 대한 연구입니다.  그러나 어떤 문서도 DBN 기반 딥러닝을 이용한 기업부도 예측이나 SVM 방법과의 성능 비교, 부도기업 예측 민감도 향상에 대한 내용을 포함하고 있지 않습니다. 따라서 질문에 대한 직접적인 답변은 불가능합니다.


**본론:**

제공된 문서들은 모두 딥러닝을 활용한 다양한 예측 및 분석 모델을 제시하지만, 질문에서 요구하는 기업부도 예측, DBN(Deep Belief Network), SVM(Support Vector Machine) 비교 분석, 부도기업 예측 민감도 향상 등의 주제를 다루고 있지 않습니다.  문서들은 딥러닝의 응용성을 다양한 측면에서 보여주고 있으나, 질문의 범주와는 관련이 없습니다.  따라서 본론에서 추가적인 내용을 서술할 수 없습니다.


**결론:**

제공된 학술 문서에는 질문에서 요구하는 DBN 기반 딥러닝을 이용한 기업부도 예측과 기존 SVM 방법 간의 성능 차이, 특히 부도기업 예측 민감도 향상 결과에 대한 정보가 포함되어 있지 않습니다. 따라서 질문에 대한 답변은 불가능합니다.  추가적인 관련 자료가 필요합니다.",딥러닝 알고리즘을 이용한 제주도 관광객 수 예측,딥러닝 기반 시선 추정 시스템,문법 기반 타일링을 이용한 텍스처와 개체 분포 생성,자율주행 자동차를 위한 딥러닝 기반 실시간 장면 이해에 관한 연구,딥러닝 알고리즘을 이용한 저널추천 방법론,딥러닝 기반 범죄자 신원 인식 시스템 설계 및 구현,딥러닝 모델을 이용한 AV 미디어 기반 실감효과 장면 검출 기법,딥러닝 알고리즘의 학습시간 단축에 대한 연구,마인크래프트를 활용한 게임기반학습 프로그램 개발 및 적용,딥러닝 방법론의 이해,머신러닝 기반 손동작 EEG(뇌전도)신호 판별 연구,모바일 인터넷 기반 농기계 관리진단 시스템의 구현,간호대학생의 근거기반실무 역량에 영향을 미치는 요인,스마트 교육을 기반으로 한 융합형 가정과 프로그램 개발,인공지능 기반 대화형 인터랙션에 대한 사용자 경험 연구,델파이와 AHP 기법을 활용한 이러닝 기반 교원연수 프로그램 평가 모형 개발 연구,수치모델을 통한 한국 남해 동부해역의 해양쓰레기 이동에 관한 연구,소비자들의 서비스 로봇의 이용의도 영향요인에 대한 탐색적 연구,지속가능한 수변지역 개발을 위한 토지이용계획,지방자치단체의 구역 및 경계에 관한 법적 과제,A numerical experiment study on the circulation of the Japan Sea : East Sea,딥러닝 기법을 활용한 비디오 감성 분류,공감기반 학습모형 개발연구,사례기반 애니메이션을 활용한 간호사 대상 근거기반간호 임상질문 이러닝 프로그램 개발 및 효과,다중이용업소 소방안전의 실효성 확보를 위한 방안,다중이용업소 화재피해 최소화 방안에 관한 연구 : 화재 원인 조사 분석을 중심으로,민간의료보험 가입이 의료이용에 미치는 영향,한중소비자의 여행공유경제 이용의도 비교분석 : 여행공유경제 플랫폼과 소비자 개인 특성을 중심으로,화석돌말류를 통한 울릉분지와 대한해협에서의 고해양학적인 연구,,,,,,,,,,,,,,,,,,,,,
비정형 리뷰 데이터를 활용해 고객 평점을 예측하기 위해 설계된 딥 러닝 모델 구조와 주요 실험 결과(정확도·출력 카테고리)를 요약해 주실 수 있나요?,"##제목## 딥러닝 기반 고객평점 예측 모델 요약 ##서론## 온라인 쇼핑몰에서는 사용자가 남긴 비정형 텍스트 리뷰가 구매 결정에 큰 영향을 미치지만, 개인정보 제약으로 일반적인 고객 특성 데이터를 활용하기 어렵다. 본 연구는 리뷰 자체에서 고객 특징을 자동으로 추출해 평점을 예측하는 딥러닝 모델을 제안한다. ##본론## 모델 구조는 텍스트 마이닝 기법을 통해 전처리된 리뷰 텍스트로부터 특성을 추출하고, 다층 퍼셉트론 구조에 입력하도록 설계되었다. 은닉층에는 과적합을 완화하기 위한 Drop-Out을 적용하고, 활성화 함수로는 연산 효율이 높은 ReLU를 사용했다. 출력층은 고객 평점을 ‘좋음’, ‘보통’, ‘나쁨’의 세 가지 카테고리로 분류하도록 구성되었다. 실험 대상은 11번가에서 수집한 화장품 리뷰 데이터이며, 학습된 모델은 실제 입력 평점과 비교해 90%의 분류 정확도를 기록했다. ##결론## 제안된 딥러닝 모델은 비정형 리뷰만으로 고객 평점을 세 단계로 높은 정확도로 예측할 수 있음을 보였으며, 개인정보 없이도 사용자 만족도 분석 및 추천 시스템 등에 활용 가능함을 입증했다.",Can you summarize the deep learning model structure and major experiments designed to predict the customer ratings by utilizing atypical review data?,"##title## Summary of deep learning -based customer rating prediction model ##introduction## In the online shopping mall, the user's unstructured text review has a big impact on the purchase decision, but it is difficult to use general customer characteristics data as a constraint of personal information. This study suggests a deep learning model that automatically extracts customer features and predicts the rating. ## Main ## The model structure is designed to extract the characteristics from the pre -processed review text through the text mining technique and to input it into the multilayer perceptron structure. The hidden layer applied a Drop-out to relieve overpacking, and the activation function used a high computational efficiency. The output layer is composed of three categories: 'good', 'normal' and 'bad'. The experiment target is cosmetics review data collected at 11th Street, and the learned model recorded 90%classification accuracy compared to the actual input rating. ##conclusion## The proposed deep learning model shows that the customer rating can be predicted at three stages with only an atypical review, and proved to be used for user satisfaction analysis and recommendation system without personal information.","Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",28,1.1859924140007934,"**제목: 비정형 리뷰 데이터 기반 고객 평점 예측 딥러닝 모델 분석 보고서**

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 비정형 리뷰 데이터를 활용하여 고객 평점을 예측하는 딥러닝 모델의 구조와 주요 실험 결과(정확도, 출력 카테고리)를 분석합니다.  문서들은 다양한 빅데이터 분석 기법과 리뷰 데이터 분석 사례를 제시하지만, 딥러닝 모델의 구체적인 구조와 실험 결과는 명시적으로 제시하지 않습니다. 따라서 본 보고서는 제공된 자료의 범위 내에서 분석 가능한 내용만을 다룹니다.

**본론:**

제공된 문서들은 빅데이터 분석을 활용한 다양한 연구들을 소개하고 있으나, 질문에서 요구하는 딥러닝 모델의 구체적인 설계와 실험 결과는 포함하고 있지 않습니다. 문서 1은 심전도 데이터 분석을 위한 빅데이터 플랫폼 개발을, 문서 2는 조직 신뢰 지수 추이 분석 모델을, 문서 3은 양양국제공항에 대한 소비자 관심 성향 분석을, 문서 4는 조작된 리뷰 식별 연구를, 문서 5는 영화 리뷰와 흥행 요인 분석을 다룹니다. 이 연구들은 모두 빅데이터 분석 기법을 활용하지만, 고객 평점 예측을 위한 딥러닝 모델 구축 및 실험 결과는 제시하지 않습니다.  문서 4는 소비자가 조작되었다고 평가한 리뷰와 일반적인 리뷰 간의 차이를 다수준 로지스틱 회귀분석과 포아송 회귀분석을 이용하여 분석했으나, 이는 딥러닝 모델이 아닌 통계적 기법을 활용한 것입니다.  문서 5는 리뷰의 양과 방향성이 영화 흥행에 미치는 영향을 SPSS를 이용하여 분석하였으나, 역시 딥러닝 모델과는 무관합니다. 따라서 제공된 문서만으로는 질문에 대한 명확한 답변을 제공할 수 없습니다.


**결론:**

제공된 문서에는 비정형 리뷰 데이터를 활용한 고객 평점 예측을 위한 딥러닝 모델의 구조 및 구체적인 실험 결과(정확도, 출력 카테고리)에 대한 정보가 포함되어 있지 않습니다. 따라서 질문에 대한 답변은 불가능합니다. 추가적인 자료가 필요합니다.",빅데이터 기반의 생체신호 분석 플랫폼 개발,데이터 마이닝 기법을 활용한 조직 신뢰 지수 자동 추이분석 모델링 방법론,양양국제공항에 대한 소비자관심 성향 빅데이터 시각화 분석,조작된 리뷰(Fake Review)는 무엇이 다른가?,리뷰 작성 시기에 따른 영화의 주 별 흥행 요인 연구 : 리뷰의 양과 방향성을 중심으로,관광 공공데이터 기반 모바일 애플리케이션의 사용자 관심요소 분석,데이터 마이닝 기법에 관한 연구,미국 기업의 오픈데이터 활용사례와 비즈니스 네트워크 분석 : “데이터와 기술” 분야를 중심으로,빅데이터 기반의 생체신호 분석 사례 및 연구,기업의 빅데이터 활용 수준 진단지표 개발 연구,온라인 리뷰가 소비자 온라인 리뷰 지지에 미치는 영향에 관한 연구,온라인 리뷰 유용성과 상품매출에 영향을 주는 요인 : 중국 온라인 쇼핑 플랫폼을 기반으로,전환적 지역혁신정책: 리뷰,온라인 구전에서 리뷰 유형과 리뷰 방향성이 소비자의 지각된 유용성에 미치는 영향,빅데이터 활용과 분석기법 고찰,데이터 시각화를 이용한 미디어아트 : 빅 데이터 시각화 작품 <Earth>를 중심으로,Incretin-based therapy :A look into the characteristics of various DPP-4 inhibitors in the market and currently in development : 인크레틴 요법: 현재 시판중이거나 시판 준비중인 DPP-4 억제제에 대한 리뷰,"한방병원 입원 4기 암환자들의 CRP, ESR, Fibrinogen 수치 변화와 치료기간과의 상관관계 분석 : 후향적 차트리뷰 : Correlation of Inflammation and Coagulation Markers with the Treatment Period of Stage IV Cancer Inpatients in a Korean Medicine Hospital:A Retrospective Chart Review",온라인 리뷰 콘텐츠와 언어 스타일이 리뷰 유용성에 미치는 영향,A Study to verify the Location of Tak-lock(&#x6dbf;鹿),창옥병(蒼玉屛)의 위치 비정(比定) 및 사암(思菴) 박순(朴淳)의 정원유적 연구,웹@매니아 리뷰,금성의 위치 비정,‘임나 4현’의 위치 비정,A Study on the Location of Mokjikuk,A Study to Verify the Location of the Mt. Gal-Seok(碣石),백제부흥운동기 주류성 위치 비정 연구,Study on the Location for Tomb of King Jinpyeong of Silla,목출도(木出島)'의 명의(名義)와 비정(比定)에 관한 고찰(考察),A Study on the Location of the Palace of Goryeo Dynasty Namgyung,,,,,,,,,,,,,,,,,,,,
"Go 게임에 적용된 심층 학습 기술의 핵심 아이디어와 제안된 CNN 레이어 구성, 실험 비교 결과를 간결하게 정리해 주실 수 있나요?","##제목## 바둑에 적용된 심층 학습 기술 설계 및 성능 비교 ##서론## - Go 게임은 규칙은 단순하지만 조합 수가 방대하여 전통적 알고리즘만으로 최적 수를 탐색하기 어려움 - 딥 러닝, 특히 CNN을 활용해 수읽기와 다음 수 예측 정확도를 높이고자 하는 연구가 주목받고 있음 ##본론## - 핵심 아이디어: 오픈소스 Go 엔진(HuuDucGo, Orego, Fuego)에 심층 학습을 접목하여 다음 착점을 계산 - 제안된 CNN 구조: 5개의 은닉층 중 3개를 컨볼루션 레이어로 구성하고, 나머지 2개는 완전연결층으로 수 평가 수행 - 학습 방법: 대규모 기보 데이터를 이용해 각 네트워크가 정책망(policy network)으로 작동하도록 지도학습 - 실험 결과: HuuDucGo 모델은 Orego 및 Fuego와 비교 시 수렴 속도와 착점 예측 정확도에서 유사한 성능을 보이며, 제안 구조의 실용성 입증 ##결론## - 3개의 CNN 레이어를 포함한 5층 네트워크는 기존 엔진과 동등한 수준의 수읽기 성능을 달성 - Go 게임에 대한 딥 러닝 적용 가능성을 확인했으며, 향후 대용량 연산 및 강화학습 도입으로 추가 성능 향상 여지 존재","Can you briefly summarize the core ideas of in -depth learning technology applied to Go games, the proposed CNN layer configuration and experimental comparison results?","##title## In -depth learning technology design and performance comparison applied to Go ##introduction## -GO game has a simple rules, but the number of combinations is huge, so it is difficult to explore the optimal number with traditional algorithms. -The research to increase the number of reads and the next water prediction accuracy using deep learning, especially CNN, is attracting attention. ## Main ## -Core Ideas: Calculate the next worship by incorporating in -depth learning with open source Go engine (Huuducgo, Orego, Fuego) -CNN structure proposed: 3 out of five hidden layers consists of a confection layer, and the other two are completely connected to the number of numbers. -Learning method: Learning to operate each network with a policy network using large -scale notification data. -The HuuducGo model shows similar performance in convergence speed and accuracy of accuracy when comparing with OREGO and FUEGO. ##conclusion## -The 5th floor network, including three CNN layers, achieves the same level of reading performance as the existing engine. -I have confirmed the possibility of applying deep learning for GO games, and the introduction of large -capacity computing and reinforcement learning in the future","Title: Deep Learning 프레임워크 성능 비교 연구 : Cloud Computing 환경에서, Abstract: 통신 기술의 발달로 인한 사람과 사람, 장치와 장치, 사람과 장치 간의 연결성의 증가와 저장 매체 기술의 발달, 그리고 데이터 저장 비용의 감소로 인해 데이터의 양이 폭발적으로 증가했다. 이에 따라 다양한 형태의 대규모의 데이터를 빠른 시간 내에 효율적으로 처리할 수 있는 Cloud Computing 기술이 주목 받고 있고, Cloud Computing을 위한 오픈소스 기반의 솔루션 또한 많이 나타나게 되었다. &amp;#xD; 2012년부터 주목받기 시작한 Deep Learning은 전 세계적으로 가장 많은 관심을 받는 연구 분야 중 하나이며, 이중 CNN(Convolution Neural Network)은 가장 대표적 알고리즘이다. Deep Learning은 미래사회를 이끌어갈 분야로 평가받고 있으며, 이에 따라 많은 연구들이 진행되고 있고, Deep Learning을 쉽게 활용할 수 있도록 하는 많은 프레임워크가 개발되었다. &amp;#xD; 이에 따라 많은 사람들이 쉽게 Deep Learning을 접할 수 있게 되었지만 특정 환경에서 어떤 프레임워크가 더 우수한 성능을 보이는지에 대한 연구는 부족한 실정이다. 본 논문에서는 특정 환경에서의 성능 비교가 부족하다는 기존 연구의 한계점을 개선하고자 가장 대표적인 Cloud Computing용 오픈소스 소프트웨어 중 하나인 OpenStack을 이용하여 Cloud Computing 환경에서 어떤 Deep Learning 프레임워크가 더 우수한 성능을 보이는지 비교해 보고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014373092,","Title: 딥 러닝을 이용한 DC 모터 제어, Abstract: 딥 러닝(deep learning)은 최근에 많이 알려지게 된 심층 인공신경망 알고리즘이다. 일반적인 인공신경망보다 은닉층의 개수와 뉴런의 개수를 확장시키고, 학습이 효율적으로 될 수 있게 알고리즘을 개선한 것이 가장 큰 특징이다. 이러한 특징을 활용하여 기존의 인공신경망으로 풀지 못했던 크고 복잡한 문제들을 해결할 수 있게 되었다. 음성인식, 손 글씨 인식, 얼굴 인식 등 복잡한 패턴인식과 분류에 관련된 다양한 분야에 대한 적용 연구가 활발히 진행되고 있다. 하지만 이러한 장점에도 불구하고, 아직까지 딥 러닝이 제어문제를 해결하기 위해 적용된 사례는 찾아보기 어렵다. 본 논문에서는 간단한 사례를 통해 딥 러닝의 제어문제에 대한 적용 가능성을 확인해 본다. 딥 러닝 알고리즘 중에서 가장 잘 알려진, 깊은 믿음 네트워크(deep belief network) 알고리즘을 사용하여 산업현장에서 가장 많이 사용되고 있는 PID 제어기를 모방하는 딥 러닝 제어기를 설계한다. DC 모터를 제어하는 시스템에서 PID 제어기에 들어오는 입력과 PID 제어기에서 나오는 출력값을 학습 데이터로 사용하여 딥 러닝으로 학습하는 방법을 사용한다. 시뮬레이션을 통해 제안한 딥 러닝 제어기와 PID 제어기를 비교하여 딥 러닝 알고리즘의 성능을 검증한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0013710110,","Title: 딥러닝 알고리즘에 기반한 기업부도 예측, Abstract: 기업의 부도는 국가경제에 막대한 손실을 입히며, 해당기업의 이해관계자들 모두에게 경제적 손실을 초래하고 사회적 부를 감소시킨다. 따라서 기업의 부도를 좀 더 정확하게 예측하는 것은 사회적·경제적 측면에서 매우 중요한 연구라 할 수 있다. &amp;#xD; 이에 최근 이미지 인식, 음성 인식, 자연어 처리 등 여러 분야에서 우수한 예측력을 보여주고 있는 딥러닝(Deep Learning)을 기업부도예측에 이용하고자 하며, 본 논문에서는 기업부도예측 방법으로 여러 딥러닝 알고리즘 중 DBN(Deep Belief Network)을 제안한다. 기존에 사용되던 분석기법 대비 우수성을 확인하기 위해 최근까지 기업부도예측에서 연구되고 있는 SVM(Support Vector Machine)과 비교하고자 하였으며, 1999년부터 2015년 사이에 국내 코스닥·코스피에 상장된 비금융업의 기업데이터를 이용하였다. 건실기업의 수는 1669개, 부도기업의 수는 495개이며, 한국은행의 기업경영분석에서 소개된 재무비율 변수를 이용하여 분석을 진행하였다. 분석결과 DBN이 SVM보다 여러 평가척도에서 더 좋은 성능을 보였다. 특히 시험데이터에 대해 부도기업을 부도기업으로 예측하는 민감도에서 5%이상의 더 뛰어난 성능을 보였으며, 이에 기업부도예측분야에 딥러닝의 적용가능성을 확인해 볼 수 있었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014169472,","Title: 딥 러닝기반 고객평점 예측모델, Abstract: 인터넷의 발달과 휴대용 기기의 발달로 사용자들이 데이터를 생산하고, 공유하는 일들이 매우 자연스럽고 쉬운 일이 되었다. e-마켓플레스로 대변되는 온라인 쇼핑몰에서도 사용자들의 데이터 생산과 공유가 리뷰의 형식으로 활발하게 이루어지고 있다. 리뷰의 형식은 보통 정해진 형식이 없는 비 정형데이터인 텍스트와 제품에 대한 고객의 평점으로 이루어져있다. 이와 같이 형태로 적극적으로 공유된 정보들은 구매에 중요한 요소로 사용되고 있다. &amp;#xD; 본 논문에서는 이렇게 누적된 리뷰 데이터를 학습하여 고객의 평점을 예측하는 딥 러닝(Deep learning) 모델을 작성하고자 한다. 학습에 필요한 입력데이터 즉 고객의 특성에 관한 일반적인 정보는 쇼핑몰 내부에 있고, 개인 정보가 포함되어 있기 때문에 사용하기 어려운 문제점이 있다. 이를 극복하기 위해 리뷰 자체에서 고객의 특징(feature)을 추출하는 방법을 사용하였다. 비정형 리뷰 데이터에서 텍스트 마이닝 기법을 사용하여 정형화된 고객의 특징을 추출하였다.&amp;#xD; 실험 대상 제품은 11번가 쇼핑몰에서 하나의 화장품을 선정하였다. 최적의 딥 러닝 모델을 찾기 위하여 Drop-Out 및 Rectified Linear hidden Unite(ReLU)를 사용하며 결과를 평가하였다. 딥 러닝의 예측 결과는 고객 평점을 기반으로 하여 좋음, 보통, 나쁨 3가지를 출력 하도록 실험을 진행하였다. 실험을 통해 완성된 딥 러닝 모델이 출력하는 좋은, 보통, 나쁨 3가지 결과와 실제 고객이 입력 한 평점을 비교하였다. 실험 결과 90%의 정확도를 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014861002,","Title: 바둑에 적용된 깊은 학습: 응용 및 실험에 대한 조사, Abstract: 4 천년 전에 Go-game (바둑) 이 발명되어 널리 지능을 가진 사람들을 가르치기 위해 널리 적용되었습니다. 많은 왕이 그것을 연주하고 지능을 향상시키기 위해 아들을 가르쳤습니다.&amp;#xD; 1980 년대에 퍼스널 컴퓨터가 만들어지고 인기를 얻었습니다. 또한 많은 게임이 사람들이 컴퓨터로 게임을하거나 기존 게임을 플레이 할 때 사용자를 지원할 수 있도록 프로그래밍되어 있습니다. Shogi, Chess, Xiangqi, Go-game, tic-tac-toe 등과 같이 지금까지도 우리 조상이 연주 한 많은 유명한 전통 게임이 컴퓨터 프로그램에 의해 삽화가되고 많은 게임이 성공적으로 프로그래밍되었습니다 . 점진적으로 개선되기 위해 매일 복잡성 게임이 개발되고 있습니다. 특히, 복잡성이 매우 높은 일부 게임은 장군, 체스, 고 게임 등과 같은 전략과 규칙을 가지고 노는 것이 지능적이라고 생각합니다. 인간과 똑같이 지능적으로 플레이 할 수 있도록 프로그램하는 것은 매우 어렵습니다.&amp;#xD; 기계 학습은 컴퓨터가 인간의 두뇌와 유사한 데이터를 생각하고 학습하게하는 솔루션으로 부상했습니다. 알고리즘을 사용하여 분석 모델을 작성하여 컴퓨터가 특정 목적을 위해 주어진 데이터에서 '학습'하도록 돕습니다. 이제는 무인 자동차, 로봇 장치와 같은 흥미 진 진한 새로운 응용 프로그램을 만들기 위해 방대한 양의 데이터에 적용 할 수 있습니다. 딥 러닝 (Deep Learning)은 인공 신경 네트워크 (artificial neural networks)라고 불리는 뇌의 구조와 기능에 영감을받은 알고리즘과 관련된 기계 학습의 하위 분야입니다. 이것은 더 나은 훈련 된 데이터 세트를 얻기 위해 학습 진도를 향상시키는 새로운 접근법으로 알려져있어 더 정확한 결과를 초래합니다.&amp;#xD; 내 논문은 Go-game에 깊은 학습을 적용하는 데 중점을 둡니다. 나는 'Go-game에 적용된 깊은 학습'에 관한 설문 조사를합니다. Go-game에 대한 오픈 소스 코드 프로젝트와 문제 해결을위한 심층적 인 학습 기술을 적용하는 방법을 소개합니다. 정확성과 효과가 더 높은 Go- 게임을위한 다음 동작 계산에 대해 자세히 설명합니다. 저는 고문 교수 인 Jung Keechul과 함께 Go-game의 차세대 제안에 대한 제안을했습니다. 이 방법에서는 3 개의 CNN 레이어가있는 5 개의 숨겨진 레이어를 사용하여 데이터를 학습합니다.&amp;#xD; 저의 논문의 기여는보다 높은 성과와 효과를 가진 HCI에 깊은 학습을 적용하는 접근법을 과시하는 것입니다. 첫째, 심층 학습에 대한 완전한 관찰과 그것을 설문 조사를 통해 적용하는 방법을 제공했습니다. Go-game에 깊은 학습이 적용되었습니다. 둘째, Go-game 연구 및 프로젝트에 필요한 거대한 자원을 보여주었습니다. 셋째, Go-game에 적용된 실험과이 분야에서의 작업을 보여주었습니다. 마지막으로 필자는 내 프로그램 (HuuDucGo), Orego 및 Fuego의 3 가지 프로그램을 비교했습니다. 그들 사이에 제안의 수렴은 다음을 보여줍니다 : HuuDucGo의 제안을 받아 들일 수 있습니다. 우리의 작업에 대한 특별한 실험 : Orego와 Fuego와 같은 다른 두 가지 큰 프로그램의 제안과 수렴되는 수용 가능한 결과를 가지고 Go- 게임을 할 때 다음 행동을 계산하고 제안하는 데 깊은 지식을 적용합니다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014545149,","Title: = Deep Learning을 이용한ROS기반의 모바일 로봇의 자율 주행 제어, Abstract: 최근 영상처리 기술의 발전과 인공지능 및 Deep learning 기술의 발전으로 말미암아 자율주행 자동차가 앞으로의 시장을 주도할 차세대 기술로 주목되고 있다. 그에 맞추어 본 논문에서는 ROS(Robot Operate System) 기반의 모바일 로봇인 ‘터틀봇3’를 활용하여 라인의 영상처리 이미지 데이터를 추출 한 후 라인을 트랙킹하는 자율 주행 제어를 구현하였다. 영상처리는 ‘OpenCV’를 기본으로 하여 Canny 알고리즘과 Houghline 알고리즘을 통해 라인을 검출 한 후 이미지 데이터를 ROS의 메시지 통신을 통해 전송되고, 전송된 데이터를 바탕으로 모바일 로봇의 주행을 제어 한다. Deep Learning을 이용하여 모바일 로봇의 주행 기록을 학습시켜 모바일 로봇의 주행을 보완한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014721788,","Title: 눈 특징의 STFT 결합 영상과 deep learning을 이용한 감성 인식, Abstract: 최근 사용자의 요구를 이해하기 위해 인간-컴퓨터 상호작용 (HCI) 분야에서 다양한 연구가 수행되고 있다. HCI의 대표적인 기술 중 하나는 사용자 감정 인식이다. 감정의 중요성이 증대됨에 따라, 사용자의 감정을 인식하기 위해 얼굴 표정, 제스처, 음성신호, 생리신호, 안구특징 및 멀티 모달리티 (Multi-Modality) 신호를 특징으로 사용하는 방법들이 제안되고 있다. &amp;#xD; 특히, 안구 특징은 사용자가 의도적으로 제어할 수 없으며 컴퓨터가 무의식적인 특징들을 인식할 수 있기 때문에 감정인식에 적합하다. 또한 다양한 분야에 적용될 것으로 기대되는 가상현실과 증강현실을 위해 안구 특징에 기반한 감정인식 기술이 연구되어야 한다.&amp;#xD; 합성곱 신경망 (CNN)과 재귀 신경망 (RNN)과 같은 심층 학습 (Deep learning) 기술들이 다양한 분야에서 성공하고 있으며, 다양한 모달리티들을 이용하는 감정인식 연구에 적용되고 있다. 그러나 다른 모달리티들과 달리, 안구 특징만을 사용하는 심층 학습기반의 감정인식 연구는 매우 부족하다.&amp;#xD; 본 학위논문에서는 시간정보와 동공 크기와 눈 움직임 신호와 같은 안구 특징들만을 이용한 심층 학습 기반의 감정인식 방법을 제안한다.&amp;#xD; 그 과정은 다음과 같다. 먼저, 눈 깜빡임 또는 기술적인 결함으로 인해 발생되는 눈 크기 및 눈 움직임 신호들의 데이터 미획득 구간을 채우기 위한 보간을 수행한다. 그 후 데이터의 길이와 범위를 일치시키기 위해, 신호의 시간과 각 피실험자의 신호들에 대해 정규화를 수행한다. 다음으로 동공 크기 및 눈 움직임 신호들의 시간과 주파수 정보를 분석하기 위해 Short-Time Fourier Transform (STFT) 특징들을 추출하고, 그 특징들을 결합하여 STFT 특징 결합 영상이라 불리우는 단일 이미지를 생성한다. 마지막으로, valence-arousal 인식을 수행하기 위해, STFT 특징 결합 영상에 적합한 심층 학습 모델을 생성한 후 leave-one-out cross validation (LOOCV) 방법을 이용하여 제안하는 방법의 성능을 평가한다. &amp;#xD; 대부분의 연구에서, 안구 특징은 다른 모달리티 기반의 감정인식 성능을 향상시키기 위한 보조정보로만 사용하고 있다. 이는 안구 특징이 자극에 민감하고 수동적인 특징 추출방법으로 양질의 특징을 추출하기 어려운 많은 이상치 (Outlier)들을 포함하기 때문이다. 그러나 제안하는 방법의 분류 정확도는 Soleymani [53]가 제안한 결정 수준 융합 (DLF)와 서포트 벡터 머신 (SVM)을 이용한 방법보다 valence와 arousal 감정에 대해 각각 23.6%, 9.8% 향상된 분류 정확도를 달성하였다.&amp;#xD; 실험결과는 제안하는 방법의 효과성을 입증하였고, CNN 모델이 다른 모달리티 기반의 감정인식 방법뿐만 아니라 안구 특징 기반 감정인식에도 효과적이며, 눈 움직임 정보가 valence 감정 인식에도 효과적임을 보였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014668242,","Title: 딥 러닝 기반 머리 포즈 추정 및 얼굴 특징점 정렬에 관한 연구, Abstract: 컴퓨터 비전은 어떤 영상에서 장면이나 특징을 인식하는 분야로 근본적인 목적은 입체를 인식하거나 영상 내의 객체를 인식, 또는 객체 간의 관계를 이해하는 것이다. 1982년 D. Marr의 “Vision”이 출간된 이후 생물학적 접근에 의한 비전 연구가 주목을 받기 시작하면서 인공신경망을 이용한 컴퓨터 비전 연구가 활발히 진행되었다. 이후 1998년 Yann LeCun 등이 Convolutional Neural Network의 구조를 제안하였고, 이것이 초기의 CNN 모델이다. 본격적으로 Deep Learning이라는 용어는 Geoffrey Hinton에 의해서 사용되었다. 2006년 Geoffrey Hinton은 기존 신경망의 문제점을 해결하기 위해 Unsupervised Learning을 적용하는 방법을 제안하였다. 또한 최근 GPU의 발전으로 기존의 학습 속도의 한계를 극복하였고, 각종 Social Network Service(SNS)가 활발해 짐에 따라 다양한 형태의 데이터를 활용할 수 있게 되었다. 본 연구은 딥 러닝 기술 중 컴퓨터 비전에서 대표적으로 사용하는 Convolutional Neural Network(CNN)를 적용하여 사람의 머리 포즈를 추정하고 얼굴 특징점을 정렬하는 방법을 구현한다. 머리 포즈를 추정하기 위해서 CNN 중 분류(Classification)기법을 사용하고 각 층(Layer)의 수를 3, 4, 5개의 비지도학습(Unsupervised Learning)과 2개의 지도학습( Supervised Learning)을 이용한 구성을 비교하여 실험한다. 또한 입력 데이터의 채널 및 데이터의 양과 입력 방법에 따른 결과를 비교, 분석한다. 얼굴 특징점을 정렬하기 위해서 계층구조(Hierarchical Structure)를 사용하고 각 특징의 상관관계를 포함하지 않는 패치(Patch)를 적용하는 방법을 구현한다. 머리 포즈 추정에 사용한 데이터베이스는 ICT-3DHP, Biwi, GI4E와 자체 제작한 DB로 총 36,000장의 데이터를 사용하여 학습 및 실험을 한다. 또한 얼굴 특징점 정렬에 사용한 데이터베이스는 AFLW 10,000장을 학습하고 5,000장을 테스트한다. 머리 포즈 추정 실험의 오류를 측정하는 방법으로 Mean Absolute Error(MAE)를 사용하여 비교하였으며, Roll, Pitch, Yaw의 MAE는 각각 0.78, 0.99, 1.40의 값을 얻었다. 또한 얼굴 특징점 정렬은 Mean Absolute Percent Error(MAPE)를 사용하여 오차를 계산하였다. 21개의 각각의 특징점 평균 오차 약 1.0으로 기존의 평균보다 뛰어난 성능을 보인다. 이는 기존의 POSIT으로 추정한 값과 달리 얼굴 특징점을 사용하지 않고 영상만을 보고 판단할 수 있는 컴퓨터 비전에서 궁극적 형태의 새로운 학습 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014007463,","Title: 포인트 클라우드 기반 딥 러닝 기법을 이용한 BIM 객체 분류에 관한 연구, Abstract: 건축 산업 전반에 BIM(Building Information Modeling)의 활용이 확대되고 있다. BIM은 3차원 건축물 객체 데이터를 기반으로 건축물이 지닌 다양한 정보를 담고 있는 데이터 형태이다. BIM 데이터는 IFC(Industry Foundation Classes) 표준 형태로 제작 및 배포된다. 이 때 BIM 데이터를 IFC 표준으로 생성하는 과정에서 설계자가 직접 IFC 데이터의 정보를 매핑해야 하는 문제가 존재한다. 이는 전문 인력 자원의 소요와 인적 오류의 발생 가능성을 높일 수 있는 위험을 지니고 있다. 본 연구에서는 이러한 위험을 줄이고, 보다 효과적으로 IFC 표준에 맞는 BIM 데이터 생성을 위한 딥 러닝 기법을 이용하여 학습한 모델을 통한 자동화된 BIM-IFC간 클래스 매핑 과정을 제안하였다.표준 BIM 라이브러리 데이터인 KBIMS 데이터를 이용한 실험에서 심층 신경망, 합성곱 신경망, Pointnet 총 3개의 딥 러닝 구조를 학습하여 평가하였다. 실험 결과 세 모델 모두 85% 이상의 높은 성능을 보였으며 그 중 3차원 객체의 위치 정보를 점들의 집합 형태의 데이터인 포인트 클라우드 형태로 표현한 Pointnet이 95% 이상의 정확도를 보여 가장 높은 성능의 모델임을 확인할 수 있었다. 본 연구의 의의는 BIM-IFC 클래스 매핑 작업에서 자동화된 딥 러닝 기반 모델 학습 과정을 통해 기존의 설계 전문가가 수작업으로 수행하는 정보 입력 과정을 자동화할 수 있다는 가능성을 보여준 것에 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0014912468,","Title: Deep Learning을 활용한 산사태 결정론 방법의 활용성 고찰, Abstract: 산사태 위험지역을 결정론적인 방법으로 도출할 수 있는 Analytic Hierarchy Process (AHP) 기반의 선행 연구가 2017년도에 제안되었다. 해당 연구의 목적은 기존에 제안된 결정론적인 방법의 활용성을 향상시키고자 deep learning 기법을 적용하여 해당 방법의 신뢰성을 검증하는 것이다. AHP 기반의 결정론적인 방법은 8개 인자인 세립분 함량, 표토층 두께, 간극비, 탄성계수, 전단강도, 투수계수, 포화도 그리고 함수비로 구성되며 이를 통해 안전율을 도출할 수 있다. 대상 지역을 1 m 정사각형의 격자로 구성한 후 현장 및 실내 실험을 통해 8개의 인자를 도출하였다. 안전율은 Mohr-Coulomb의 파괴 이론을 통해 계산하여 deep learning의 출력 값으로 활용하였다. Deep learning 기법 적용 시 입력 값과 출력 값의 학습 능률을 향상시키기 위하여 경사하강법 중 Bayesian regularization을 적용하였으며, 학습 결과 실제 안전율과 deep learning 기법으로 예측된 안전율이 train과 test 단계 모두에서 우수한 신뢰성을 보여준다. 해당 연구에서 활용한 deep learning 기법이 산사태 위험지역 선정에 결정론적 방법으로 유용하게 이용될 것으로 사료된다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116645979,","Title: Deep Learning 기반 COF 이미지 검사시스템, Abstract: 제품단가 대비 불량유출 위험도가 높은 Chip On Film시장에서, 광학품질검사는 주요 과제 중 하나이다. 따라서 관련 기업들은 자동 전수검사를 기본적으로 수행하고 있으며, 이의 성능을 향상시키는 데 투자를 아끼지 않고 있다. 그러나 기존 검사방법의 성능 문제로 인해 최종 판정은 아직 작업자들에 의해 수행되고 있으며, 대부분의 비용이 아직 인적 자원에 투자되고 있다. 최근 집중 조명 받은 Deep learning 관련 기술은 이러한 기존 광학품질검사의 패러다임을 바꾸는 듯 했으나, 이를 COF 양산 검사시스템에 성공적으로 적용한 사례는 아직 보고되지 않고 있다. 불량유출의 허용치는 0.00005% 이하인 50ppm수준으로 철저히 관리되어야 하지만, 기존 DL Model의 학습 방식으로는 상기와 같은 수준의 불량유출 허용치를 관리하기 어렵기 때문이다. 이의 이유로는 크게 두 가지를 들 수 있다. 첫째, 학습 Data로 사용될 COF 이미지의 Region of interest(ROI) 추출이 어렵다. 둘째, COF 불량 유형이 학습된 Deep learning Model의 Overfitting 및 Underfitting 제어 난이도가 어렵다. 셋째. Deep learning에 적합한 데이터 유형인지에 대한 정량적인 판단이 어렵다.&amp;#xD; 본 논문에서는, 상기 언급된 한계를 개선하는 새로운 COF양산 검사 시스템을 제안한다. 제안하는 방법은 불량 Feature의 ROI를 보다 정교하게 추출할 수 있는 방법 중 하나인 Inpainting기법의 접목, 이를 불량 유형에 맞게 CNN 혹은 전통적 Image processing을 사용할지를 결정하는 정량적인 Parameterize score의 설계, 그리고 Heuristic하게 구성된 DL기반의 이미지 판정 기법으로 구성된다. 제안된 양산 검사 시스템은 기존 광학검사를 대체하여, 기존대비 성능을 200% 이상 향상시켰으며, 불량 허용치를 0.00003% 이내인 30ppm 수준으로 요구 수준을 달성하였다. 제안되는 방법은 국내 COF 생산 기업의 공장의 양산 검사 시스템에 실제로 접목되었으며, 현재도 공장 내 Process의 하나로 자리 잡고 비용절감에 지속적으로 기여하고 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0015530077,","Title: Deep Semi-Supervised Learning 기반 컴퓨터 보조 진단 방법론, Abstract: Medical image applications 분야는 가장 인기 있으며 적극적으로 연구되는 현대 Machine Learning 및 Deep Learning applications 중 하나의 분야로 부상되고 있다. Medical image analysis는 환자의 신체 영상의 획득과 의료 전문가의 진단 및 분석을 목적으로 한다. 여러 Machine Learning 방법론을 사용하면 다양한 질병을 진단할 수 있게 된다. 하지만, 보다 효율적이며 강인한 모델을 설계하기 위해서는 Label이 지정된 데이터 샘플이 필요하게 된다. &amp;#xD; 따라서, Label이 지정되지 않은 데이터를 활용하여 모델의 성능을 향상시키는 Medical image 분야에서 semi-supervised Learning의 연구가 활발히 이루어지고 있다. 본 연구에서는 2D 초음파 영상(CADe)와 KL-grade 무릎 방사선사(CADx) 분류에서 유방 병변 Segmentation을 위한 딥러닝 기술을 사용하여 Medical image analysis에서 개선된 Semi-Supervised CAD 시스템을 제안하였다. 본 논문에서는 residual 및 attention block을 통합한 residual-attention-based uncertainty-guided mean teacher framework를 제안한다. 높은 수준의 feature와 attention module의 flow를 가능하게 하여 deep network를 최적화하기 위한 residual은 학습 과정 중에서 가중치를 최적화하기 위해 모델의 focus를 향상시킨다. &amp;#xD; 또한, 본 논문에서는 semi-supervised 학습 방법을 사용하여 학습 과정에서 label이 지정되지 않은 데이터를 활용할 수 있는 가능성을 탐구한다. 특히, uncertainty-guided mean-teacher-student 구조를 활용하여 residual attention U-Net 모델의 학습 중 label이 지정되지 않은 샘플을 통합할 수 있는 가능성을 입증하였다. &amp;#xD; 따라서, label이 지정되지 않은 추가 데이터를 unsupervised 및 supervised 방식으로 활용할 수있는 semi-supervised multitask learning-based 학습 기반 접근 방식을 개발하였다. 구체적으로, 이 과정은 reconstruction에 대해서만 unsupervised 된 상태에서 먼저 학습된 dual-channel adversarial autoencoder를 제안한다. 본 연구는 supervised 방식으로 추가 데이터를 활용하기 위해 auxilary task를 도입하여 multi-task learning framework를 제안한다. 특히, leg side의 식별은 auxilary task로 사용되므로 CHECK 데이터셋과 같은 더 많은 데이터셋을 사용할 수 있게 된다. 따라서, 추가 데이터의 활용이 소수의 label된 데이터만 사용할 수 있는 KL-grade 분류에서 main task의 성능을 향상시킬 수 있음을 보여준다. &amp;#xD; 다양한 측면, 즉 전반적인 성능, label이 지정되지 않은 추가 샘플 및 auxiliary task의 효과, 강인한 분석 등에 대해 공개적으로 사용 가능한 두 개의 가장 큰 데이터셋에 대해 제안된 모델을 평가하였다. 제안된 모델은 각각 75.52%, 78.48%, 75.34%의 Accuracy, Recall, F1-Score를 달성하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0016663213,","Title: Self-Imitation Learning을 이용한 개선된 Deep Q-Network 알고리즘, Abstract: Self-Imitation Learning은 간단한 비활성 정책 actor-critic 알고리즘으로써 에이전트가 과거의 좋은 경험을 활용하여 최적의 정책을 찾을 수 있도록 해준다. 그리고 actor-critic 구조를 갖는 강화학습 알고리즘에 결합되어 다양한 환경들에서 알고리즘의 상당한 개선을 보여주었다. 하지만 Self-Imitation Learning이 강화학습에 큰 도움을 준다고 하더라도 그 적용 분야는 actor-critic architecture를 가지는 강화학습 알고리즘으로 제한되어 있다. 본 논문에서 Self-Imitation Learning의 알고리즘을 가치 기반 강화학습 알고리즘인 DQN에 적용하는 방법을 제안하고, Self-Imitation Learning이 적용된 DQN 알고리즘의 학습을 다양한 환경에서 진행한다. 아울러 그 결과를 기존의 결과와 비교함으로써 Self-Imitation Leaning이 DQN에도 적용될 수 있으며 DQN의 성능을 개선할 수 있음을 보인다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202107554621981,","Title: Deep Metric Learning 기반 원격탐사 변화탐지 기술 연구, Abstract: 원격탐사 영상을 활용하여 변화를 탐지하기 위해 다양한 기술들이 활발히 연구되고 있다. 본 논문에서는 Triplet Loss 기반 Deep Metric Learning 기법을 활용하여 원격탐사 영상에서 변화 탐지를 수행하는 새로운 접근법을 제안하고, 이를 통해 기존 변화 탐지 기술의 한계를 극복하고자 한다. 원격탐사 기술은 도시 개발, 환경 모니터링, 재난 관리 등 다양한 분야에서 핵심적인 역할을 하고 있으며, 특히 시계열 영상 간의 변화를 정확히 탐지하는 기술은 점차 중요성이 높아지고 있다. 그러나 기존의 변화 탐지 기술은 위치 불일치, 조명 변화, 계절적 요인과 같은 외부 환경에 민감하며, 텍스처와 색상 변화를 효과적으로 구분하지 못하는 한계가 존재한다.&amp;#xD; 본 연구에서는 이러한 문제를 해결하기 위해 Deep Metric Learning의 Triplet Loss를 도입하여 변화탐지의 정확도와 신뢰성을 높이는 새로운 방법론을 제시한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0017177484,","Title: 딥러닝 기반의 딥 클러스터링 방법에 대한 분석, Abstract: 클러스터링은 데이터의 정답값(실제값)이 없는 데이터를 기반으로 데이터의 특징벡터의 거리 기반 등으로 군집화를 하는 비지도학습 방법이다. 이 방법은 이미지, 텍스트, 음성 등 다양한 데이터에 대해서 라벨링이 없이 적용할 수 있다는 장점이 있다. 기존 클러스터링을 하기 위해 차원축소 기법을 적용하거나 특정 특징만을 추출하여 군집화하는 방법이 적용되었다. 하지만 딥러닝 기반 모델이 발전하면서 입력 데이터를 잠재 벡터로 표현하는 오토인코더, 생성 적대적 네트워크 등을 통해서 딥 클러스터링의 기술이 연구가 되고 있다. 본 연구에서, 딥러닝 기반의 딥 클러스터링 기법을 제안하였다. 이 방법에서 오토인코더를 이용하여 입력 데이터를 잠재 벡터로 변환하고 이 잠재 벡터를 클러스터 구조에 맞게 벡터 공간을 구성 및 k-평균 클러스터링을 하였다. 실험 환경으로 pytorch 머신러닝 라이브러리를 이용하여 데이터셋으로 MNIST와 Fashion-MNIST을 적용하였다. 모델로는 컨볼루션 신경망 기반인 오토인코더 모델을 사용하였다. 실험결과로 k가 10일 때, MNIST에 대해서 89.42% 정확도를 가졌으며 Fashion-MNIST에 대해서 56.64% 정확도를 가진다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202314857616824,","Title: 딥러닝의 모형과 응용사례, Abstract: 딥러닝은 인공신경망(neural network)이라는 인공지능분야의 모형이 발전된 형태로서, 계층구조로 이루어진 인공신경망의 내부계층(hidden layer)이 여러 단계로 이루어진 구조이다. 딥러닝에서의 주요 모형은 합성곱신경망(convolutional neural network), 순환신경망(recurrent neural network), 그리고 심층신뢰신경망(deep belief network)의 세가지라고 할 수 있다. 그 중에서 현재 흥미로운 연구가 많이 발표되어서 관심이 집중되고 있는 모형은 지도학습(supervised learning)모형인 처음 두 개의 모형이다. 따라서 본 논문에서는 지도학습모형의 가중치를 최적화하는 기본적인 방법인 오류역전파 알고리즘을 살펴본 뒤에 합성곱신경망과 순환신경망의 구조와 응용사례 등을 살펴보고자 한다. 본문에서 다루지 않은 모형인 심층신뢰신경망은 아직까지는 합성곱신경망 이나 순환신경망보다는 상대적으로 주목을 덜 받고 있다. 그러나 심층신뢰신경망은 CNN이나 RNN과는 달리 비지도학습(unsupervised learning)모형이며, 사람이나 동물은 관찰을 통해서 스스로 학습한다는 점에서 궁극적으로는 비지도학습모형이 더 많이 연구되어야 할 주제가 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201620853199880,","Title: 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조 개발, Abstract: 본 논문에서는 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조를 개발한다. 제안하는 복합 미생물 배양기는 수집한 복합 미생물 데이터에 대해 복합 미생물 데이터 전처리, 복합 미생물 데이터 구조 변환, 딥러닝 네트워크 설계, 설계한 딥러닝 네트워크 학습, 시제품에 적용되는 GUI 개발 등으로 구성된다. 복합 미생물 데이터 전처리에서는 미생물 배양에 필요한 당밀, 영양제, 식물엑기스, 소금 등의 양에 대해 원-핫 인코딩을 실시하며, 배양된 결과로 측정된 pH 농도와 미생물의 셀 수에 대해 최대-최소 정규화 방법을 사용하여 데이터를 전처리한다. 복합 미생물 데이터 구조 변환에서는 전처리된 데이터를 물 온도와 미생물의 셀 수를 연결하여 그래프 구조로 변환 후, 인접 행렬과 속성 정보로 나타내어 딥러닝 네트워크의 입력 데이터로 사용한다. 딥러닝 네트워크 설계에서는 그래프 구조에 특화된 그래프 합성곱 네트워크를 설계하여 복합 미생물 데이터를 학습시킨다. 설계한 딥러닝 네트워크는 Cosine 손실함수를 사용하여 학습 시에 발생하는 오차를 최소화하는 방향으로 학습을 진행한다. 시제품에 적용되는 GUI 개발은 사용자가 선택하는 물 온도에 따라 목표하는 pH 농도(3.8 이하) 복합 미생물의 셀 수(108 이상)를 배양시키기 적합한 순으로 나타낸다. 제안된 미생물 배양기의 성능을 평가하기 위하여 공인시험기관에서 실험한 결과는, pH 농도의 경우 평균 3.7로, 복합 미생물의 셀 수는 1.7 &#x00D7; 108으로 측정되었다. 따라서, 본 논문에서 제안한 딥러닝 예측 결과 정보를 적용하는 복합 미생물 배양기를 위한 딥러닝 구조의 효용성이 입증되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202315032964275,","Title: Deep learning for radar, Abstract: Motivated by the recent advances in deep learning, we lay out a vision of how deep learning techniques can be used in radar. Specifically, our discussion focuses on the use of deep learning to advance the state-of-the-art in radar imaging. While deep learning can be directly applied to automatic target recognition (ATR), the relevance of these techniques in other radar problems is not obvious. We argue that deep learning can play a central role in advancing the state-of-the-art in a wide range of radar imaging problems, discuss the challenges associated with applying these methods, and the potential advancements that are expected. We lay out an approach to design a network architecture based on the specific structure of the synthetic aperture radar (SAR) imaging problem that augments learning with traditional SAR modelling. This framework allows for capture of the non-linearity of the SAR forward model. Furthermore, we demonstrate how this process can be used to learn and compensate for trajectory based phase error for the autofocus problem., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12546494,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002574280,","Title: Deep Learning 기반의 폐기물 선별 Vision 시스템 개발, Abstract: Recently, with the development of industry and the improvement of living standards, various wastes are generated along with the production of various products. Most of these wastes are used as containers for products, and plastic or aluminum is used. Various attempts are being made to automate the classification of these wastes due to the high labor cost, but most of them are solved by manpower due to the geometrical shape change due to the nature of the waste. In this study, in order to automate the waste sorting task, Deep Learning technology is applied to a robot system for waste sorting and a vision system for waste sorting to effectively perform sorting tasks according to the shape of waste. As a result of the experiment, a Deep Learning parameter suitable for waste sorting was selected. In addition, through various experiments, it was confirmed that 99% of wastes could be selected in individual & group image learning. It is expected that this will enable automation of the waste sorting operation., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202213659225473,","Title: 학습전략과 심층학습, Abstract: Learning strategies are defined as behaviors and thoughts that a learner engages in during learning and that are intended to influence the learner's encoding process. Today, demands for teaching how to learn increase, because there is a lot of complex material which is delivered to students. But learning strategies shouldn't be identified as tricks of students for achieving high scores in exams. Cognitive researchers and theorists assume that learning strategies are related to two types of learning processing, which are described as 'surface learning' and 'deep learning'. In addition learning strategies are associated with learning motivation. Students with 'meaning orientation' who struggle for deep learning, are intrinsically motivated, whereas students with 'reproduction orientation' or 'achieving orientation' are extrinsically motivated. Therefore, to foster active learning and intrinsic motivation of students, it isn't enough to just teach how to learn. Changes of curriculum and assessment methods, that stimulate deep learning and curiosity of students are needed with educators and learners working cooperatively., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200923354858103,","Title: Deep Learning을 기반으로 한 Feature Extraction 알고리즘의 분석, Abstract: Recently, artificial intelligence related technologies including machine learning are being applied to various fields, and the demand is also increasing. In particular, with the development of AR, VR, and MR technologies related to image processing, the utilization of computer vision based on deep learning has increased. The algorithms for object recognition and detection based on deep learning required for image processing are diversified and advanced. Accordingly, problems that were difficult to solve with the existing methodology were solved more simply and easily by using deep learning. This paper introduces various deep learning-based object recognition and extraction algorithms used to detect and recognize various objects in an image and analyzes the technologies that attract attention., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202020455277386,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Deep Structured Learning: Architectures and Applications, Abstract: Deep learning, a sub-field of machine learning changing the prospects of artificial intelligence (AI) because of its recent advancements and application in various field. Deep learning deals with algorithms inspired by the structure and function of the brain called artificial neural networks. This works reviews basic architecture and recent advancement of deep structured learning. It also describes contemporary applications of deep structured learning and its advantages over the treditional learning in artificial interlligence. This study is useful for the general readers and students who are in the early stage of deep learning studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002428228,","Title: Deep Learning in MR Image Processing, Abstract: Recently, deep learning methods have shown great potential in various tasks that involve handling large amounts of digital data. In the field of MR imaging research, deep learning methods are also rapidly being applied in a wide range of areas to complement or replace traditional model-based methods. Deep learning methods have shown remarkable improvements in several MR image processing areas such as image reconstruction, image quality improvement, parameter mapping, image contrast conversion, and image segmentation. With the current rapid development of deep learning technologies, the importance of the role of deep learning in MR imaging research appears to be growing. In this article, we introduce the basic concepts of deep learning and review recent studies on various MR image processing applications., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002483857,","Title: Deep Learning 기반의 DGA 개발에 대한 연구, Abstract: Recently, there are many companies that use systems based on artificial intelligence. The accuracy of artificial intelligence depends on the amount of learning data and the appropriate algorithm. However, it is not easy to obtain learning data with a large number of entity. Less data set have large generalization errors due to overfitting. In order to minimize this generalization error, this study proposed DGA which can expect relatively high accuracy even though data with a less data set is applied to machine learning based genetic algorithm to deep learning based dropout. The idea of this paper is to determine the active state of the nodes. Using Gradient about loss function, A new fitness function is defined. Proposed Algorithm DGA is supplementing stochastic inconsistency about Dropout. Also DGA solved problem by the complexity of the fitness function and expression range of the model about Genetic Algorithm As a result of experiments using MNIST data proposed algorithm accuracy is 75.3%. Using only Dropout algorithm accuracy is 41.4%. It is shown that DGA is better than using only dropout., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201734651404542,","Title: An overview of deep learning techniques, Abstract: ZusammenfassungDeep Learning ist der Ansatz, der die k&uuml;nstliche Intelligenz innerhalb weniger Jahre tiefgreifend ver&auml;ndert hat. Auch wenn sie durch verschiedene algorithmische Fortschritte begleitet wird, ist diese Technik vor allem aus Anwendungssicht &#x201e;disruptiv“: Sie verschiebt die Grenze automatisierbarer Aufgaben betr&auml;chtlich, ver&auml;ndert die Art der Produktentwicklung und steht praktisch jedermann zur Verf&uuml;gung. Gegenstand des Deep Learning sind neuronale Netze mit einer großen Anzahl von Schichten. Verglichen mit fr&uuml;heren Ans&auml;tzen mit idealerweise einer einzigen Schicht, erlaubt dies den Einsatz massiver Rechenhardware, um Black-Box-Modelle mit einem Minimum an Entwicklungsaufwand direkt aus Rohdaten zu trainieren. Die meisten erfolgreichen Anwendungen finden sich in der Auswertung visueller Bilder, aber auch in der Audio- und Text-Modellierung., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART88488243,","Title: Deep Contour Recovery: Repairing Breaks in Detected Contours using Deep Learning, Abstract: We present a contour recovery framework based on a deep learning model to connect broken contours (breaks) produced by contour detection methods. The idea is that the convolutional neural network iteratively predicts vectors that can grow along the direction of the true contour from the end points of the breaks. For this prediction, we use residual connections training, which models continuous predictions from the previous inference. However, conventional residual connections training is prone to gradually accumulating errors at each inference step. In this work, we propose a ground truth selection algorithm and sub-iteration training to efficiently and reliably train a deep learning model. The ground truth selection extracts a small set of coordinates to represent an actual contour. The sub-iteration training creates the next input that is predicted by additional training of a network replicated from the main network. Our experimental results demonstrate that the ground truth selection creates a ground truth suitable for contour recovery. Moreover, our approach improves the performance of contour detection when applied to the results of existing representative contour detection methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002638568,","Title: Gamification for Education of Deep Learning, Abstract: In this study, we introduced a test platform of gamification, based on Unity-Agents, for education of deep learning. We determined to isolate the internal and external cause of deactivated Korean game-based education in comparison to European and drew requirements for educators, through the opinions of five educators by an open-ended discussion. Using the requirements, we drew design factors for the platform of gamification for education of deep learning. Our design will feature a complete learning based on game play and updated processes of ‘declaration of agents’, ‘process of player brains’, ‘training scenario’, ‘process of heuristic brains’, ‘processes of internal and external brains’, and ‘modifying action, reward, and status’. For the design, the learners could be able to keep up with their abilities and to endorse continued learning. We developed an executable prototype of gamification based on the design. The educators evaluated a learning sample that applied on the prototype and discussed that it was relevant, despite some technical kinks. We appreciated the feedback and our gamification would be modified to allow for their comments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002542238,","Title: Deep Learning in der Augenheilkunde, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94392381,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: Diabetes detection using deep learning algorithms, Abstract: Diabetes is a metabolic disease affecting a multitude of people worldwide. Its incidence rates are increasing alarmingly every year. If untreated, diabetes-related complications in many vital organs of the body may turn fatal. Early detection of diabetes is very important for timely treatment which can stop the disease progressing to such complications. RR-interval signals known as heart rate variability (HRV) signals (derived from electrocardiogram (ECG) signals) can be effectively used for the non-invasive detection of diabetes. This research paper presents a methodology for classification of diabetic and normal HRV signals using deep learning architectures. We employ long short-term memory (LSTM), convolutional neural network (CNN) and its combinations for extracting complex temporal dynamic features of the input HRV data. These features are passed into support vector machine (SVM) for classification. We have obtained the performance improvement of 0.03% and 0.06% in CNN and CNN-LSTM architecture respectively compared to our earlier work without using SVM. The classification system proposed can help the clinicians to diagnose diabetes using ECG signals with a very high accuracy of 95.7%., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002424231,","Title: Deep Learning in Dentistry: A Literature Review, Abstract: The aim of this literature review is to investigate current application and diagnostic performance of AI in the dental field, address their limitations, and suggest possible future applications to AI in dentistry. Studies implementing deep learning in the dental field were searched, identified, and extracted from the electronic databases (PubMed, Cochrane Library, Scopus). Full-text articles describing the application of deep learning for the detection, classification, diagnosis, or clinical outcomes of dental problems as well as the study methods and deep learning architecture were included. The initial electronic search identified 1226 titles, and 115 studies were eventually included in the review.According to the evaluation criteria the studies all involved deep learning methods in dentistry (published 2016-2021), and the studies were divided into their scope of each subfield in dentistry; namely, anatomy (n=26), orthodontics (n=12), oral and maxillofacial surgery (n=29), endodontics and conservative dentistry (n=17), periodontology (n=5), implant dentistry (n=7), prosthodontics (n=3), forensic dentistry and identification (n=8), and etc. (n=8). There was a high risk of bias and applicability concerns were detected for most studies, mainly due to data selection and reference test conduct. Application of deep learning proposed in the studies exhibited wide clinical applications in the dental field. However, the evaluation criteria for the efficacy of deep learning have still not been clarified, and further verification of the reliability and applicability of the AI models is essential to implement these models to clinical practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002967457,","Title: Deep learning, Abstract: Artificial intelligence is one of the most beautiful dreams of mankind. Although computer technology has made considerable progress, so far, there is no computer showing intelligence like human beings. The emergence of deep learning gives people a glimmer of hope. So, what is learning deep? Why is it so important? How does it work? And what are the existing achievements and difficulties? This paper provides an overview of deep learning which will answer these questions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART100567018,","Title: Effective Electricity Demand Prediction via Deep Learning, Abstract: Prediction of electricity demand in homes and buildings can be used to optimize an energy management system by decreasing energy wastage. A time-series prediction system is still a challenging problem in machine learning and deep learning. Our main idea is to compare three methods. For this work, we analyzed an electricity demand prediction system using the current state-of-the-art deep-learning methods with a machine-learning method: error correction with multi-layer perceptron (eMLP) structure, autoregressive integrated moving average (ARIMA) structure, and a proposed structure named CNN-LSTM. For this, we measured and collected electricity demand data in Germany for home appliances. We report the prediction accuracy in terms of the mean square error (MSE) and mean absolute percentage error (MAPE). The experimental result indicates that CNN-LSTM outperforms eMLP and ARIMA in accuracy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002787934,","Title: A Comparison of Deep Reinforcement Learning and Deep learning for Complex Image Analysis, Abstract: The image analysis is an important and predominant task for classifying the different parts of the image. The analysis of complex image analysis like histopathological define a crucial factor in oncology due to its ability to help pathologists for interpretation of images and therefore various feature extraction techniques have been evolved from time to time for such analysis. Although deep reinforcement learning is a new and emerging technique but very less effort has been made to compare the deep learning and deep reinforcement learning for image analysis. The paper highlights how both techniques differ in feature extraction from complex images and discusses the potential pros and cons. The use of Convolution Neural Network (CNN) in image segmentation, detection and diagnosis of tumour, feature extraction is important but there are several challenges that need to be overcome before Deep Learning can be applied to digital pathology. The one being is the availability of sufficient training examples for medical image datasets, feature extraction from whole area of the image, ground truth localized annotations, adversarial effects of input representations and extremely large size of the digital pathological slides (in gigabytes).Even though formulating Histopathological Image Analysis (HIA) as Multi Instance Learning (MIL) problem is a remarkable step where histopathological image is divided into high resolution patches to make predictions for the patch and then combining them for overall slide predictions but it suffers from loss of contextual and spatial information. In such cases the deep reinforcement learning techniques can be used to learn feature from the limited data without losing contextual and spatial information., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202009863559871,","Title: Affective Computing Among Individuals in Deep Learning, Abstract: This paper is a study of deep learning among artificial intelligence technology which has been developing many technologies recently. Especially, I am talking about emotional computing that has been mentioned a lot recently during deep learning. Emotional computing, in other words, is a passive concept that is dominated by people who scientifically analyze human sensibilities and reflect them in product development or system design, and a more active concept that studies how devices and systems understand humans and communicate with people in different modes. This emotional signal extraction, sensitivity, and psychology recognition technology is defined as a technology to process, analyze, and recognize psycho-sensitivity based on micro-small, hyper-sensor technology, and sensitive signals and information that can be sensed by the active movement of the autonomic nervous system caused by human emotional changes in everyday life. Chapter 1 talks about overview and Chapter 2 shows related research. Chapter 3 shows the problems and models of real emotional computing and Chapter 4 shows this paper as a conclusion., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002605687,","Title: Design a personalized recommendation system using deep learning and reinforcement learning, Abstract: As the E-commerce market grows, the importance of personalized recommendation systems is increasing. Existing collaborative filtering and content-based filtering methods have shown a certain level of performance, but they have limitations such as cold start, data sparseness, and lack of long-term pattern learning. In this study, we design a matching system that combines a hybrid recommendation system and hyper-personalization technology and propose an efficient recommendation system. The core of the study is to develop a recommendation model that can improve recommendation accuracy and increase user satisfaction compared to existing systems. The proposed elements are as follows. First, the hybrid-hyper-personalization matching system provides recommendation accuracy compared to existing methods. Second, we propose an optimal product matching model that reflects user context using real-time data. Third, we optimize Personalized Recommendation System using deep learning and reinforcement learning. Fourth, we present a method to objectively evaluate recommendation performance through A/B testing., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003193557,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: Deep Learning and Mathematical Models in Dermatology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART104979282,","Title: Deep Learning Research Trend Analysis using Text Mining, Abstract: Since the third artificial intelligence boom was triggered by deep learning, it has been 10 years. It is time to analyze and discuss the research trends of deep learning for the stable development of AI. In this regard, this study systematically analyzes the trends of research on deep learning over the past 10 years. We collected research literature on deep learning and performed LDA based topic modeling analysis. We analyzed trends by topic over 10 years. We have also identified differences among the major research countries, China, the United States, South Korea, and United Kingdom. The results of this study will provide insights into research direction on deep learning in the future, and provide implications for the stable development strategy of deep learning., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002543007,","Title: A deep-learning-based emergency alert system, Abstract: Emergency alert systems serve as a critical link in the chain of crisis communication, and they are essential to minimize loss during emergencies. Acts of terrorism and violence, chemical spills, amber alerts, nuclear facility problems, weather-related emergencies, flu pandemics, and other emergencies all require those responsible such as government officials, building managers, and university administrators to be able to quickly and reliably distribute emergency information to the public. This paper presents our design of a deep-learning-based emergency warning system. The proposed system is considered suitable for application in existing infrastructure such as closed-circuit television and other monitoring devices. The experimental results show that in most cases, our system immediately detects emergencies such as car accidents and natural disasters., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002284220,","Title: 딥러닝을 이용한 포트홀 검출 시스템, Abstract: The automotive industry is developing day by day. Among them, it is very important to prevent accidents while driving. However, despite the importance of developing automobile industry technology, accidents due to road defects increase every year, especially in the rainy season. To this end, we proposed a road defect detection system for road management by converging deep learning and raspberry pi, which show various possibilities. In this paper, we developed a system that visually displays through a map after analyzing the images captured by the Raspberry Pi and the route GPS. The deep learning model trained for this system achieved 96% accuracy. Through this system, it is expected to manage road defects efficiently at a low cost., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202111861110290,","Title: Application of Deep Learning in Dentistry and Implantology, Abstract: Artificial intelligence and deep learning algorithms are infiltrating various fields of medicine and dentistry. The purpose of the current study was to review literatures applying deep learning algorithms to the dentistry and implantology. Electronic literature search through MEDLINE and IEEE Xplore library database was performed at 2019 October by combining free-text terms and entry terms associated with ‘dentistry’ and ‘deep learning’. The searched literature was screened by title/abstract level and full text level. Following data were extracted from the included studies: information of author, publication year, the aim of the study, architecture of deep learning, input data, output data, and performance of the deep learning algorithm in the study. 340 studies were retrieved from the databases and 62 studies were included in the study. Deep learning algorithms were applied to tooth localization and numbering, detection of dental caries/periodontal disease/periapical disease/oral cancerous lesion, localization of cephalometric landmarks, image quality enhancement, prediction and compensation of deformation error in additive manufacturing of prosthesis. Convolutional neural network was used for periapical radiograph, panoramic radiograph, or computed tomography in most of included studies. Deep learning algorithms are expected to help clinicians diagnose and make decisions by extracting dental data, detecting diseases and abnormal lesions, and improving image quality., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002634341,","Title: Emulearner: Deep Learning Library for Utilizing Emulab, Abstract: Recently, deep learning has been actively studied and applied in various fields even to novel writing and painting in ways we could not imagine before. A key feature is that high-performance computing device, especially CUDA-enabled GPU, supports this trend. Researchers who have difficulty accessing such systems fall behind in this fast-changing trend. In this study, we propose and implement a library called Emulearner that helps users to utilize Emulab with ease. Emulab is a research framework equipped with up to thousands of nodes developed by the University of Utah. To use Emulab nodes for deep learning requires a lot of human interactions, however. To solve this problem, Emulearner completely automates operations from authentication of Emulab log-in, node creation, configuration of deep learning to training. By installing Emulearner with a legitimate Emulab account, users can focus on their research on deep learning without hassle., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201811459663569,","Title: Dance Movement Recognition based on Deep Learning, Abstract: In recent years with continuous development of the computer vision field, there has been an increasing demand for fast and accurate recognition of human movement, especially in sports. This paper researches ballet movements, which are recognized and analyzed using a convolutional neural network (CNN) based on deep learning. Training of the CNN is improved by particle swarm optimization (PSO). Then, 1,000 ballet videos are used as a dataset to compare optimized CNN, traditional CNN, and support vector machine (SVM) methods. The results show that the improved CNN converged fastest, stabilizing after about five iterations, whereas the traditional CNN method took approximately 20 iterations to stabilize. Additionally, after convergence, error in the improved CNN was smaller than from the traditional CNN. The average recognition accuracy of the SVM method was 84.17%, with a recognition time of 3.32 seconds; for the traditional CNN method, it was 90.16% with a recognition time of 2.68 s; and for the improved CNN method, it was 95.66% with a recognition time of only 1.35 s., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003088774,","Title: Enhancing Smart Grid Anomaly Detection Through Deep Learning, Abstract: The modernization of power grids into smart grids introduces numerous benefits, including improved efficiency, reliability, and sustainability. But, the complicated and interconnected nature of smart grid systems also presents challenges, particularly in detecting anomalies and ensuring grid resilience against disruptive events. Traditional anomaly detection methods often struggle to adapt to the dynamic and heterogeneous nature of smart grid data, leading to inefficiencies in identifying and mitigating anomalies. To address these issues, this study proposes a new approach to enhance smart grid anomaly detection and resilience trough deep learning techniques, with a focus on leveraging the TensorFlow framework. The research objective is twofold: firstly, to develop advanced deep learning models capable of accurately detecting anomalies within smart grid data, and secondly, to enhance grid resilience by proactively responding to and mitigating identified anomalies. TensorFlow, a versatile deep learning framework, is chosen as the primary tool for its ability to handle large scale datasets, optimize model performance, and facilitate efficient training of complex neural network architectures. By using the power of deep learning, the developed models exhibit robustness in identifying subtle anomalies and devising proactive strategies to mitigate their impact., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003160214",29,1.1859924140007934,"**제목: 제공된 문서에서 Go 게임과 심층 학습 기술 관련 정보 부재에 대한 보고서**

**서론:**

제공된 다섯 개의 학술 문서는 얼굴 인식, 질적 연구 방법론, 자기결정성 이론, IT 서비스 관리, 게임 중독과 청소년의 자아정체감 및 도덕판단력 등 다양한 주제를 다루고 있습니다.  그러나 Go 게임에 적용된 심층 학습 기술, CNN 레이어 구성, 실험 비교 결과에 대한 정보는 어떤 문서에도 포함되어 있지 않습니다. 따라서 질문에 대한 직접적인 답변은 불가능합니다.

**본론:**

제공된 문서들은 심층 신경망을 활용한 얼굴 인식 기술 향상 연구(문서 1), 질적 연구 방법론의 정의와 양적 연구 방법론과의 차이점에 대한 논의(문서 2), 자기결정성 이론과 교육적 적용(문서 3), 소규모 IT 조직을 위한 ITSM 운영 방안(문서 4), 그리고 게임 중독과 청소년의 자아정체감 및 도덕 판단력의 관계(문서 5)를 다루고 있습니다.  모든 문서에서 Go 게임이나 심층 학습 기술의 구체적인 적용, CNN 레이어 구성, 실험 결과에 대한 언급은 없습니다.  따라서 질문에서 요구하는 Go 게임 관련 심층 학습 기술의 핵심 아이디어, CNN 레이어 구성, 실험 비교 결과를 제시할 수 없습니다.

**결론:**

제공된 문서에는 Go 게임에 적용된 심층 학습 기술에 대한 정보가 포함되어 있지 않습니다.  따라서 질문에 대한 답변은 불가능합니다.  Go 게임과 심층 학습 기술에 대한 정보를 포함하는 추가 자료가 필요합니다.",한정된 데이터베이스에서의 심층 신경망 얼굴인식 성능 향상,질적 연구 방법의 내용과 적용전략: 양적인 질적 연구와질적인 질적 연구,자기결정성이론과 현장 적용 연구,소규모 IT 운영조직을 위한 ITSM 운영방안 연구,게임중독 중학생의 자아정체감과 도덕판단력,게임 데이터의 법적 쟁점,HDPE PIPE를 사용한 해양심층수 취수배관 시공에 관한 연구,붉은덕다리버섯 (Laetiporus sulphureus var. miniatus)과 해양심층수 (deep-sea water)의 항당뇨 및 항비만 활성 연구 : Studies on the anti-diabetic and anti-obesity activities from edible mushroom and deep-sea water,심층혼합처리공법 배치형태에 따른 지반거동해석,"카올린, 아데노신 및 식물복합추출물등이 함유된 안면팩의 피부 개선효과에 관한 인체적용시험 연구",게임 중독 청소년의 특성분석 : 개입의 필요성 판단을 위한 연구,8주간의 해양심층수 섭취와 수영운동의 병행이 흰쥐의 지질대사와 골대사에 미치는 영향,건강신념 모델을 적용한 고혈압 영양교육프로그램 개발 및 효과 평가,게임 엔진을 활용한 입체음향 연구,"게임이용동기와 게임중독 및 몰입, 대학적응의 관계: PC와 모바일의 차이를 중심으로",게임중독 예방프로그램 개선방안,해양심층수 취수를 위한 대구경 GFRP 취수관의 최적 설계,해양심층수 첨가가 요구르트의 품질에 미치는 영향,해양심층수 브랜드가치에 대한 잠재소비자의 특성연구,해안 연약지반의 심층혼합처리공법(DCM) 시공사례 연구,PRECEDE 모형을 적용한 초등학교 안전교육의 진단적 연구,로이의 적응 모델을 적용한 동종 조혈모세포이식 환자의 삶의 질 변화,게임 원작의 영화화에 대한 연구,게임 플랫폼에 따른 이용 동기가 게임 중독에 미치는 영향,게임 욕구조절 프로그램이 인터넷 게임 중독 완화와 자기효능감에 미치는 효과,"자기 통제 훈련 프로그램이 온라인 게임 중독 대학생들의 게임 중독 수준, 공격성 및 충동성에 미치는 효과",연약지반의 심층혼합처리 개량 심도 결정에 관한 연구,"재직근로자의 훈련 참여동기와 훈련만족도, 학업성취도 및 현업적용 예상도의 관계",국제비즈니스계약에 적용되는 법,발전설비에 적용되는 보수용접 조건 및 사례분석,,,,,,,,,,,,,,,,,,,,
How would you concisely summarize the strategic landscape and major industry examples that characterize IT convergence developments in Korea?,"##Strategic Landscape and Key Industry Cases of IT Convergence in Korea## ##Introduction## IT convergence in Korea has emerged as a core driver of national growth, combining information technology with traditional industries to foster new markets and enhance competitiveness. Government initiatives launched since 2008 have provided policy frameworks, R&D support and specialized convergence centers to accelerate cross–sector collaboration and standardization efforts. ##Main Body## Strategically, Korea benchmarks international convergence best practices while selectively focusing resources on promising fields such as u-IT, IT/OT and IT/BT fusion. In consumer electronics, LG and Samsung integrate sensors, network connectivity and multimedia platforms to deliver intelligent home appliances and smart displays. Heavy industry player POSCO employs IT to optimize steel production processes and develop smart factory solutions. The power sector’s Advanced Distribution Management System illustrates IT/OT convergence by merging SCADA, automation and global information-sharing functions for real-time grid control. Defense convergence models leverage commercial IT to improve weapon acquisition, command-and-control and logistics through dedicated defense IT convergence centers and new business-model frameworks. In agriculture and environment, smart-farm projects combine IoT sensors with climate control systems to promote low-carbon green growth, while healthcare and sports services use wearable u-IT devices and big-data analytics to enhance rehabilitation and performance monitoring. ##Conclusion## Korea’s IT convergence landscape is characterized by targeted government support, cross-industry standardization and leading examples in electronics, manufacturing, energy, defense and green industries. Sustained success will depend on ecosystem development, talent cultivation and continuous alignment of policy with emerging technological synergies.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",30,1.1859924140007934,"**Title:**  Analysis of Strategic Landscapes in Korean IT Convergence: A Lack of Relevant Information in Provided Documents

**Introduction:**

This report aims to concisely summarize the strategic landscape and major industry examples characterizing IT convergence developments in Korea, based on the provided academic documents.  However, it is crucial to acknowledge that none of the supplied documents offer information directly relevant to this specific question.  Therefore, this report will address the limitations of the provided context and discuss the generalizable aspects of strategic management and organizational performance applicable to the Korean IT convergence sector.


**Body:**

The provided documents focus on various aspects of strategic management and organizational performance across diverse industries. Document 1 examines the relationship between strategic planning, strategic maneuverability, and firm performance in the Indonesian oil and gas industry. Document 2 investigates the influence of strategic planning and resource-based view on organizational performance, mediated by strategic coordination within a dual-function organization (Pushidrosal) in Indonesia.  Document 3 critiques the existing strategic management literature, arguing for a more practically oriented approach. Document 4 explores the advancement of landscape construction technology through a landscape engineering approach, completely unrelated to IT convergence.  Finally, Document 5 details a method for classifying landscape character in New Zealand, also irrelevant to the question.

While these papers do not contain information about the Korean IT convergence landscape, they offer valuable insights into general strategic principles.  For instance, the importance of strategic planning (Documents 1 & 2) and the need for organizational agility and responsiveness in dynamic environments (Document 1) are universally applicable to any industry, including Korea's rapidly evolving IT sector.  The emphasis on effective resource allocation (Document 2) and the need for a practically relevant strategic management approach (Document 3) are equally important considerations for Korean IT companies navigating the complexities of convergence.


**Conclusion:**

The provided documents lack information directly addressing the strategic landscape and major industry examples of IT convergence developments in Korea.  However, the research presented offers valuable insights into general strategic management principles and organizational performance factors that are universally relevant.  To provide a thorough answer to the original question, additional resources specifically focused on the Korean IT convergence sector are necessary.  Further research using industry reports, case studies, and market analyses would be required to provide a detailed and accurate response.",Strategic Planning and Firm Performance: The Mediating Role of Strategic Maneuverability,The Influence of Strategic Planning and Strategic Resources Base View on the Organization Performance Mediated by Strategic Coordination,Rejuvenating strategic management: the Strategic Option Grid,Advancing Landscape Construction Technology Through a Landscape Engineering Approach,Classifying Landscape Character,25 Years of HOW: A Celebration of Language Teaching and Learning,Future Public Conflicts That Aging Will Bring in Korea: A Comparative Analysis of Korea and Japan,Subtle strategic insights from strategic groups analysis,Strategic networks,"Regionalism in the Asia-Pacific Region: How Wide, How Deep?",How the 'What' Becomes the 'How',BCG vaccine in Korea,Systematic Review Reporting - Writing concisely and precisely,Beyond belief: Strategic taboos and organizational identity in strategic agenda setting,Strategic Thinking and Strategic Planning: Not Yet Habitual in Albania,Role of Strategic Analysis in Strategic Decision-Making,Landscape Urbanism의 이론적 지형과 설계 전략,Landscape Painting in the Research of Landscape Changes,Mainstream economics and economic crises: how responsible? how reformable?,How do we know how?,North Korea as Neighbor: Critical Scholarship on North Korea (in English),"Review toward all RNA structures, concisely",Strategic Leadership in Hybrid Warfare,"Strategic planning, strategic management, strategic foresight: The seminal work of H. Igor Ansoff","Liminality, Seasonality and Landscape",도시경관분석을 위한 경관형용사 목록 작성,Catalysis in Korea,Nursing in Korea,Bivalve mollusks in Ulsan Bay (Korea),Landscape and the holistic research in landscape ecology,Bdelloid rotifers from Korea,재생으로서의 Operational Landscape : 한강대교 보행자 공간을 중심으로,"Cassatella, Claudia; Peano, Attilia (eds.) (2011): Landscape indicators: Assessing and monitoring landscape quality","The Procedural Syllabus and the Task Syllabus: How Similar, How Different?","Echinodermata from Chindo Island, Korea",A Concisely Convergent Synthesis of Berberine Chloride,Landscape Performance and Sustainable Landscape Design - Case Study of Green Infrastructure -,An undergraduate rootkit research project : How available? How hard? How dangerous?,Science in space- How pure - How pragmatic,Review of “North Korea as Neighbor: Critical Scholarship on North Korea (in English)”,Presenting Science Concisely.,LaTeX for Everyone: A Reference Guide and Tutorial for Typesetting Documents Using a Computer.,Solving Concisely Expressed Combinatorial Auction Problems,Presenting Sets of Problem Solutions Concisely,Solving Concisely Expressed Combinatorial Auction Problems,Presenting Sets of Problem Solutions Concisely,Transport aircraft requirements - How much? How soon? How to pay?,HOW TO CHEAT,"Chloroplasts, Concisely",韓國分斷 리스크프리미엄에 관한 硏究 : Korea Discount를 中心으로
Can you provide a brief synthesis of the performance evaluation criteria and standardization framework proposed for u-IT convergence devices?,"##Assessment and Standardization of Performance Criteria for u-IT Convergence Devices## ##Introduction## The rapid evolution of ubiquitous IT technologies has driven the development of convergence devices across communication, broadcasting, portals, content, equipment, and solution domains. To support reliable deployment and market adoption, a structured framework for assessing device performance and ensuring interoperability is essential. ##Main Body## The study first defines u-IT convergence devices and identifies common sensing elements—temperature, pressure, magnetic, optical, gas, and humidity sensors—that underpin their functionality. It then establishes three core evaluation dimensions: technical feasibility (performance and accuracy), economic feasibility (cost and resource efficiency), and management feasibility (maintainability and operational support). Building on these criteria, the research proposes a standardization framework for network-integrated devices, detailing guidelines for certification, interoperability testing, and quality assurance. ##Conclusion## By integrating rigorous performance metrics with a unified standardization approach, this framework fosters consistent certification, enhances device safety and reliability, and lays the groundwork for broader adoption of u-IT convergence systems in a ubiquitous information society.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",31,1.1859924140007934,"**Title:** A Synthesis of Performance Evaluation Criteria from Diverse Research Contexts

**Introduction:**

The provided documents explore various performance evaluation methodologies across different domains.  While none directly address performance evaluation criteria and standardization frameworks for u-IT convergence devices, several papers offer insights into relevant evaluation principles and approaches that can be extrapolated. This report synthesizes these findings to provide a relevant response to the original question.

**Body:**

The documents highlight several key aspects of performance evaluation that are applicable to the broader context of u-IT convergence devices.  Document 2 presents a robust framework for evaluating the reliability and validity of a questionnaire measuring olfactory disorders. This framework, while specific to a medical context, demonstrates a structured approach involving item generation, reliability analysis (internal consistency and test-retest), normative data generation, validity analysis (comparison with other measures), responsiveness analysis, and cut-off value determination.  This rigorous multi-faceted approach could serve as a model for evaluating the performance of u-IT devices, adapting the specific metrics to the functionality and intended use of the devices.

Document 3 analyzes the performance of Indonesian State Owned Enterprises (SOEs) using both managerial and financial performance indicators. This highlights the importance of considering multiple dimensions of performance.  For u-IT convergence devices, a comprehensive evaluation would likely necessitate similar multi-dimensional criteria, potentially including aspects like user experience, energy efficiency, security, interoperability, and functional performance.  The study also underscores the potential discrepancy between different performance measures, emphasizing the need for careful consideration of the chosen metrics and their alignment with the overall goals.

Document 4 focuses on performance prediction in software systems, advocating for the use of parametric performance completions to bridge the gap between high-level models and implementation details.  This model-driven approach underscores the importance of considering various implementation scenarios and usage patterns when evaluating the performance of u-IT devices.  The achieved prediction accuracy (deviation below 10-15%) in the real-world case study highlights the potential of such a model-based approach for predicting and assessing device performance under diverse conditions.

Finally, Document 5 describes the use of audience-response systems (ARS) for evaluating lectures.  While the context is different, the emphasis on immediate feedback and the comparison between different evaluation methods (ARS versus end-of-term online evaluations) can inform the development of a standardized framework for u-IT devices.  The use of ARS could be adapted for real-time performance monitoring and feedback collection from users, supplementing more traditional performance testing approaches.  The significance of incorporating user feedback is implicit in the reported high correlations between various ARS assessment parameters (prior knowledge, presentation, relevance).

Document 1, focusing on organizational evaluation, advocates for a process-based, negotiated, and generative approach, emphasizing context-dependency and the collaborative production of knowledge. This highlights the importance of considering the specific context of use and involving stakeholders in the evaluation process.  For u-IT convergence devices, this suggests a need for flexible and adaptable evaluation frameworks, and a collaborative effort involving developers, users, and other relevant stakeholders.


**Conclusion:**

While the provided documents do not offer a specific, standardized framework for evaluating u-IT convergence devices, they collectively illustrate essential components of a robust evaluation methodology.  Such a framework would need to be multi-dimensional, incorporating metrics reflecting functional performance, user experience, security, energy efficiency, and interoperability.  A model-driven approach could enhance prediction capabilities.  A rigorous, iterative process, incorporating user feedback and context-specific considerations, is crucial for ensuring the validity and relevance of the evaluation.  The examples provided suggest a combination of quantitative and qualitative measures, potentially leveraging technologies like ARS for real-time feedback, alongside more traditional performance benchmarks.",The practice of evaluation as an evaluation of practices,Italian version of the Brief Questionnaire of Olfactory Disorders (Brief-IT-QOD),"Performance of Indonesian State Owned Enterprises, Managerial Performance vs. Financial Performance",Parametric performance completions for model-driven performance prediction,Audience-response systems for evaluation of pediatric lectures &#x2013; comparison with a classic end-of-term online-based evaluation,Unraveling Anabolic Resistance in Sarcopenia: A Narrative Synthesis of Age-Related Impairments in Muscle Protein Synthesis,Broadening the Educational Evaluation Lens With Communicative Evaluation,Brief guide to immunostaining,Cognitive Behavioral Therapy (Brief vs Standard Duration) for Schizophrenia,Thermal Plasma Synthesis of Ceramic Nanomaterials,Mod&egrave;les math&eacute;matiques et physiologiques de la performance humaine,“We are Performance Philosophy Problems” : Towards an accessible Performance Philosophy?,Empowerment Evaluation as Evaluation Ideology,Evaluation policy and evaluation practice,Evaluation,3차원 인체측정을 위한 측정용 브리프에 관한 연구,Adequate reporting of seolite synthesis in the literature,Synthesis of Silicon Nanocrystals,Microfluidic asymmetrical synthesis and chiral analysis,Synthesis of alkyl quercetin derivatives,Interaction art using Video Synthesis Technology,Synthesis of Methiocarb,Photochemical Synthesis of Naked Palladium Nanoparticles,High Performance Fortran : Language Specification (PART II),High performance Fortran language specification (part III),Influence des limites du cycle &#x00E0; adsorption sur la performance du syst&#x00E8;me,Understanding Performance Improvement,Evaluation of Mass Casualty Incident Exercises (MCI),The Use of Multiple Evaluation Approaches in Program Evaluation,Lecture Performance Festival,Brief contents,Brief contents,Brief contents,Brief contents,TCP/IP 상에서 CAN 데이터 프레임 송수신이 가능한 가상 CAN 버스 소프트웨어의 구현,Non-Random CAN Fuzzing을 통한 효율적인 ECU 분석 기술,FPGA 기반 CAN Spoofing 공격 탐방지 장치,객체인식을 위한 FAST와 BRIEF 알고리즘 기반 FPGA 설계,Sonochemical Synthesis에 의한 리튬이차전지용 LiCoO_(2) 나노 정극 분말 합성연구,After Performance : On transauthorship,Evaluation of Evaluation '85,Organization for Program Evaluation in Colorado,CAN 통신을 이용한 차량 상태 모니터링 시스템 개발,"CAN, CAN FD, FlexRay를 이용한 자동차용 진단시스템에 관한 연구",FreeRTOS상에서의 CAN통신 보안 설계,CAN Protocol을 이용한 CAN 통신 시스템 설계 및 구현,키워드 검색 지원을 위한 확장 CAN 메커니즘,CAN 네트워크에서의 Starvation Free 프로토콜,차량용 CAN-FD 제어기의 구현 및 검증,한국어판 Brief cognitive rating scale의 타당도
How would you distill the key design elements and convergence concepts of an IT/OT-based advanced distribution management system?,"##Title## Design Elements and Convergence Principles of an IT/OT-Based Advanced Distribution Management System ##Introduction## Power distribution networks have evolved beyond basic SCADA and automation to embrace Advanced Distribution Management Systems (ADMS) that fuse operational technology (OT) with information technology (IT). This convergence blurs traditional boundaries, promoting interoperability, real-time data exchange and enhanced decision-making across the grid. ##Main Body## Key design elements center on a multi-layered architecture that integrates distribution SCADA for remote monitoring, distribution automation for service restoration and a suite of management applications to optimize performance. Interoperability standards and a data-centric middleware layer ensure seamless communication among sensors, actuators, control centers and enterprise systems. The IT/OT convergence concept drives the joint deployment of ICT capabilities—such as data analytics, enterprise integration and cybersecurity—with OT functions like fault detection, remote control and load management. System configurations typically include distributed field devices connected through resilient, secure communication channels, scalable computing resources for analytics, and modular applications for network modeling, outage management and voltage optimization. ##Conclusion## By tightly integrating IT and OT layers, a converged ADMS delivers real-time visibility, operational agility and higher distribution efficiency. This holistic design approach lays the foundation for smarter, more resilient and adaptive power grids.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",32,1.1859924140007934,"**Title:** Key Design Elements and Convergence Concepts in an IT/OT-Based Advanced Distribution Management System

**Introduction:**

This report addresses the key design elements and convergence concepts of an IT/OT (Information Technology/Operational Technology)-based advanced distribution management system (ADMS).  While the provided documents do not directly address ADMS, they offer insights into relevant concepts such as modularity, dynamic resource allocation, and the importance of holistic design processes, which are crucial for building such a system.

**Body:**

An effective IT/OT-based ADMS requires a sophisticated integration of information and operational technologies to manage and optimize distribution networks.  Several key design elements emerge from the provided texts:

* **Modularity:** Document 1 describes a modular impulsive green monopropellant propulsion system (MIMPS-G).  This highlights the importance of modularity in complex systems. An ADMS should similarly be designed with modular components to allow for easier maintenance, upgrades, and scalability. This modularity allows for flexibility in adapting to changing operational demands and technological advancements.

* **Dynamic Resource Allocation:** Document 2 discusses the challenges of dynamic resource allocation in pervasive computing environments. An ADMS must effectively manage and allocate resources (e.g., power, communication bandwidth, computational capacity) dynamically to respond to changing network conditions and optimize system performance. This necessitates an architecture that supports opportunistic resource utilization, similar to the service-oriented network sockets (SoNS) and light-weight adaptive network sockets (LANS) described in Document 2.

* **Holistic Design Process:**  Document 4 emphasizes a holistic design process for experiential design.  This concept is highly applicable to ADMS development. The system's design should consider all aspects, including the IT infrastructure, OT components, user interfaces, data analytics, and operational procedures, ensuring seamless integration and optimal functionality. This includes understanding cognitive interactions in the design process and utilizing different thinking modes and sensory modalities to better anticipate user needs and operational challenges.

* **Multidisciplinary Design Optimization:** Document 5 advocates for multidisciplinary design optimization in additive manufacturing. This principle is equally relevant to ADMS.  The system's design should involve experts from various disciplines (IT, OT, power systems engineering, data science, etc.) to ensure that all aspects are effectively optimized and potential conflicts or inefficiencies are addressed during the design phase, rather than later in the implementation or operational stages.  Utilizing concurrent optimization methods and surrogate modeling can significantly improve the efficiency and effectiveness of the design process.

* **Causal Reasoning and ITBV Creation:**  Document 3 underscores the significance of causal reasoning in creating information technology business value (ITBV).  An ADMS should be designed with a clear understanding of the cause-and-effect relationships between system components, operational parameters, and business outcomes.  This understanding helps to ensure that the system delivers the intended value and contributes to achieving organizational objectives.  The development of dynamic models rather than static ones is crucial for capturing the complex interactions within the system.


**Convergence Concepts:**

The convergence of IT and OT is central to the functionality of an ADMS. The system requires a seamless integration of these two realms, using IT for data acquisition, analysis, and control, and OT for real-time interaction with physical assets. This convergence is essential for enabling advanced functionalities, such as real-time monitoring, predictive maintenance, and demand-side management.  The successful convergence demands careful consideration of security, interoperability, and data standards, ensuring reliable and secure communication between IT and OT components.


**Conclusion:**

The design of an effective IT/OT-based ADMS requires a holistic approach, incorporating modularity, dynamic resource allocation, and multidisciplinary design optimization principles. A clear understanding of the causal relationships between system components and business outcomes is crucial for realizing the intended value. The successful convergence of IT and OT systems is essential for achieving the advanced functionality and operational efficiency inherent in a modern ADMS.  The principles highlighted in the provided documents, though not explicitly focused on ADMS, offer valuable insights into crucial design elements and convergence concepts applicable to this complex system.",Modular Impulsive Green Monopropellant Propulsion System (MIMPS-G): For CubeSats in LEO and to the Moon,How the 'What' Becomes the 'How',Causality in information technology business value: a review,Evolving a Holistic Design Process of Experiential Design - Focus on the Cognitive Interaction in Design Process -,Multidisciplinary design optimization in design for additive manufacturing,"Major and trace elements pollution of sediments associated with Abandoned Barite Mines in parts of Oban Massif and Mamfe Embayment, SE Nigeria",A nonfullerene acceptor incorporating a dithienopyran fused backbone for organic solar cells with efficiency over 14%,Quantitative detection of the molecular changes associated with early cataractogenesis in the living human lens using quasielastic light scattering,Seasonal fitness parameters and selection indices in the natural population of Drosophila melanogaster Meig.,Structural Design of Zymolysis Building of Institute of Microbe Research,CAAD Design Methodology for New Media Design Environment,Generating regular elements,Determination of Total Flavones and Elements in Mosla soochowensis Matsuala,Elements and Opposites in Heraclitus,Determination and Analysis on Elements in Chinese Walnut Shell,SUBSERIES CONVERGENCE AND SEQUENCE-EVALUATION CONVERGENCE,"Does convergence cause trade, or does trade cause convergence?",CONVERGENCE OF C-SEMIGROUPS,Convergence Accommodation to Convergence CA/C Ratio: Convergence Versus Divergence,Mainstream economics and economic crises: how responsible? how reformable?,25 Years of HOW: A Celebration of Language Teaching and Learning,How do we know how?,"Regionalism in the Asia-Pacific Region: How Wide, How Deep?",Impact of Ir-Valence Control and Surface Nanostructure on Oxygen Evolution Reaction over a Highly Efficient Ir-TiO<sub>2</sub> Nanorod Catalyst,Design and science,Architecture and Design of Mental Health Institutions,Drosophila melanogaster 한국 집단내 hobo elements의 분포,"Special clean elements, perspective elements and perspective rings",Conversion Coefficients for Superheavy Elements,Measuring Economic Convergence,CONVERGENCE OF INTEGRABLE SEMIGROUPS,REGULAR CONVERGENCE SPACES,The convergence and partial convergence of alternating series,"The Procedural Syllabus and the Task Syllabus: How Similar, How Different?",An improved third order theory and assessment of efficient zigzag theory for angle-ply flat hybrid panels,Internal tide oceanic tomography,The Effect of Different Surfactants and Polyelectrolytes on Nano-Vesiculation of Artificial and Cellular Membranes,Computer Elements,WEAKLY CANCELLATIVE ELEMENTS IN SEMIGROUPS,CONVERGENCE OF REGULARIZED SEMIGROUPS,한국재래돼지의 육질 연관 DNA marker 규명 및 Primer Design에 관한 연구,Topological convergence and uniform convergence,Transport aircraft requirements - How much? How soon? How to pay?,An undergraduate rootkit research project : How available? How hard? How dangerous?,매스커스터마이제이션을 위한 소비자 참여 디자인 방법(인터랙티브 디자인 툴킷의 개발을 중심으로),HOW TO CHEAT,Science in space- How pure - How pragmatic,모던 디자인 (Modern Design)의 디자인 사고에 대한 연구,디자인사고(Design Thinking)기반 프로세스를 통한 디자인교육 연구 - 스마트폰 어플리케이션 디자인수업을 중심으로 -,Elements de bibliographie.
Could you outline the principal concerns IT companies face in defense-related IT convergence and the proposed solutions for cost estimation and governance?,"##Key Challenges and Solutions in Defense IT Convergence## ##Introduction## Defense-related IT convergence involves integrating commercial information technologies into military acquisition and operations. While this integration promises enhanced capability and efficiency, IT firms encounter unique hurdles when entering defense projects due to stringent requirements and complex procurement structures. ##Main Body## 1. Role Clarification: IT companies often face ambiguity over their responsibilities in defense programs, stemming from traditional procurement models that favor established defense contractors. Clear definition of tasks, deliverables, and accountability is proposed via standardized role descriptions and contractual frameworks tailored to IT services. 2. Governance and Control Tower: The absence of a centralized oversight entity leads to fragmented decision-making and delayed approvals. Establishing a dedicated defense IT convergence “control tower” can unify stakeholders, streamline processes, and monitor progress through joint military–industry governance boards. 3. Software Cost Estimation: Conventional cost models are ill-suited for software-intensive projects, resulting in budget overruns and disputes. Adopting recognized estimation methodologies—such as COCOMO II or function-point analysis—alongside modular development contracts can yield more realistic forecasts and cost transparency. ##Conclusion## Addressing these concerns through explicit role definitions, a centralized governance structure, and robust software cost-estimation practices enables smoother collaboration between IT firms and defense organizations, ultimately reducing risk and improving project outcomes.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",33,1.1859924140007934,"**Title:**  Challenges and Solutions in Cost Estimation and Governance for IT Companies in Defense-Related IT Convergence

**Introduction:**

This report addresses the principal concerns IT companies face in defense-related IT convergence, focusing specifically on cost estimation and governance.  The provided documents do not directly address this specific niche, therefore, a response will be constructed by applying principles and challenges extrapolated from the provided research to the specified context.

**Body:**

The provided research highlights several challenges relevant to the question.  Document 1, focusing on greenhouse gas emission management in large European companies, illustrates the difficulties in managing complex systems with numerous interdependent factors (""uncertainties in climate change policy are the key barrier"").  This analogy applies to defense-related IT convergence, where the complexity of systems, stringent regulations, and evolving technological landscapes pose significant challenges to accurate cost estimation.  Unforeseen technological advancements or regulatory changes can lead to significant cost overruns.


Document 2 examines the impact of COVID-19 on Moroccan listed companies. The findings highlight the importance of financial resilience – specifically high sales, low debt, high liquidity, and financial autonomy – in mitigating negative impacts.  For IT companies in defense-related projects, maintaining financial resilience is crucial to absorbing unexpected costs or delays.  A robust financial model that accounts for potential risks and incorporates contingency planning is essential for effective cost estimation and governance.


Document 3 discusses security and privacy concerns in the metaverse. While not directly related to cost, it underscores the importance of risk assessment and mitigation in complex technological environments.  Defense-related IT convergence projects often involve sensitive data and require stringent security measures.  These security requirements significantly impact cost estimations and necessitate robust governance structures to ensure compliance and accountability.


Document 4 describes a new approach to Principal Component Analysis (PCA) for large data sets. This highlights the increasing need for efficient data management and analytical techniques in dealing with the vast amount of data inherent in defense-related IT convergence projects. Effective cost estimation requires thorough data analysis to identify potential cost drivers and optimize resource allocation.


Document 5 analyzes the shift in Korean college students' learning styles. While seemingly unrelated, this study highlights the importance of adaptability and responsiveness to change.  In the rapidly evolving field of defense-related IT, companies must be able to adapt their cost estimations and governance structures to accommodate new technologies and changing project requirements.


Therefore, principal concerns for IT companies in defense-related IT convergence regarding cost estimation and governance include:  the inherent complexity of systems leading to unpredictable costs; the need for robust financial resilience to absorb unexpected shocks; stringent security and compliance requirements impacting both cost and governance; and the necessity for efficient data management and analytical techniques to inform accurate cost projections.  Solutions include developing comprehensive, risk-based cost models; establishing rigorous financial controls and contingency plans; implementing stringent security protocols and compliance frameworks; and employing advanced data analytics for optimal resource allocation and risk mitigation.


**Conclusion:**

IT companies involved in defense-related IT convergence face significant challenges in cost estimation and governance due to project complexity, regulatory constraints, security concerns, and the need for adaptive strategies.  Effective solutions require a multi-faceted approach encompassing detailed risk-based cost modeling, robust financial planning, stringent security protocols, and the utilization of advanced data analytics.  A strong emphasis on financial resilience and adaptable governance structures is critical for success in this demanding environment.",The management of greenhouse gas emissions in large European companies,Impact of Covid-19 on companies’ performance and financial resilience: Evidence from Moroccan listed companies,Metaverse: Security and Privacy Concerns,Segmented principal component transform&ndash;principal component analysis,Analyzing the Shift of Korean College Students’ Learning Styles and Strategies in Non-Face-to-Face and Face-to-Face Environments,Could DCT Reveal Photorealistic Images?,3D Face Modeling using Face Image,Could Arthroscopes be Better?,Zebrafish toxicological screening could aid Leishmaniosis drug discovery,Principal Component Regression by Principal Component Selection,Employment and companies,"The effect of trunk stabilization exercise according to face-to-face, non-face-to-face, and self-exercise on balance ability",What Could I have Done Differently?,Spinal Cord Injury: How Could Acupuncture Help?,How Algeria Could Survive the Arab Spring? Governance Perspective,Principal stratification analysis using principal scores,Natural principal connections on the principal gauge prolongation of a principal bundle,Principal Effectiveness and Principal Turnover,Maternal concerns during early parenthood,An investigation of preservice elementary teachers' concerns on teaching music using Fuller and Bown's teacher concerns model,Summarizing software concerns,Determining Patient Concerns Before Joint Arthroplasty,Employment and companies,The Consequences of the Economic Crisis on Small Companies from Romania,Impact of takeovers on profitability of target companies: Evidence from Croatian companies,Effectiveness of Telephone and Face-to-Face Aftercare Conversations following Inpatient Psychosomatic Rehabilitation,Impact of face proportions on face attractiveness,Korean ESL Refusals in Face-to-Face Interaction,A Comparative Study on psychological state the face-to face and Non face-to-face Teaching Experience of Nursing student due to COVID-19,Radically Principal Ideal Rings,The Principal Principle and Posterior Credences,Nutritional concerns in pediatric inflammatory bowel disease,On the Mortality of Companies,Valuing insurance companies,The Effect of Types of College Entrance Examination on Academic Achievement of General Chemistry in Face-to-face and Non-face-to-face Teaching-Learning,All change at Companies House,Are financial holding companies' subsidiaries riskier than bank holding companies’ affiliates?,Principal component analysis를 이용한 LSP 계수의 압축기법,The Reflective Principal From Newbie to Veteran Principal,Could all laboratory animal use could be ended by the year 2020?,Could Alice equalize student learning?,Principal element lattices,Concerns about raising concerns,What motor cars could be,What Motor Cars Could Be,"Work concerns, family concerns.",Health Concerns,Current concerns are past concerns.,인지 문법을 통한 face의 의미 분석,Tunnel Mapper를 이용한 Tunnel 막장면 조사에 관한 연구
How can you succinctly capture the factors that shape consumer purchase attitudes toward IT-based convergence products and their implications for competitiveness?,"##Title## Factors Influencing Consumer Attitudes toward IT‐Based Convergence Products and Their Competitive Implications ##Introduction## This study examines how consumers’ perceived attitudes toward IT‐based convergence products shape their purchase decisions and explores the strategic implications for firms seeking to strengthen competitiveness in this emerging market. ##Main Body## Grounded in established decision‐making theories, the research formulates and empirically tests hypotheses about key attitude drivers. Perceived usefulness stands out as the dominant factor: when consumers believe that a convergence product offers clear functional benefits and enhances their tasks, they are far more likely to adopt it. Other elements—such as ease of use, technological novelty, and alignment with lifestyle needs—also contribute but to a lesser extent. By measuring these perceptions through surveys and statistical analyses, the study identifies which product attributes most influence consumer attitudes. Armed with these insights, companies can prioritize feature development, tailor communication strategies, and refine pricing models to highlight utility and differentiate offerings. ##Conclusion## Focusing on the utility dimension of convergence products enables firms to cultivate favorable consumer attitudes, paving the way for successful market entry and sustained competitive advantage.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",34,1.1859924140007934,"**Title:** Shaping Consumer Purchase Attitudes Toward IT-Based Convergence Products: Factors and Competitive Implications

**Introduction:**

This report analyzes the factors influencing consumer purchase attitudes toward IT-based convergence products and their implications for competitiveness.  The analysis draws exclusively upon the provided research papers, focusing on relevant aspects of data summarization, consumer behavior modeling, and the impact of technological architectures.

**Body:**

Understanding consumer attitudes toward IT-based convergence products requires a multi-faceted approach.  While none of the provided papers directly addresses consumer attitudes toward convergence products, several offer insights into related areas that contribute to a comprehensive understanding.

First, the efficient summarization of data, as described in Document 1 (""Summarizing data succinctly with the most informative itemsets""), is crucial for understanding consumer preferences.  The methodology described, using a probabilistic maximum entropy model, allows for the identification of the most informative itemsets—key features that significantly influence consumer choices.  Applying this approach to consumer data on convergence products would reveal the most impactful attributes driving purchase decisions.  This would allow companies to prioritize features that resonate most with consumers, maximizing their competitive advantage.

Document 4 (""The Effect of Cloud-based IT Architecture on IT Exploration and Exploitation: Enabling Role of Modularity and Virtuality"") highlights the role of IT architecture in shaping consumer experiences.  The study shows that modularity in cloud-based IT systems positively impacts both exploration (discovery of new features) and exploitation (utilization of existing features).  For convergence products, a modular design allows for flexible customization and adaptability, enhancing consumer satisfaction and influencing purchase decisions positively.  This, in turn, enhances a company's competitiveness through superior user experience.

Document 3 (""Sustainability Factors for PSS Business Models"") emphasizes the increasing importance of sustainable business models.  While focused on Product-Service Systems (PSS), the principles of sustainability—economic, environmental, and social—are equally relevant to the IT sector.  Consumers are increasingly considering the sustainability of their purchases, impacting their choices towards convergence products.  Companies that incorporate sustainable practices throughout their product lifecycle, including design, manufacturing, and disposal, will gain a competitive advantage by appealing to environmentally conscious consumers.


Document 2 (""Jungian Arts-Based Research: What it is, Why do it, and How"") indirectly contributes to understanding consumer behavior by suggesting that the unconscious mind influences choices.  While not directly applicable to IT product purchasing, the concept of archetypes and the ""deep psyche"" can be interpreted metaphorically to represent deeply ingrained consumer preferences. Understanding these underlying preferences through market research could allow companies to better target their marketing and product development efforts.  This aligns with the data summarization techniques discussed in Document 1, focusing on uncovering the underlying patterns that dictate consumer behavior.

Finally, Document 5 (""25 Years of HOW: A Celebration of Language Teaching and Learning"") highlights the importance of understanding the ""dynamic nature of context and meaning"" in the learning process.  This principle extends to the consumer context, indicating that consumer attitudes are not static but are shaped by various environmental factors and individual experiences. Companies must be adaptable to changes in consumer preferences and technological advancements, continuously refining their product offerings to maintain competitiveness.

**Conclusion:**

In summary, shaping consumer purchase attitudes toward IT-based convergence products necessitates a comprehensive understanding of several key factors.  Efficient data summarization techniques allow for the identification of key features influencing consumer choices.  Modular IT architectures enhance user experience and adaptability.  Sustainable business models appeal to environmentally conscious consumers.  And finally, understanding the dynamic nature of consumer preferences necessitates continuous adaptation and innovation. By addressing these aspects, companies can improve their competitiveness in the evolving market of IT-based convergence products.",Summarizing data succinctly with the most informative itemsets,"Jungian Arts-Based Research:What it is, Why do it, and How",Sustainability Factors for PSS Business Models,The Effect of Cloud-based IT Architecture on IT Exploration and Exploitation: Enabling Role of Modularity and Virtuality,25 Years of HOW: A Celebration of Language Teaching and Learning,The Factors affecting employee satisfaction:,Mainstream economics and economic crises: how responsible? how reformable?,Activity-based justification of IT investments,Invariant Generation through Strategy Iteration in Succinctly Represented Control Flow Graphs,Designing Human Factors Courses with a Human Factors Mind,Socio-demographic Factors of Geriatric Depression,How do we know how?,How the 'What' Becomes the 'How',Super-Solutions : Succinctly Representing Solutions in Abductive Annotated Probabilistic Temporal Logic,英語 That節에 관한 硏究,영한 번역에서 나타나는 지시어 This/That 차이 연구,Lives of That and That-Clauses: A Lexicalist Approach,초록에서 보이는 평가적 that에 관한 코퍼스 연구,"Vacuous It-Extraposition: A Lexicalist, Construction-based Approach",An ERP Operation Audit Model Based on IT Infrastructure Library,Component Transformations - Eigenvalue Analysis Succinctly Defines Their Relationships,Factors Influencing the Consumption of Calcium-Rich Foods among Adolescents,Numerical Analysis of Stress Concentration Factors,영어의 that-trace 효과에 관한 연구,관계절 보문자 that의 범주 연구,"Regionalism in the Asia-Pacific Region: How Wide, How Deep?",Achieving IT&#x2010;based synergies through regulation&#x2010;oriented and consensus&#x2010;oriented IT governance capabilities,INFERTILITY FACTORS AND THEIR DIAGNOSIS :,"The Procedural Syllabus and the Task Syllabus: How Similar, How Different?",NK cell-based immunotherapy for treating cancer: will it be promising?,Constraint satisfaction with succinctly specified relations,Editorial: Synthesizing current research succinctly and elegantly,Human Factors,Performance-Based Accountability: What Has It Brought to American Education?,Writing Clearly and Succinctly,The Complexity of Searching Succinctly Represented Graphs,Transport aircraft requirements - How much? How soon? How to pay?,An undergraduate rootkit research project : How available? How hard? How dangerous?,HOW TO CHEAT,Science in space- How pure - How pragmatic,Succinctly Shire,A Comparison of Succinctly Represented Finite-State Systems,의료기기 usability engineering과 human factors engineering 방식 비교 분석,Human Factors,영어의 THAT에 대한 통시적 연구 : 관계대명사인가 접속사인가,that 관계절의 통사구조와 의미,영어 보문자 that에 관한 연구,WH-운용자로서의 관계사 That,Problem-based learning : is it worth it?,"Photo-Based User Interfaces: Picture It, Tag It, Use It"
한국 IT융합 신산업 역량강화요인과 이를 도출하기 위한 연구 결과를 간결하게 요약해 주시겠습니까?,"##제목## IT융합 신산업 역량 강화 요인 도출 연구 개요 ##서론## IT는 한국 경제성장과 사회 전반의 혁신을 이끌며 생산성·효율성·편의성을 크게 향상시켜 왔고, 타 산업과의 융합을 통해 새로운 성장 동력으로 부상하였다. 이러한 맥락에서 IT융합 신산업의 경쟁력 강화를 위해 핵심 역량 요인을 과학적으로 도출하는 것이 중요하다. ##본론## 이 연구는 2011년 정책연구에서 학계 및 공공기관 전문가를 대상으로 델파이 기법을 활용하여 IT융합 역량 요소를 도출하고, 이를 기존 선행연구 결과와 비교·분석하여 역량 수준 변화를 평가하였다. 분석 과정에서 전략적 자원 집중, 산·학·연 협력 확대, 표준화 추진, 전문 인력 양성, 정책 지원 체계 구축 등이 핵심 강화 요인으로 식별되었다. 각 요인은 신산업 창출과 지속적 성장에 필요한 기반으로 평가되었으며, 국내외 주요국의 융합 전략과 비교해 볼 때 한국의 강·약점을 객관적으로 파악할 수 있었다. ##결론## 본 연구는 델파이 결과와 비교 분석을 통해 IT융합 신산업 역량 강화의 구체적 방향을 제시하며, 향후 정책 수립과 산업 전략 마련 시 실질적 가이드라인으로 활용될 수 있다.",Can you concernly summarize the factors of strengthening the new IT convergence and the results of the research to derive it?,"##title## IT convergence new industrial capacity strengthening factor derivation research ##introduction## IT has greatly improved productivity, efficiency, and convenience by leading Korea's economic growth and innovation throughout society, and has emerged as a new growth engine through fusion with other industries. In this context, it is important to scientifically derive core competency factors to strengthen the competitiveness of IT convergence new industries. ## Main ## In the 2011 policy study, IT convergence capacity elements were used to use Delphi techniques for academic and public institution experts, and compared with the results of the previous studies. In the analysis process, strategic resources focused, expansion of industry, academia and research cooperation, standardization promotion, fostering professional manpower, and establishing a policy support system were identified as core factors. Each factor was evaluated as the basis for the creation of new industries and continuous growth, and compared to the convergence strategy of major domestic and foreign countries, Korea's strong and weaknesses were objectively identified. ##conclusion## This study suggests a specific direction of strengthening IT convergence new industries by comparative analysis and comparative analysis, and can be used as a practical guideline for future policy establishment and industrial strategy.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",35,1.1859924140007934,"**제목: 한국 IT 융합 신산업 역량 강화 요인 분석:  문헌 고찰을 통한 탐색**

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 한국 IT 융합 신산업의 역량 강화 요인을 분석하고, 이를 도출하기 위한 연구 결과를 간결하게 요약합니다.  제공된 문서들은 한국 및 다른 국가의 산업 정책, 디자인 교육, 습지 연구, FTA 효과 등 다양한 분야를 다루고 있으므로, IT 융합 신산업에 직접적으로 관련된 정보는 제한적입니다. 따라서 본 보고서는 관련성이 있는 정보를 추론하고,  간접적인 시사점을 도출하여 답변을 구성합니다.


**본론:**

제공된 문서 중 IT 융합 신산업 역량 강화와 가장 관련성이 높은 것은 문서 2, ""융합 이후의 융합: 융합 추구의 한국디자인교육 5년에 관한 분석과 고찰"" 입니다.  이 연구는 2009년부터 2014년까지 진행된 ""Convergence Design College Development Project""를 사회학적 관점에서 분석했습니다.  이 프로젝트의 경험과 관찰을 바탕으로 융합 디자인 교육의 미래 계획을 수립하는 것을 목표로 하였습니다.  이는 IT 융합 신산업에 필요한 인재 양성과 관련된 중요한 시사점을 제공합니다.  즉,  융합 디자인 교육의 성공적인 추진을 위해서는  ""융합의 필요성과 방법""에 대한 인식론적, 문화적 이해에 대한 객관적인 분석이 필요하며, 교육 목표와 주제에 대한 이해뿐 아니라, 교육 아이디어의 토대와 그 실현 가능성에 대한 현실적 조건을 파악하는 과정이 중요하다고 연구는 지적합니다.  이러한 과정을 통해 내부적 이해를 충분히 확보하여 외부와의 적극적인 융합을 가능하게 할 수 있다는 것입니다.  IT 융합 신산업 역량 강화를 위해서는 이러한 융합적인 사고와 교육 시스템이 필수적이며,  '외부'와의 융합 (산업계, 다른 학문 분야 등)을 위한 내부적 준비가 중요함을 시사합니다.

문서 5, ""우리나라 가구제조 기업의 글로벌전략에 관한 연구""는 한국 기업의 글로벌 전략 수립에 대한 분석을 제공합니다.  비록 IT 융합 산업과 직접적으로 관련된 내용은 아니지만, 글로벌 경쟁 환경에서의 생존 전략으로서 전략적 제휴, 표준화 전략, 현지화 전략, 틈새시장 공략,  고부가가치 제품 개발 등의 요소가  IT 융합 신산업에도 적용 가능한 중요한 시사점을 제공합니다.  특히,  기술 혁신의 가속화와 국제적 경쟁 심화 속에서  핵심 역량을 기반으로 한 전략적 제휴 및  고부가가치 제품 개발을 통한 경쟁력 확보가 중요함을 보여줍니다.  IT 융합 신산업 또한 이러한 전략을 통해 글로벌 경쟁력을 강화할 수 있습니다.


**결론:**

제공된 문서를 바탕으로 한국 IT 융합 신산업 역량 강화 요인을 분석한 결과,  융합적인 사고와 인재 양성,  전략적 제휴를 통한 핵심 역량 강화,  고부가가치 제품 개발 및 틈새시장 공략 등이 중요한 요소임을 확인할 수 있습니다.  특히, 문서 2에서 제시된 융합 디자인 교육의 성공적인 모델은 IT 융합 신산업 인재 양성에 대한 중요한 시사점을 제공하며,  문서 5에서 제시된 글로벌 전략 또한 IT 융합 신산업의 경쟁력 강화에 적용 가능한 중요한 전략적 함의를 지닙니다.  하지만 제공된 자료만으로는 한국 IT 융합 신산업 역량 강화 요인에 대한 포괄적인 분석을 수행하기에는 한계가 있습니다.  더욱 심층적인 연구를 통해  정책적 지원, 투자 전략, 시장 환경 등 다양한 요소를 종합적으로 분석할 필요가 있습니다.",일본의 문화를 통한 산업진흥정책 연구 - 경제산업성의 활동과 정책을 중심으로,융합 이후의 융합: 융합 추구의 한국디자인교육 5년에 관한 분석과 고찰,한국의 습지지형 연구 성과와 과제,FTA가 한국 교역에 미치는 효과 분석,우리나라 가구제조 기업의 글로벌전략에 관한 연구,중국 디스플레이 산업 발전에 따른 한국기업의 대응전략,증강현실 기술을 활용한 융합형 교육 콘텐츠 설계 및 구현,젠더의 시각에서 본 고등학교 한국사 교과서,중국인 한국어 학습자의 발성 유형에 따른 한국어 폐쇄음의 변별 지각 양상,사회과 융합교육 프로그램 개발 및 적용 효과,융합교육 전문가 양성을 위한 교육프로그램 개발 및 효과성 분석,스마트 교육을 기반으로 한 융합형 가정과 프로그램 개발,글로벌 / 글로컬시대의 문화융합과 미디어콘텐츠 역할에 관한 연구,핵융합 시스템에서 방사화 분석 및 방사선 안전성 평가,한국전력공사 운영실태 문제점과 발전방향,한국인의 행복 인식 유형,『한국사』교과서 ‘동학 농민 운동’의 민주적 가치 내용분석,4차 산업혁명과 지역의 산학협력 활성화 방안 에 관한 연구: 포항지역 중심으로,융합기술 개발연구의 실현과정: 새로운 사회과학 패러다임,한국의 교육 제도에 한국 문화적 가치가 준 영향,한국어 교육목적과 학습동기 변인에 따른 상관성 분석,4차산업 혁명에 대응할 수 있는 SCM 고도화 방법에 대한 연구,융합 특징을 기반으로 한 개선된 이미지 위조검출,핵융합 수소동위원소의 우라늄 흡탈장 반응 특성,사회복지학에서의 죽음에 관한 응시와 성찰 - 질적연구방법의 유용성 -,4차산업 관련 주력산업의 고용 결정 요인 분석: 대규모 기업집단을 중심으로,안전보건교육 의무화와 산업재해,뿌리산업 제조 중소기업 현황과 정책적 시사점,이성열의 연출미학,기업 경쟁과 산업 발전 : 디스플레이 산업을 중심으로,,,,,,,,,,,,,,,,,,,,
IT와 BT 융합 기술의 특성과 특허 분석 결과를 바탕으로 융합 강도와 협력 네트워크를 요약해 주세요.,"##제목## IT와 BT 융합 기술의 특성과 특허 분석 ##서론## 정보기술(IT)과 생명공학(BT)의 융합은 신시장 창출과 기술 혁신을 이끄는 핵심 동력으로 떠오르고 있습니다. 그러나 정량적 데이터에 기반한 IT-BT 융합 정도와 협력 양상에 대한 연구가 부족한 상황입니다. 이에 특허 인용·공동분류 분석을 통해 융합 강도와 관련 조직 간 네트워크를 파악하고자 합니다. ##본론## 1. 분석 방법 - 특허 인용(citation)과 공동분류(co-classification) 정보를 활용해 기술 간 융합 강도를 계량화 - 두 가지 포트폴리오 매트릭스를 개발해 융합 범위와 심도를 시각화 2. 융합 강도 측정 - IT-BT 교차 특허 수와 인용 빈도가 꾸준히 증가, 특히 최근 몇 년간 융합 특허 비중이 크게 확대 - 공동분류 분석 결과, 정보처리 기술과 유전자·단백질 분석 기술 간 상호참조가 빈번 3. 협력 네트워크 - 기업·연구기관·대학 간 특허 공동 출원·인용 네트워크가 형성되어 있으며, 노드 중심성 분석에서 몇몇 주도 기업이 핵심 허브 역할 - BT 분야의 연구집단이 상대적으로 강한 내부 협력망을 구축한 반면, IT 분야는 외부 기관과의 연계가 활발 ##결론## 특허 기반 분석을 통해 IT-BT 융합 기술의 강도가 지속 상승 중임을 확인했으며, 기업·학계·연구소 간 협력 네트워크가 융합 확산의 핵심 축으로 자리매김함을 보여줍니다. 이러한 정량적 증거는 각 조직이 융합 전략 수립과 협업 파트너 발굴 시 유용한 참고자료가 될 것입니다.",Summary the convergence strength and cooperative network based on the characteristics of IT and BT convergence technology and patent analysis results.,"##title## Characteristics and patent analysis of IT and BT convergence technology ##introduction## The convergence of information technology (IT) and biotechnology (BT) is emerging as a core engine for creating new markets and technology innovation. However, there is a lack of research on IT-BT convergence and cooperation patterns based on quantitative data. Therefore, through patented citation and joint classification analysis, we would like to identify the network between related organizations. ## Main ## 1. Analysis method -The use of patent citation and co-classification information by quantifying convergence strength between technologies by utilizing information -Investigating the convergence range and depth by developing two portfolio matrix 2. Fusion strength measurement -The number of IT-BT cross-patents and the frequency of citation steadily increases, especially in recent years, the proportion of convergence patents has increased significantly in recent years -As a result of the joint classification analysis, the mutual reference between the information processing technology and the genetic and protein analysis technology is frequent. 3. Cooperation network -Patent joint application and citation networks between companies, research institutes, and universities are formed, and some leading companies play a core hub role in node -centric analysis. -However, the research group in the BT field has established a relatively strong internal cooperation grid, while the IT field is active in connection with external institutions. ##conclusion## The patent-based analysis confirmed that the intensity of IT-BT convergence technology is continuously rising, and it shows that the cooperative network between corporations, academia and research institutes has become a core axis of convergence proliferation. This quantitative evidence will be a useful reference for each organization when establishing a convergence strategy and finding a collaborative partner.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",36,1.1859924140007934,"**제목: IT와 BT 융합 기술의 융합 강도 및 협력 네트워크 분석: 학술 문헌 고찰을 중심으로**

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 IT와 BT 융합 기술의 특성과 특허 분석 결과를 분석하여 융합 강도와 협력 네트워크를 요약하고자 한다.  제공된 문서들은 다양한 융합 기술 분야(디자인, 유전자 가위, CCS, 증강현실, 핵융합)를 다루고 있으나, 각 문서에서 드러나는 융합의 특징과 협력의 양상을 분석하여 IT와 BT 융합 기술의 일반적인 특성을 유추해낼 수 있다.

**본론:**

제공된 문서에서는 IT와 BT의 직접적인 융합 기술에 대한 특허 분석 결과는 제시되지 않는다. 따라서,  각 문서에서 나타나는 다양한 기술 융합 사례를 통해 IT와 BT 융합의 강도와 협력 네트워크를 간접적으로 분석한다.

* **융합 강도:**  문서 4는 증강현실(AR) 기술과 교육 분야의 융합을 다루며,  AR 기술의 발전과 스마트폰 보급으로 인해 위치기반 서비스(LBS)를 활용한 교육 콘텐츠가 증가하고 있음을 보여준다. 이는 IT(AR, LBS, 스마트폰 기술)와 교육(BT와 연관된 인지 과학, 교육학적 접근 포함 가능) 분야의 상당한 융합 강도를 시사한다.  문서 1은 융합 디자인 교육 프로그램을 분석하며,  융합의 필요성과 방법에 대한 인식론적, 문화적 이해의 객관적인 분석이 다면적인 논의를 위해 필요하다고 강조한다. 이는 융합 디자인 분야에서 IT와 BT의 융합 강도가 높을수록  상호작용과 사회적 적용에 대한 심층적인 이해가 필요함을 의미한다. 문서 2는 유전자 가위 기술(BT)과 빅데이터 분석(IT)의 융합을 통해 맞춤의학을 추구하는 사례를 제시한다. 이는 빅데이터 분석 기술을 통해 유전자 정보를 효율적으로 처리하고 분석하는 높은 수준의 IT와 BT 융합을 보여준다.  문서 3과 5는 각각 CCS 기술과 핵융합 기술에서 안전성 평가에 IT기술 (시뮬레이션, 데이터 분석)의 중요성을 강조하며,  이러한 기술들이 고도의 안전성을 확보하기 위해 필수적인 요소로 작용함을 보여준다.


* **협력 네트워크:**  모든 문서는 다학제적 연구 협력의 중요성을 강조하고 있다. 문서 1은 융합 디자인 교육의 성공을 위해 다양한 분야의 전문가들의 협력이 필수적임을 시사한다. 문서 2는 전문가 인터뷰와 빅데이터 분석을 통해 유전자 가위 기술의 사회적 영향에 대한 다각적인 분석을 수행하였는데, 이는 의료, 법률, IT 전문가를 포함한 다양한 분야의 협력 네트워크를 반영한다. 문서 3은 CCS 기술 상용화를 위해 공학, 안전, 법규 전문가의 협력이 필요함을 강조한다.  문서 4는 증강현실 콘텐츠 개발을 위해 교육, IT, 디자인 등 다양한 분야의 전문가 협력을 통해 융합형 교육 콘텐츠를 설계 및 구현했다. 문서 5는 핵융합 시스템의 안전성 평가를 위해 핵융합, 방사선, 시뮬레이션 전문가들의 협력이 필요함을 보여준다.

**결론:**

제공된 문서들을 종합적으로 분석한 결과, IT와 BT 융합 기술은 높은 융합 강도를 보이며,  다학제적 협력 네트워크를 통해 시너지를 창출하는 것으로 나타났다.  특히, 데이터 분석, 시뮬레이션,  정보통신 기술의 발전은 BT 분야의 발전과 사회적 적용을 가속화하는 중요한 역할을 수행한다.  각 기술 분야의 전문가들의 협력은 융합 기술의 성공적인 개발과 안전한 상용화에 필수적이다.  그러나 본 분석은 제공된 문서에 한정되어 있으며, 더욱 포괄적인 특허 분석 및 추가적인 연구를 통해 더욱 명확한 결론을 도출할 수 있을 것이다.",융합 이후의 융합: 융합 추구의 한국디자인교육 5년에 관한 분석과 고찰,유전자 가위 기술의 사회적 영향과 법제도 운영 방안에 대한 고찰 : 빅데이터 분석과 전문가 인터뷰 결과를 중심으로,CCS 기술 상용화를 위한 위험요소 분석,증강현실 기술을 활용한 융합형 교육 콘텐츠 설계 및 구현,핵융합 시스템에서 방사화 분석 및 방사선 안전성 평가,융합기술 개발연구의 실현과정: 새로운 사회과학 패러다임,융합교육 전문가 양성을 위한 교육프로그램 개발 및 효과성 분석,스마트 교육을 기반으로 한 융합형 가정과 프로그램 개발,글로벌 / 글로컬시대의 문화융합과 미디어콘텐츠 역할에 관한 연구,기술 기업가 소유 소기업의 기술사업화 성공·실패 요인에 관한 연구,우엉가루를 첨가한 조청의 품질 특성,복숭아 농축액을 첨가한 스콘의 제주 및 품질 특성,소셜커머스 사이트 이용만족도에 영향을 미치는 소셜커머스 사이트 특성과 소비자특성 : 한중비교 중심으로,융합 특징을 기반으로 한 개선된 이미지 위조검출,사회과 융합교육 프로그램 개발 및 적용 효과,핵융합 수소동위원소의 우라늄 흡탈장 반응 특성,적정기술 활용한 도시화에 따른 대기오염문제 해결방안 모색 : 몽골 울란바타르시의 경우,리튬이차전지용 무기 고체 전해질의 기술동향,"온라인 쇼핑객의 점포태도 : 제품범주, 점포유형, 소비자특성 및 점포충성도와의 관계",포물선의 성질과 특성,도자기 원료의 특성 연구,선취업 후진학자의 특성 분석,빅데이터 활용과 분석기법 고찰,유전자 재조합 기술의 최근 동향: Recombineering을 통한 타깃 벡터 제작,살인범죄의 특성 및 대응방안,동결건조 연근 분말을 첨가한 머핀의 품질특성,내열 점착 특성 폴리이미드의 제조,사회적 기업의 적정기술 활용을 통한 혁신 사례연구,보건의료기술 진흥사업의 평가와 정책적 함의,,,,,,,,,,,,,,,,,,,,,
스마트 농업 분야에서 저탄소 녹색산업 정책을 지원하는 IT 융합 기술 적용 사례와 효과를 요약해 주시겠습니까?,"##제목## 저탄소 녹색산업 정책 지원을 위한 스마트 농업 IT 융합기술 적용 사례와 효과 ##서론## 최근 발리 로드맵 채택으로 개발도상국 역시 온실가스 감축 의무를 지게 되면서 산업 전 분야에서 저탄소 전략이 요구되고 있다. 농업 분야는 기후 변화 대응과 식량 안보를 동시에 해결할 수 있는 핵심 산업으로 주목받고 있으며, 이에 스마트 농업에 IT 융합 기술을 도입하여 저탄소 녹색산업을 육성하려는 정책적 노력이 진행되고 있다. ##본론## 1. 스마트팜 환경제어 시스템: 온·습도, 가스, 광도 센서와 네트워크 기능을 활용해 실시간으로 작물 재배 환경을 모니터링하고 자동으로 관개·환기·조명을 조절함으로써 에너지 소비와 온실가스 배출을 줄인다. 2. 데이터 기반 의사결정: 빅데이터와 시뮬레이터를 결합해 다양한 작물·지역별 생육 조건을 분석하고, 정책 수립 시 과학적 근거를 제공하여 효율적인 자원 배분이 가능하다. 3. 에너지 효율화 및 비용 절감: 네트워크 제어 기술을 적용한 농업용 설비가 전력 사용량을 최적화하고, ICT 기반 원격 관리로 인건비를 절감하여 경제성과 지속가능성을 동시에 높인다. 4. 일자리 창출과 산업 연계: 스마트 농업 시스템 구축을 위한 소프트웨어 개발, 장비 유지보수, 데이터 분석 분야 등 신성장 일자리를 창출하고, 지역 시뮬레이터 기관과 정책 부처의 협업 모델을 제시한다. ##결론## 스마트 농업에 IT 융합 기술을 적용하면 생산성 향상과 온실가스 감축을 동시에 달성할 수 있으며, 데이터 기반의 정책 결정과 신기술 일자리 창출에도 기여한다. 향후 시스템 시뮬레이션 조직과의 연계 강화, 인력 양성, 인프라 확충을 통해 저탄소 녹색산업 정책을 더욱 효과적으로 지원할 수 있다.",Can you summarize the cases and effects of IT convergence technology that supports low -carbon green industry policy in smart agriculture?,"##title## Cases and effects of smart agricultural IT convergence technology for low -carbon green industry policy support ##introduction## With the adoption of Bali Roadmap, developing countries have also been obliged to reduce greenhouse gas emissions, requiring low -carbon strategies in all industries. The agricultural sector is attracting attention as a core industry that can solve both climate change and food security at the same time. Therefore, policy efforts to foster the low -carbon green industry by introducing IT convergence technology to smart agriculture. ## Main ## 1. Smart Farm Environmental Control System: Use the on -humidity, gas, light sensor and network functions to monitor the crop cultivation environment in real time and automatically adjust irrigation, ventilation, and lighting to reduce energy consumption and greenhouse gas emissions. 2. Data -based decision: combining big data and simulators to analyze various crops and regional growth conditions for each crop and region, and provide scientific basis when establishing policies to efficiently distribute resources. 3. Energy efficiency and cost savings: Agricultural facilities using network control technology optimize power consumption and reduce labor costs by ICT -based remote management to increase economic feasibility and sustainability at the same time. 4. Creation of jobs and industrial linkage: Create new growth jobs such as software development, equipment maintenance, and data analysis to build smart agricultural systems, and present collaboration models of local simulator institutions and policy departments. ##conclusion## Applying IT convergence technology to smart agriculture can achieve productivity improvement and greenhouse gas reduction at the same time, and contributes to data -based policy decisions and new technology jobs. In the future, it is possible to more effectively support low -carbon green industry policy by strengthening linkage with system simulation organizations, fostering manpower, and expanding infrastructure.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",37,1.1859924140007934,"**제목:** 스마트 농업과 저탄소 녹색산업 정책 지원: IT 융합 기술 적용 사례와 효과 분석

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 스마트 농업 분야에서 저탄소 녹색산업 정책을 지원하는 IT 융합 기술 적용 사례와 효과를 분석합니다.  문서들은 스마트 팩토리, 스마트 모빌리티, 치유농업 등 다양한 분야를 다루고 있으나, 이 중 치유농업 관련 문서(문서 3)에서 농업과 IT 기술의 융합, 그리고 농촌 경제 활성화 및 지속가능성에 대한 내용을 분석하여 질문에 답하도록 하겠습니다.

**본론:**

문서 3은 치유농업의 관광 상품화를 통한 농촌 활성화 전략을 제시합니다.  치유농업은 농촌의 전통 가치(전통 농업 방식, 건강한 생활 방식, 지속 가능한 삶, 자연 환경)와 새로운 트렌드(정신적 안정, 심리적 편안함 추구)를 결합한 고부가가치 관광 상품으로서의 가능성을 제시합니다.  이러한 치유농업 관광 상품화는 농촌 지역의 활성화와 6차 산업화를 견인할 핵심 전략으로 제시되고 있으며, 이는 곧 저탄소 녹색산업 정책과도 밀접하게 연결됩니다.

문서 3에서 제시된 성공 전략들을 살펴보면, 먼저 도시와 차별화된 독특하고 진정성 있는 치유농업 관광 상품 개발이 중요합니다.  이를 위해서는 전통 농업 유산의 계승과 보존, 지속 가능한 전통 농업 방식의 유지 및 발전, 그리고 품질 관리가 필수적입니다.  더불어, 치유농업 관리자와 운영자의 의사소통 능력 강화 및 정부, 기관과의 유기적인 협력 체계 구축 또한 강조됩니다.

이러한 성공 전략들은 IT 기술과의 융합을 통해 더욱 효과적으로 구현될 수 있습니다.  예를 들어, 스마트팜 기술을 활용하여 농업 생산 과정의 효율성을 높이고 환경 친화적인 농업 방식을 도입하면 저탄소 녹색산업 정책에 기여할 수 있습니다.  또한, 온라인 플랫폼을 구축하여 치유농업 관광 상품을 홍보하고 예약 시스템을 운영하면 접근성을 높일 수 있습니다.  관광객들의 체험 후기를 수집하고 분석하는 시스템을 통해 서비스 품질 향상에 활용하는 것 또한 가능합니다.  이러한 IT 기술의 적용은 농촌 지역의 경제 활성화뿐 아니라, 지속가능한 농업 모델 구축에도 기여하며, 저탄소 녹색산업 정책 목표 달성에 큰 효과를 가져올 것입니다.


**결론:**

문서 3을 중심으로 분석한 결과, 치유농업의 관광 상품화 전략은 IT 기술과의 융합을 통해 저탄소 녹색산업 정책을 효과적으로 지원할 수 있습니다.  스마트팜 기술, 온라인 플랫폼 구축, 데이터 분석 시스템 등의 적용을 통해 농업 생산성 향상, 환경 보호, 농촌 경제 활성화를 동시에 달성할 수 있으며,  결과적으로 지속 가능한 농업 모델을 구축하는 데 크게 기여할 것으로 예상됩니다.  이는 농촌 지역의 경쟁력 강화와 삶의 질 개선으로 이어질 것이며,  궁극적으로는 저탄소 녹색 성장 정책의 성공적인 이행에 기여할 것입니다.",메가시티에서의 스마트 모빌리티를 위한 디자인 기초 방향 연구,스마트폰과 연동되는 M2M 기반 스마트 팩토리 관리시스템의 설계 및 구현,치유농업의 관광상품화를 위한 전략적 접근방안 연구,스마트 팩토리 추진 전략과 경제적 기대효과에 관한 연구,"한국 기록문화유산 정보시각화 연구 방안 : 천문류초, 천상열차분야지도 중심으로",사물인터넷 적용을 통한 건설 안전관리 시스템 개선방안,빅데이터를 활용한 헤어 미용분야 패러다임 변화 연구,스마트 그리드 기반 지능형 홈 시스템 설계 및 구현,정밀농업 도입의 경제성 분석,교육중심형 치유농업 선호모델 개발,친환경농업 확대 방안 : 광주광역시 사례를 중심으로,스마트폰 중독 위험군 대학생의 정신건강과 피드백 중재의 효과 연구,성공적인 메이크업 아티스트에 관한 탐색적 연구 : 심층면접법을 중심으로,⟨논문⟩ 농업부문 개도국지위 유지의 의미: DDA 농업협상 하빈슨 초안에 따른 영향분석,농업 종사자들의 자세분석 연구,도시농업 활성화를 위한 협력적 거버넌스 연구,스마트폰 의존 유형이 스마트폰 중독 정도와 일상생활에 미치는 영향,스마트폰 중독 성향을 보이는 청소년의 기질 특성,스마트폰 중독 수준과 사용방식이 자기효능감에 미치는 영향,스마트팩토리 기반의 동적 공급사슬 설계와 운영에 대한 연구,스마트시티 빅데이터 관점에서의 안전도시 구현에 관한 연구,부동산분야 국가직무능력표준(NCS)에 관한 고찰,『天象列次分野之圖』 圖說의 문헌학적 연구,조선초기 천문관측 기구의 이해와 교육적 활용방안,치유농업 전문가 양성의 효율성 제고를 위한 연구,This study examined the awareness of agricultural accounting of the agricultural management corporations in order to promote the agricultural management corporations of accounting management,도시농업 운영의 인식과 만족도에 관한 연구,인듐틴옥사이드에서의 자기조립박막 형성과 유기전기발광소자로의 응용,2020년 압축기 분야 연구동향,2020년 환경기계 분야 연구동향,,,,,,,,,,,,,,,,,,,,
국방 IT융합 비즈니스 모델 유형과 핵심 프로세스를 간략히 정리해 주세요.,"##제목## 국방 IT융합 비즈니스 모델 유형 및 핵심 프로세스 ##서론## 국방 IT융합은 민간의 첨단 정보기술을 군사 분야에 적용하여 전투력과 운영 효율을 극대화하기 위한 국가 전략이다. 2008년 관련 정책 수립 이후 국방IT융합센터를 중심으로 과제 발굴·기획·실행이 이뤄지면서 다양한 비즈니스 모델이 제시되었다. 본 요약에서는 주요 모델 유형과 이를 추진하기 위한 핵심 프로세스를 정리한다. ##본론## 1. 비즈니스 모델 유형 가. 무기체계 획득·관리: 자산의 설계 단계부터 폐기 단계까지 전 주기를 IT로 통합 관리 나. 군사정보 수집·분석: 빅데이터·AI 기반 정보 통합·분석 플랫폼 구축 다. 군사력 건설(훈련·운영): 가상·증강현실을 활용한 전술훈련 및 원격 지휘통제 체계 라. 자원관리 및 지원: 물류·병참·정비 업무의 실시간 모니터링 및 자동화 2. 핵심 프로세스 1) 요구분석 및 개념정의: 군 전문인력과 협력해 임무별 요구사항 수립 2) 상용기술 탐색·검증: 민간 IT 제품의 적합성 평가 및 시범적용 절차 3) 조달·배치 절차: 국방획득 프로세스에 신속 도입을 위한 시험·인증·조달 경로 확보 4) 통제·조정(컨트롤타워): 융합센터 주관으로 산·학·연 협력과 의사결정 조율 5) 비용 예측 및 성과평가: 소프트웨어 개발비용 합리화와 KPI 기반 결과 측정 ##결론## 국방 IT융합 비즈니스 모델은 임무 영역별 특화된 네 가지 유형으로 구분되며, 이를 실현하기 위해 요구분석에서 성과평가에 이르는 순환적 프로세스를 체계화해야 한다. 이러한 모델과 과정을 일관되게 운영하면 스마트 국방 구현과 함께 국방 산업의 혁신적 성장 동력을 확보할 수 있다.",Please briefly summarize the type of defense IT convergence business model and the core process.,"##title## Defense IT convergence business model type and core process ##introduction## Defense IT convergence is a national strategy to maximize combat and operational efficiency by applying private advanced information technology to the military sector. Since the establishment of relevant policies in 2008, various business models have been proposed with the discovery, planning, and implementation of the Defense IT Convergence Center. This summary summarizes major model types and key processes to promote it. ## Main ## 1. Business model type go. Acquisition and management of the weapon system: Integrated management of the entire period from IT from the design stage of the asset to the disposal stage me. Collection / Analysis of Military Information: Integration and Analysis Platform based on Big Data and AI -based information all. Military power construction (training and operation): Tactical training and remote command control system using virtual and augmented reality la. Resource management and support: real -time monitoring and automation of logistics, logistics, and maintenance work 2. Core process 1) Requirements and Conceptual Affection: In cooperation with military experts, establish requirements for each mission 2) Commercial Technology Search and Verification: Procedure for Evaluation and Pilot Application of Private IT Products 3) Procurement / Placement Procedure: Secure test, certification, and procurement route for rapid introduction to the defense acquisition process 4) Control and adjustment (control tower): Coordination of industrial, academia, research cooperation and decision -making with the organizer of the convergence center 5) Cost prediction and performance evaluation: Rationalization of software development costs and measurement of KPI -based results ##conclusion## Defense IT Convergence Business Models are divided into four types of specialized mission areas, and to realize this, the circular process from requirements analysis to performance evaluation must be systematic. Consistently operating these models and processes can secure innovative growth engines in the defense industry along with the implementation of smart defense.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",38,1.1859924140007934,"## 제목: 국방 IoT 융합 비즈니스 모델 유형 및 핵심 프로세스 분석

**서론:**

본 보고서는 제공된 학술 문서들을 바탕으로 국방 IT 융합 비즈니스 모델의 유형과 핵심 프로세스를 분석합니다.  문서 1과 2는 스마트 TV 및 IoT 비즈니스 모델 혁신에 대한 일반적인 틀을 제시하며, 문서 3은 국방 IoT 시스템의 보안 아키텍처 설계를 다룹니다. 문서 4는 비즈니스 모델 평가 지표 개발에 대해 논의하며, 문서 5는 비즈니스 모델 특허에 대한 고찰을 제공합니다.  이러한 자료들을 종합하여 국방 환경에 특화된 IoT 융합 비즈니스 모델의 특징을 도출하고자 합니다.  다만, 제공된 문서에서는 국방 IT 융합 비즈니스 모델에 대한 직접적인 정의나 분류가 제시되어 있지 않으므로,  문서 3의 국방 IoT 아키텍처 설계를 중심으로 분석하고, 다른 문서들의 개념적 틀을 참조하여 유추합니다.


**본론:**

제공된 문서 중 문서 3은 국방 IoT 아키텍처 설계를 통해 사이버 공격에 대한 방어 체계를 구축하는 데 중점을 두고 있습니다. 이를 바탕으로 국방 IT 융합 비즈니스 모델의 유형과 핵심 프로세스를 다음과 같이 추론할 수 있습니다.

**1. 국방 IoT 융합 비즈니스 모델 유형:**

문서 3에서 제시된 아키텍처는 국방 환경에 특화된 보안 중심의 비즈니스 모델로 해석될 수 있습니다.  이는 단순히 IoT 기기를 운용하는 것을 넘어,  **강력한 보안 기능을 핵심 가치 제안으로 하는 서비스 모델** 입니다.  다른 문서에서 언급된 비즈니스 모델 혁신의 여러 유형 (문서 1) 중에서도, 높은 수준의 혁신 (5, 6 유형)을 통해 경쟁 우위를 확보하고자 하는 전략과 부합합니다.  즉, 모방이 어렵고 높은 수익성을 확보할 수 있는 독점적인 보안 기술을 기반으로 하는 비즈니스 모델입니다.


**2. 핵심 프로세스:**

문서 3에 따르면, 국방 IoT 융합 비즈니스 모델의 핵심 프로세스는 다음과 같습니다.

* **데이터 수집 및 통합:** 과학화 감시체계, UAV 등 다양한 IoT 단말에서 수집된 데이터를 Collector를 통해 수집하고, Redis(In-memory DB)를 이용하여 통합합니다.
* **데이터 분석 및 시각화:** Elasticsearch(분산 검색 엔진)를 이용하여 데이터를 분석하고, Kibana Web server를 통해 시각화하여 관리자가 체계적으로 로그 기록을 분석할 수 있도록 합니다.
* **보안 강화:** 간접 연동 방식 도입, 접근 통제 강화, 로그 기록 보호 등을 통해 네트워크, 서버, 단말기, 응용 체계를 보호합니다. 특히 Proxy Server를 통해 Web Server와 Log Server를 분리하여 Web Server 파괴 시에도 로그 기록을 안전하게 보호하는 메커니즘을 구축합니다.
* **사이버 공격 대응:**  로그 분석을 통해 사이버 공격을 탐지하고 대응하며,  시스템의 보안 상태를 지속적으로 관리합니다.  (buffer overflow 공격 및 Ping of Death 공격에 대한 안정적인 시스템 운영 결과가 제시됨)

**결론:**

본 보고서에서는 제공된 문서들을 바탕으로 국방 IT 융합 비즈니스 모델의 유형을  보안 중심의 고부가가치 서비스 모델로, 핵심 프로세스를 데이터 수집/통합, 분석/시각화, 보안 강화, 사이버 공격 대응으로 분석하였습니다.  국방 환경의 특수성을 고려하여,  보안 및 안정성이 가장 중요한 요소이며,  이를 기반으로 높은 수준의 비즈니스 모델 혁신을 달성하는 것이 핵심임을 확인할 수 있습니다.  향후 연구에서는  다양한 국방 IoT 활용 사례 분석을 통해 더욱 구체적인 비즈니스 모델 유형 및 핵심 프로세스를 규명할 필요가 있습니다.",비즈니스 모델 혁신 관점에서 살펴본  스마트 TV 진화에 관한 연구,비즈니스 모델 관점에서 바라 본 IoT,사이버공격에 대비한 국방 IOT 아키텍처 설계,비즈니스 모델 현황 진단을 위한 평가지표 개발,비즈니스 모델 特許에 관한 硏究,국방 M&S에서 통신효과모델의 필요성 및 구축방안에 관한 연구,비즈니스 모델 특허를 둘러싼 벤처기업의 행태와 시장환경에 관한 연구,플랫폼 비즈니스 이론 기반의 모바일 플랫폼 성공 및 실패요인도출을 위한 사례연구 : 이동통신사업자 모바일 플랫폼 중심으로,비즈니스 모델 관점에서의 플랫폼 비즈니스 평가체계 연구,커뮤니티 비즈니스 활성화 방안 연구 : 한국의 대표적 성공모델을 중심으로,국방비 수준을 결정하는 영향요인에 대한 계량분석,국방기획체계의 발전 방향: 문서별 적실성과 연계성을 중심으로,DEA를 활용한 국방기술 연구개발 효율성 분석－응용연구와 시험개발 기술 중심으로－,"미국 국방개혁 사례 연구 : 레이건, 클린턴, 부시 행정부를 중심으로",군수품 품질 향상을 위한 국방 표준화 및 규격 업무체계 발전방안,무인기술을 활용한 군 보급지원체계 발전방안 : 유지물자분야를 중심으로,시스템다이내믹스를 이용한 사이버위협 대응 전략: 핵심역량 및 개방형 혁신의 도입을 중심으로,융합기술 개발연구의 실현과정: 새로운 사회과학 패러다임,글로벌 / 글로컬시대의 문화융합과 미디어콘텐츠 역할에 관한 연구,핵융합 시스템에서 방사화 분석 및 방사선 안전성 평가,핵융합 수소동위원소의 우라늄 흡탈장 반응 특성,국제비즈니스계약에 적용되는 법,중국 B2B 협상에서 협상자 개인특성과 협상전략이 협상성과에 미치는 영향에 관한 연구: '&#xaf4c;시'를 조절변수로,통일한국 시대의 동북아 전략구도와 우리의 안보전략,융합 특징을 기반으로 한 개선된 이미지 위조검출,사회과 융합교육 프로그램 개발 및 적용 효과,증강현실 기술을 활용한 융합형 교육 콘텐츠 설계 및 구현,융합교육 전문가 양성을 위한 교육프로그램 개발 및 효과성 분석,스마트 교육을 기반으로 한 융합형 가정과 프로그램 개발,융합 이후의 융합: 융합 추구의 한국디자인교육 5년에 관한 분석과 고찰,,,,,,,,,,,,,,,,,,,,
AHP 방법론을 이용한 에너지-IT 융합기술 도출 과정과 연구 성과를 압축적으로 알려주실 수 있나요?,"##제목## AHP 방법론을 활용한 에너지-IT 융합기술 도출 및 성과 요약 ##서론## 지속적인 에너지 소비 비효율과 환경문제 해결을 위해 에너지-IT(EIT) 융합이 효과적인 대안으로 주목받고 있으나, 국내에서는 스마트그리드 외에 체계적인 기술 선별과 정책적 투자가 미흡한 실정이다. 이에 본 연구는 AHP(Analytic Hierarchy Process) 기법을 통해 융합 기술의 효용성을 정량적으로 분석하고 우선순위를 도출하고자 하였다. ##본론## 1. 평가 체계 구성 - 에너지 저감 분야와 기술별 평가 기준(기술성, 경제성, 경영성 등)을 계층화하여 AHP 모델을 설계하였다. 2. 전문가 설문 및 가중치 산출 - 산업·학계 전문가를 대상으로 설문을 실시해 각 평가 기준의 상대적 중요도를 도출하였다. 3. 융합 분야 우선순위 - 에너지 절감 분야 중 ‘에너지절약형 건물(그린 빌딩)’이 가장 높은 효용성을 보였으며, - 그린 빌딩 내에서는 ‘네트워크 기능을 활용한 건물 내 에너지 소비 장치 제어·모니터링 기술’이 기술성·경제성 부문에서 최고 점수를 획득했다. 4. 정책적 시사점 - 정량적 우선순위는 정부의 에너지 효율화 정책 및 R&D 투자 방향 설정에 기초 자료로 활용될 수 있다. ##결론## AHP 분석 결과, 그린 빌딩 분야의 네트워크 기반 에너지 소비 장치 관리 기술이 국내 EIT 융합의 핵심 과제로 선정되었으며, 이를 바탕으로 국가 에너지 문제 해결과 경쟁력 강화를 위한 정책 결정에 실질적 기여가 가능하다.",Can you inform the energy-IT convergence technology and research results using AHP methodology?,"##title## Energy-IT convergence technology using AHP methodology and summary ##introduction## Energy-IT (EIT) convergence is attracting attention as an effective alternative to solve continuous energy consumption and environmental problems. Therefore, this study was intended to quantitatively analyze the utility of fusion technology and derive priority through the Analytic Hierarchy Process (AHP) technique. ## Main ## 1. Composition of evaluation system -The AHP model was designed by laying the energy reduction field and the evaluation criteria (technical, economic feasibility, management, etc.) by technical reduction. 2. Calculation of expert surveys and weights -The survey was conducted to industrial and academia experts to derive relative importance of each evaluation criteria. 3. Priority in convergence field -In the energy saving field, the 'energy -saving building (green building)' showed the most effective. In the green building, the “Energy Consumption Device Control and Monitoring Technology in Building using Network Functions” scored the highest score in the technical and economic feasibility. 4. Policy implications Quantitative priorities can be used as basic data for the government's energy efficiency policy and R & D investment direction. ##conclusion## As a result of the AHP analysis, the network -based energy consumption management technology in the green building sector was selected as a key task of domestic EIT convergence, and based on this, it is possible to contribute to the policy decision to solve national energy problems and strengthen competitiveness.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: The Trends of IT Convergence in Korea, Abstract: These days, the environment of IT development goes through converging with various industries and technologies. Also, it accelerates to pioneer new markets and develop new technologies. This trend becomes one of the most important factors to explore new national growth engines in Korea. Thus, this research examines current trends of IT convergence in Korea. The strategic characteristics of IT convergence in overseas are briefly explained for comparing purpose. The governmental strategies or efforts regarding the IT convergence have been surveyed. Some example convergences of LG, Samsung, and POSCO as major IT industries in Korea have been introduced. It also identifies several buzz concepts in this field. The study aims to provide an insight about the activities that are happening in the field of IT convergence in Korea. Finally, the findings through the research have been summarized., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201208438434742,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed. In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201615139872516,","Title: IT기업 관점에서의 국방IT융합 추진방향, Abstract: IT convergence technology can boost the advancement of weapon systems and efficient operation for the military reformation in Korea. This study investigated IT firms' concern about the defense acquisition process for IT-convergent systems and the role of IT firms in the process with Focus Group Interview and in-depth interview on executives of IT firms, and classified the concern to three major issues. They are the clarification of IT firms' role in the defense IT-convergent efforts, the establishment of the control tower for defense IT convergence, and reasonable estimation of software development cost in the defense acquisition process., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201415642602449,","Title: PHOTONICS IT CONVERGENCE - Photonics Convergence ISSUE, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584672,","Title: Future trends of IT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP09364542,","Title: IT convergence security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART68850688,","Title: Photonics IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200951935717067,","Title: IT 융합서비스 및 활용기술의 기술속성에 관한 연구 : 산업간 융합을 중심으로, Abstract: The IT convergence industry is expected to create some high added-value, yet the IT convergence service is still in its introductory stage, which requires the utilization of yet to be tried future technologies and development methodologies that have been never tried in the past; therefore, there is certain risk involved regarding the success of development during the introduction of service and the development of technology. From such perspective, this study found examples of the services in the IT convergence industries and the application technologies for the realization of those services; and conducted a research based on the examples, using the technical Characteristics classification; and based on the result, analyzed the standards and the peculiarity of technologies employed for the IT convergence service and the correlation and the complementarity between them; also identified the standards and the peculiarity of technologies required by the IT convergence services and analyzed the correlation between them; and finally analyzed the compatibility between the IT convergence services and the applied technologies. The conclusion of this study is expected to be utilized for selecting technologies for the introduction and the operation of the optimal IT convergence service and as a benchmark as well., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201029848353209,","Title: IT and OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508649,","Title: Technological Convergence of IT and BT: Evidence from Patent Analysis, Abstract: In recent innovation trends, one notable feature is the merging and overlapping of technologies: in other words, technological convergence. A key technological convergence is the fusion of biotechnology (BT) and information technology (IT). Major IT advances have led to innovative devices that allow us to advance BT. However, the lack of data on IT-BT convergence is a major impediment: relatively little research has analyzed the inter-disciplinary relationship of different industries. We propose a systematic approach to analyzing the technological convergence of BT and IT. Patent analysis, including citation and co-classification analyses, was adopted as a main method to measure the convergence intensity and coverage, and two portfolio matrices were developed to manage the technological convergence. The contribution of this paper is that it provides practical evidences for IT-BT convergence, based on quantitative data and systematic processes. This has managerial implications for each sector of IT and BT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201266833852356,","Title: Convergence IT 관련 기사, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART54596509,","Title: IT convergence and security, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART67385534,","Title: PHOTONICS IT CONVERGENCE - IT Korea, Shanghai EXPO, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201045340584669,","Title: IT/OT Convergence 기반의 Advanced Distribution Management System의 설계, Abstract: Power automation system to operate power distribution systems can be distinguished by distribution SCADA with remote monitoring and control; and distribution automation system with basic functions such as service restoration to the distribution SCADA; and distribution management system which is operated by various applications in order to enhance distribution system operation performance based on the distribution automation system. In the technological change, a technical boundary of information technology (IT) and operation technology (OT) is being blurred by that new concepts such as interoperability. In addtion, IT/OT convergence has been proposed by the improvement of ICT and power system technology. At the viewpoint, advanced distribution management system (ADMS) to have the new concepts and to increase distribution system operation efficiency through global information and functions from the other systems has been proposed.In order to implement the ADMS, IT and OT have to be employed together on the ADMS; and the concept-based IT/OT convergence concept has been presented. Therefore, this paper introduces ADMS and IT/OT convergence and proposes a design of IT/OT convergence based ADMS system design with configurations and functions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002106318,","Title: 국방 IT융합 비즈니스 모델 사례와 성과 분석, Abstract: Information technology (IT) convergence have been recognized one of the key drivers in the industry perspective. Especially, IT convergence have been one of the most important innovative way for defense sector. Korea government established IT convergence policy in 2008 and have been applying it to the core industry such as automotive, shipbuilding and defense industries. Recently, the creative vitamin project has been launched. Vitamin 'D' means the way to create the value of defense industry. This research analyzes and evaluates various IT convergence business models based on an operation of defense IT convergence center from 2011 to 2014, which is the industry IT convergence centers. Defense IT convergence business models can be classified into four types of mission area as follows : weapon acquisition and management, military intelligence, military power construction, and resources management. We define the concept of defense IT convergence and describe the framework and processes for applying IT to the defense sector. We analyzes and evaluates various business models designed through defense IT convergence framework and processes., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249375504,","Title: 국방IT융합 추진방법론 및 사례 연구, Abstract: Information technology convergence has been recognized one of the key drivers in the industry perspective. Korea government established IT convergence policy in 2008 and has been implementing it to the core industry such as automotive, shipbuilding and defense industries. This research analyzes various IT convergence issues based on an operation of defense IT convergence center, one of the industry IT convergence centers. Defense IT convergence issues are as follows : the methods for introducing rapid changing IT to military area, rapid deployment procedures of verified commercial technologies and products, regulations for using of domestic software promotion and so on. We define the concept of defense IT convergence and propose the framework and processes for applying IT to our defense sector as one of industries. Also, we establish various business models in the military perspective using defense IT convergence framework. In this paper, we focus the development of defense IT convergence through the alignment of national IT convergence policy and propose various business models established through operating a defense IT convergence center., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201207364424562,","Title: On exploring factors for enhancing export competitiveness in IT Convergence industries, Abstract: Purpose - The IT convergence industry, which is the subject of this study, is the main strategy field during the 4th industrial revolution era. Against this background, it is urgent to establish policy measures to survive and spread export products in the global industries.Research, design, data and methodology - In order to achieve this goal, we conducted the Importance - Performance Analysis (IPA) and found that it is necessary to develop tailor - made marketing support for small and medium sized IT exporters and to develop export strategy products with competitive technologies.Results - Above all, customized marketing support for IT export-related SMEs was needed. Next, in the first quadrant, strategic products, qualitative level, global, value added, and information systems were included, and it was found that 'development of export strategic products with competitive technologies' was necessary. In the third quadrant, related variables calculated at present time are not urgent variables.Conclusions - In this study, it would be necessary to calculate the additional implications of the variables that are not considered in this study, including future studies, because the methods considered here as analysis variables are carried out in comparison with the previous studies., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002465752,","Title: IT/OT convergence and cyber security, Abstract: A study by Forrester, commissioned by Fortinet, reveals the growing exposure of industry players to cyberthreats &ndash; one of the consequences of digital transformation. The lack of collaboration between IT teams and those in charge of industrial or operational technology (OT) is also a hindrance to cyber security for companies wishing to take full advantage of IT/OT convergence to increase their competitiveness., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117320297,","Title: 그린산업 육성을 위한 농업분야 IT융합기술, Abstract: Recently, The Bali Road Map was approved, as it demands that developing countries should also have the responsibility of greenhouse gas reduction from 2013. This suggests that the greenhouse gas and environment should be controlled across industry sectors. Accordingly, this study was conducted to identify the application and effects of the IT convergence technology to the smart farm and realize the low-carbon green industry in Korea. The smart farm technologies within and outside of Korea were comparatively analyzed for the low-carbon green industry policy. The study subjects were determined to propose the necessity of the study efficiently. First, the studies on the smart farm for low-carbon green industry policy were examined. Second, the suitable IT technology for the smart farm as well as the effect and the improvement plan of the IT technology-based smart farm system were examined. This study now aims to promote the low-carbon green industry policy and IT convergence technology and job creation. These will be achieved by providing the plan for linking the system simulator organization with the low-carbon green industry policy., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201206735658103,","Title: Medical Device Connectivity - IT Convergence :, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107060719,","Title: Mining and IT-OT convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART79508640,","Title: IT Convergence: Advice to Biomeds, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51233203,","Title: IT/automation convergence revisited, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART49538731,","Title: Navigating BAS-IT Convergence, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART30908117,","Title: 정보기술(IT)융합 콘텐츠가 노인의 작업수행능력에 미치는 영향, Abstract: This study was done on the basis that IT convergence-contents can help the elderly. The effects of IT convergence-contents were analyzed on the occupational performance of the elderly. This investigation was done with 100 elderly people above 65 years of age who lived in local community and two senior welfare centers in Busan and Kyeongbuk. The 100 elderly people were split into two groups of 50: the one group who has experience with IT convergence-contents was the experiment group, and the other group with no experience was the control group. In both groups, body functions, cognitive functions, activities of daily living and community participation were tested. The experimental group had higher scores for cognitive function, and activities of daily living than that of the control group. In conclusion, future studies can support continued IT convergence-contents at the local business community level rather than with smaller samples. This work lays the groundwork for follow-up studies to evaluate the effectiveness of IT convergence-contents., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201525249160364,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area. NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202014862061800,","Title: 강원도 동계 스포츠 IT 융합 서비스 방안 연구, Abstract: Recently, various types of information and communication technology (ICT) such as cloud computing, big data, and virtual reality have been progressed in the world. Also, it is expected that there are many domestic and foreign visitors in Gangwon-do due to the Pyeongchang winter olympic games in 2018. In this environment, it is necessary to improve the competitiveness of Gangwon-do in winter sports areas exploiting both existing IT infrastructure and application technologies. In this paper, for sustainable development of Gangwon-do winter sports IT industry after the Olympics, we propose efficient implementation methods of 3 winter sports IT convergence services and Gangwon-do ICT activation strategy. The proposed 3 winter sports IT service areas are as follows. 1) Realistic winter sports IT service, 2) Winter sports medical IT service 3) Winter sports record analysis IT service., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201403460492160,","Title: Convergence of Enterprise IT and Embedded Systems, Abstract: Convergence is currently melding entire disciplines to fully new business models and technologies across industries. What used to be embedded systems, on the one hand, with their specific constraints from the physical environments, and IT, on the other hand, are combining.1,2 This will impact education programs as well as classic industry boundaries., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART96536022,","Title: 국내 중소기업의 기술융합 전략 및 성장 정책: IT & BT 융합기술 기반 네트워크 분석, Abstract: Many scholars have addressed the technological convergence of small-medium sized firms in Korea and their impact on the economic growth of nation. Nevertheless, most studies have been investigated the relationship between entrepreneurship and venture creation, and a few studies have analyzed the innovation and technological convergence of SMEs. The purpose of this research is to gain industrial insight into the technological convergence and to suggest a dynamic growth policy for entrepreneurs of SMEs to improve their convergence performance based on IT and BT. Therefore, we intend to propose solutions to these key questions in convergence such as; what are the key patterns in the process of technological convergence of SMEs on IT and BT, and what kinds of strategy do their need? In order to answer these research questions, we adopt network analysis using patent citation information. Results of network analysis revealed that building ecosystem based on government and universities is one of the most important factors for the future growth of SMEs in Korea. Also, the fit between technological convergence direction of SMEs and division of convergence structure of government and universities will be positively associated with dynamic growth of SMEs in Korea. In conclusion, this research extends the current studies on important aspects of SMEs in the technological convergence process by proposing their growth in convergence process to a newly converging context, IT and BT, and shed light on the integrative perspectives of crucial roles of SMEs on innovation performance in the IT and BT technological convergence., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201528764978526,","Title: Investigations on IT/ET and IT/BT Convergence Technology Using Power Line Communications, Abstract: Due to enhanced high IT (information technology) development, IT-based technology convergences such as IT/ET(electric technology), IT/BT(biology technology) and IT/NT(nano technology) are actively merging trend and their applications spread wide. In this paper PLC (power line communication), one of the merging IT, is investigated as one of the potential IT candidates for IT/ET and IT/BT convergence technology for DLC (direct load control) or bio-medical engineering such as ubiquitous health cares or D2H2 (distributed diagnosis and home health care)., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08302200,","Title: A Comparative Study on Convergence of IT, BT and NT: Focusing on Patent Data, Abstract: Technological convergence is yielding new values and affecting various fields not by single technology but by convergence between technologies. This study aims to analyze the IT -BT-NT convergence and differences between technologies in respect of collaboration within (inventor) and between (assignee) organizations. Among the main technologies leading the technological convergence, IT is the most active of converging with other fields. BT is knowledge-intensive and strong cooperative networks are important in this area.NT is applied in various industrial fields upon the basic technology. Using the data on applied and granted patents by Korean applicants in the U.S., this study conducted quantitative analysis and ANOVA to gain the following results. First, the degree of convergence in between IT-BT-NT is continuously increasing since 2002. Second, BT is where the collaboration within and between organizations is the most active among IT-BT-NT. Third, there were certain differences in the degree of convergence according to the years and the fields of technologies in all the IT-BT-NT. Organizations cooperate with other institutions to sustain their competitiveness with limited internal resources. Companies in these fields are recommended to perform diverse strategies to pursue further collaboration with the outside., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002557139,","Title: IT Convergence Self-care Guide Insole, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107404764,","Title: Defense IT Convergence in South Korea, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART107401471,","Title: Color Convergence: Is it Only Mimetic?, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART26434620,","Title: Real-Time Monitoring of COVID-19 Vaccination Compliance: A Ubiquitous IT Convergence Approach, Abstract: As most countries relax restrictions on lockdown and social activities returns due to massive response to COVID-19 vaccination, there is need to put in place a universally acceptable technological innovation that can checkmate and enforce compliance to avoid resurgence of another deadly wave as witnessed previously. Combining vaccination effort with disruptive technology for compliance enforcement is an unarguable panacea. This paper presents an IT-convergence solution that fuses disruptive technologies to distinguish between vaccinated and non-vaccinated individuals in real-time and initiate strict and appropriate compliance directives and consequent denial of access to certain places. The proposed design is a fusion of facial recognition, mask wearing detection technology using Yolov5 deep learning model, network-based vaccination record management application, biometric feature-based vaccination status validation, and compliance enforcement in real-time. The system achieved 99.5&#x0025; accurate detection and 100&#x0025; real-time authentication with less computational complexities. This innovation guarantees intuitive monitoring of vaccination progress and curtailment of COVID-19 spread through compliance enforcement., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP13570757,","Title: Convergence of Energy and IT Sectors, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART133388413",39,1.1859924140007934,"**제목: AHP 방법론을 이용한 에너지-IT 융합기술 도출 과정 및 연구 성과에 대한 분석 보고서 (문서 부재)**

**서론:**

제시된 질문은 AHP 방법론을 이용한 에너지-IT 융합기술 도출 과정과 연구 성과에 대한 압축적인 설명을 요구합니다. 하지만 제공된 문서 1~5는 AHP 방법론이나 에너지-IT 융합기술에 대한 정보를 직접적으로 다루고 있지 않습니다. 따라서, 제공된 자료만으로 질문에 대한 완벽한 답변을 제공할 수 없습니다.  다만, 제공된 문서에서 얻을 수 있는 폐기물 에너지화 관련 정보를 바탕으로 에너지-IT 융합기술 연구의 가능성을 간접적으로 논의할 수 있습니다.


**본론:**

제공된 문서 중 문서 1은 고형폐기물을 이용한 에너지 발생 시설의 에너지 효율에 대한 연구 결과를 제시합니다.  생활폐기물 소각시설과 고형연료 사용시설의 에너지 회수 효율을 분석하고, 대기오염물질 배출량을 측정하여 시설 운영의 효율성과 환경적 영향을 평가하였습니다.  문서 1에 따르면 생활폐기물 소각시설의 에너지 회수 효율은 약 67%, 고형연료 사용시설은 약 89%로 나타났습니다.  고형연료 사용시설의 경우 효율은 높지만 대기오염물질 배출량이 높아  방지시설 개선의 필요성이 제기되었습니다.

이러한 연구 결과는 에너지-IT 융합기술 개발의 필요성을 시사합니다.  예를 들어,  IT 기술을 활용하여 소각 과정의 온도, 압력, 연료 공급량 등을 실시간으로 모니터링하고 제어함으로써 에너지 효율을 극대화하고 대기오염물질 배출량을 최소화하는 시스템을 구축할 수 있습니다.  또한,  인공지능(AI) 기반 예측 모델을 개발하여 폐기물의 조성 변화에 따른 에너지 발생량을 예측하고 시스템 운영을 최적화할 수 있습니다.  더 나아가,  사물 인터넷(IoT) 기술을 활용하여 다양한 센서 데이터를 수집하고 분석하여 에너지 시스템의 안정성과 효율성을 높이는 스마트 폐기물 처리 시스템을 구축할 수 있습니다.  이러한 시스템은 에너지 효율을 높이고 환경오염을 줄이는 데 기여할 뿐만 아니라,  데이터 분석을 통해 시스템 운영의 효율성을 높일 수 있습니다.


**결론:**

제공된 문서는 AHP 방법론이나 구체적인 에너지-IT 융합기술 연구 결과를 제시하지 않습니다. 하지만 문서 1의 고형폐기물 에너지화 연구 결과를 바탕으로 에너지 효율 개선과 환경오염 감소를 위한 에너지-IT 융합기술의 필요성과 가능성을 확인할 수 있습니다.  향후 연구는 AHP 방법론을 적용하여 다양한 에너지-IT 융합기술 후보들을 평가하고,  최적의 기술 도출 및 효과적인 시스템 구축 방안을 제시하는 데 집중해야 할 것입니다.  이를 위해서는  IT 기술을 활용한 실시간 모니터링 및 제어 시스템, AI 기반 예측 모델, IoT 기반 스마트 폐기물 처리 시스템 등의 개발이 중요합니다.",고형폐기물을 이용한 에너지 발생 시설의 에너지 효율에 관한 연구,문식성 교육 연구 방법론 -실험 연구 방법론을 중심으로,데이터 웨어하우스 개발 방법론 : 메타데이터 관점으로,새로운 간호윤리학 방법론;통합된 사례방법론,프로젝트 팀의 팀워크에 대한 인식유형 연구: Q방법론 적용,신재생에너지 분야 국가연구개발의 성과분석 연구,전자기유도 방식의 에너지 하베스터 설계 및 제작,Q-방법론을 활용한 유아교사의 다문화교육에 대한 이미지 유형분석,블록체인 기반 에너지 거래모델 연구,신재생에너지 정책이 건축계획에 미치는 영향에 관한 연구,에너지저장장치(ESS) 산업의 경쟁력 제고 방안,제로에너지 건물 구현을 위한 외피 설계 통합 분석 모델 : 분산형 태양광 발전을 중심으로,수치모델을 통한 한국 남해 동부해역의 해양쓰레기 이동에 관한 연구,지속가능한 수변지역 개발을 위한 토지이용계획,다중이용업소 화재피해 최소화 방안에 관한 연구 : 화재 원인 조사 분석을 중심으로,한중소비자의 여행공유경제 이용의도 비교분석 : 여행공유경제 플랫폼과 소비자 개인 특성을 중심으로,소비자들의 서비스 로봇의 이용의도 영향요인에 대한 탐색적 연구,화석돌말류를 통한 울릉분지와 대한해협에서의 고해양학적인 연구,NOC 구조 설계 방법론,다중이용업소 소방안전의 실효성 확보를 위한 방안,지방자치단체의 구역 및 경계에 관한 법적 과제,A numerical experiment study on the circulation of the Japan Sea : East Sea,[보건과 사회과학] 연구의 주제 및 방법론 동향: 1997년부터 2017년까지,프로세스 혁신 방법론,미래연구 방법론,고등학교 과학 교과서에 제시된 에너지 및 기후변화 관련 내용 분석,신재생에너지 확대 정책과 문제점: 미국과 EU사례를 중심으로,결합(Coupling)된 열음향 레이저의 음향파 특성 비교 분석,민간의료보험 가입이 의료이용에 미치는 영향,빅게임 디자인 방법론,,,,,,,,,,,,,,,,,,,,
How would you concisely summarize the key findings on using machine learning classifiers combined with molecular docking to predict cytochrome P450 ligand interactions?,"##Title## Integrative Machine Learning and Docking Approach for Predicting Cytochrome P450 Ligand Binding ##Introduction## Cytochrome P450 (CYP) enzymes play a central role in the first-phase metabolism of drugs and xenobiotics, making accurate prediction of ligand–CYP interactions critical in early drug development. Traditional experimental screening of potential CYP substrates and inhibitors is time-consuming and resource-intensive. Combining fast, data-driven classification models with molecular docking offers a promising in silico strategy to forecast which compounds are likely to bind specific CYP isoforms. ##Main Body## Four machine learning classifiers—Laplacian-modified naïve Bayesian, random forest, recursive partitioning, and support vector machine—were trained on known ligands of the five major CYP isoenzymes responsible for over 80% of drug metabolism. All models achieved over 80% accuracy, sensitivity, and specificity, alongside statistically significant AUC and Matthews correlation coefficient values, confirming their robust discriminative power. Complementary docking studies then evaluated how representative substrates orient and interact within each CYP active site, predicting plausible binding modes and key contact residues. This dual workflow—classification to flag likely binders followed by docking to characterize their interaction geometries—provides both rapid screening and mechanistic insight. ##Conclusion## By integrating high-performing machine learning classifiers with molecular docking, this approach enables reliable prediction of CYP–ligand interactions and detailed hypotheses on binding mechanisms, streamlining early evaluation of drug candidates and helping prioritize compounds for experimental validation.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",40,1.1859924140007934,"**Title:** Analysis of Cytochrome P450 Ligand Interactions:  Absence of Machine Learning and Molecular Docking Data in Provided Documents

**Introduction:**

The original question asks for a concise summary of key findings on using machine learning classifiers combined with molecular docking to predict cytochrome P450 ligand interactions.  This report analyzes the provided documents to address this question.

**Body:**

None of the provided documents (Documents 1-5) contain information on the use of machine learning classifiers combined with molecular docking to predict cytochrome P450 ligand interactions.  Document 2 discusses the engineering of Bacillus Cytochrome P450 BM3 to mimic the activity of human P450 2A6, involving directed evolution and a colorimetric screening method.  However, this methodology does not involve machine learning or molecular docking. The document describes experimental methods for identifying P450 BM3 mutants with improved activity, relying on phenotypic screening rather than computational prediction.  The remaining documents are unrelated to cytochrome P450s, machine learning, or molecular docking.  Document 1 discusses opportunistic service access in pervasive computing; Document 3 reviews language teaching pedagogy; Document 4 details histopathological findings in medicolegal autopsies; and Document 5 examines the frequency of abnormal findings in cervical spine MRIs.


**Conclusion:**

Based on the provided documents, there is no information available to summarize key findings on using machine learning classifiers combined with molecular docking to predict cytochrome P450 ligand interactions. The research described in the documents employs different methodologies, focusing on experimental approaches rather than computational prediction techniques.  Therefore, a concise summary addressing the original question cannot be provided from these sources.",How the 'What' Becomes the 'How',Human P450 2A6 활성을 갖는 Bicillus Cytochrome P450 BM3 효소의 Indigo formation을 이용한 Engineering,25 Years of HOW: A Celebration of Language Teaching and Learning,Histopathological Findings in Medicolegal Autopsies with Emphasis on Rare Incidental Findings,Magnetic Resonance Imaging of the Cervical Spine: Frequency of Abnormal Findings with Relation to Age,Systematic Review Reporting - Writing concisely and precisely,전세포 촉매 반응을 위한 시토크롬 P450 102A1와 포유류 NADPH-P450 리덕타제의 활성형 표면 발현,P450と&#x767a;がん,Dynamic CT Findings of Pulmonary Hamartoma: A Comparison with Histopathologic Findings,Correlation of Imaging Findings with Pathologic Findings of Sclerosing Adenosis,A Retrospective Study of Intervertebral Disk Disease in 21 Dogs; Clinical Findings and Outcomes,Comprehensive Cardiac Safety Assessment using hiPS-cardiomyocytes (Consortium for Safety Assessment using Human iPS Cells: CSAHi),Mainstream economics and economic crises: how responsible? how reformable?,How do we know how?,사람 cytochrome P450 1A2와 사람 cytochrome P450 1A2의 bacterial homologue cytochrome P450 BM3의 생화학 및 물리적인 특징,"Review toward all RNA structures, concisely",Breeding and Using of Silage Maize Variety Longfudan 208,"Health-Care Data Collecting, Sharing, and Using in Thailand, China Mainland, South Korea, Taiwan, Japan, and Malaysia",To Ponder the Study of Paper Using Based on the Open of Government Affair Information,참취에 대한 기호도 및 이용실태 조사에 관한 연구,Partially Polarized Signal Detection Using Polarization Sensitive Array,Approach to Neurotoxicity using Human iPSC Neurons: Consortium for Safety Assessment using Human iPS Cells,Solving frequency assignment problem using an adaptive multiple-colony ant algorithm,"Regionalism in the Asia-Pacific Region: How Wide, How Deep?",사람 태반 cytochrome p450 aromatase cDNA의 cloning,Cytochrome P450 유전자 발현과 그 cDNA cloning,"Bacillus megaterium cytochrome P450 BM3의 자연적 변형에 대한 특성연구 : 효소적, 생화학적 특성",Extraspinal findings on lumbar spine MR imaging.,"Indications and findings at colonoscopy in Ilorin, Nigeria",Colonoscopy Findings: A Single Institution Study from Pakistan,Notify boiling water by using TMP36 sensor,Research on Frog Pattern in Li Brocade,Transport aircraft requirements - How much? How soon? How to pay?,빛 유도 사이토크롬 P450 촉매의 새로운 플랫폼 기술 개발,인간 시토크롬 P450 2B6의 약물상호작용에 관한 연구,토마토 유래 cytochrome P450-19 (SlP450-19) 유전자의 분리 및 기능연구,LaTeX for Everyone: A Reference Guide and Tutorial for Typesetting Documents Using a Computer.,Solving Concisely Expressed Combinatorial Auction Problems,Solving Concisely Expressed Combinatorial Auction Problems,A Concisely Convergent Synthesis of Berberine Chloride,HOW TO CHEAT,"The Procedural Syllabus and the Task Syllabus: How Similar, How Different?","Chloroplasts, Concisely",Presenting Science Concisely.,Presenting Sets of Problem Solutions Concisely,Presenting Sets of Problem Solutions Concisely,An undergraduate rootkit research project : How available? How hard? How dangerous?,Science in space- How pure - How pragmatic,Findings,A Review of ACIR Findings
Could you outline the main points about the role of large-scale machine learning in bridging database systems and commercial applications?,"##Large-Scale Machine Learning and Commercial Applications## ##Introduction## The integration of machine learning with database technologies has shifted from a purely academic endeavor to a cornerstone of modern commercial and scientific systems. As data volumes grow into the tera-scale range, quality modeling increasingly depends on the ability to process and learn from massive datasets. Bridging database systems and real-world applications therefore requires not only new algorithms but also scalable infrastructures and standardized workflows. ##Main Body## Large-scale machine learning applications today rely on distributed storage and parallel computing frameworks tightly coupled with database engines to handle high-velocity, high-volume data. Typical workflows start with data ingestion and cleaning within a database environment, proceed to feature extraction and model training across compute clusters, and culminate in model deployment back into operational systems for real-time prediction or batch scoring. Current systems support—such as MapReduce, distributed SQL engines, and specialized ML libraries—address many scaling challenges, but critical gaps remain. In particular, there is no universally accepted life-cycle process for productionizing models (akin to CRISP-DM in data mining), leading to ad hoc integration, limited reuse, and operational bottlenecks. Moreover, emerging advances in ML research (e.g., streaming models, adaptive learning) demand new database primitives for incremental updates, low-latency inference, and co-optimization of storage and computation. ##Conclusion## To fully bridge database systems and commercial applications, future work must deliver unified platforms that support both established ML use cases and cutting-edge research. Standardized life-cycle processes, tighter DB-ML integration, and extensible infrastructures will be key to operationalizing large-scale learning at enterprise scale.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",41,1.1859924140007934,"**Title:** The Absence of Large-Scale Machine Learning in Bridging Database Systems and Commercial Applications: An Analysis Based on Provided Documents

**Introduction:**

The provided documents focus on diverse applications of large-scale techniques, including medical diagnosis, materials science, network resilience, and genetic mapping.  However, none directly address the role of large-scale machine learning in bridging database systems and commercial applications.  Therefore, this report will analyze the provided texts to determine what inferences, if any, can be drawn regarding this topic.

**Body:**

The provided documents do not contain information regarding the intersection of large-scale machine learning, database systems, and commercial applications.  Document 1 describes a computer-aided diagnosis system using a transformer and convolutional neural network, demonstrating large-scale application in medical image analysis, but not its connection to database systems or broader commercialization.  Document 2 details the large-scale synthesis of transition metal dichalcogenides for commercial applications in flexible electronics, focusing on materials science and manufacturing processes, not machine learning or database integration. Document 3 addresses network service survivability in large-scale failure scenarios through dynamic modeling, focusing on network resilience rather than database systems or machine learning applications. Document 4 discusses large-scale genotyping in malaria parasites using microarray technology, focusing on biological data analysis and genomic research, without mentioning machine learning or database systems. Finally, Document 5 analyzes the clinical role of nurse educators, entirely unrelated to the topic of large-scale machine learning, databases, or commercial applications.

Based solely on the provided documents, no direct evidence supports or refutes any specific role of large-scale machine learning in bridging database systems and commercial applications. The documents showcase large-scale methodologies in various unrelated fields, lacking any discussion of their interaction with database systems or their relevance to commercial deployment in the context of machine learning.  Therefore, a conclusive statement regarding this intersection cannot be made based on the provided context.

**Conclusion:**

The provided research papers illustrate the diverse applications of large-scale techniques across various domains. However, none of the documents offer information on the specific role of large-scale machine learning in integrating database systems with commercial applications.  Further research is needed to address this topic.  The absence of relevant information within the provided corpus prevents a comprehensive analysis of this question.",Computer-aided diagnosis system based on multi-scale feature fusion for screening large-scale gastrointestinal diseases,Synthesis of Large-Scale Transition Metal Dichalcogenides for Their Commercialization,Enhancing Network Service Survivability in Large-Scale Failure Scenarios,Large-scale Genotyping and Genetic Mapping in Plasmodium Parasites,The Nurse Educator's clinical role,What Could I have Done Differently?,Spinal Cord Injury: How Could Acupuncture Help?,Could DCT Reveal Photorealistic Images?,Tender points i trigger points--r?znice i podobie?stwa.,Trigger Points and Classical Acupuncture Points,Sixty Main Points of Design for Housing Window,초등학생이 인식하는 보건교사의 역할기대와 역할수행,Large-scale eddies measured with large scale particle image velocimetry,Could Arthroscopes be Better?,Zebrafish toxicological screening could aid Leishmaniosis drug discovery,How Algeria Could Survive the Arab Spring? Governance Perspective,The hand: Embryology and main malformative mechanisms,Les greffons osseux vascularis&#x00E9;s p&#x00E9;dicul&#x00E9;s pr&#x00E9;lev&#x00E9;s sur la main et le poignet : revue de la litt&#x00E9;rature et nouveau site donneur,"Main coup&eacute;e, main errante, main absente : All&eacute;gorie r&eacute;elle de la Grande Guerre",La main spastique psychog&egrave;ne,Harmony Mechanism Between Main Productive Region and Main Sale Region,Critical points and reconstructibility,"Extreme Points, Exposed Points and Smooth Points of the Space &#x1D4DB;<sub>s</sub>(<sup>2</sup>&#x1D459;<sup>3</sup><sub>&#x221E;</sub>)",[Fibromyalgia and trigger points],[Azithromycin: critical points],STRICTLY EFFICIENT POINTS AND HENIG PROPER EFFICIENT POINTS,Modeling Role Enactment: Linking Role Theory and Social Cognition,Role-based Process Management,Role-Based Component Integration,Large-Scale Graphene Production Techniques for Practical Applications,Condensation Toward Large-Scale Fluctuations in Noise-Driven Plasmas,Large-Scale Cloud Radio Access Networks: Fundamental Asymptotic Analysis,Jaccoud&apos;s arthropathy,Large Scale Energy Harvesting and Transfer Networks,Large scale vertical implantation of crystalline titania nanotube arrays,정수좌표가 아닌 torsion points를 갖는 타원곡선,Could Alice equalize student learning?,Could all laboratory animal use could be ended by the year 2020?,Unterschiede zwischen myofazialen Triggerpunkten und &#x201e;tender points“,영어 수행 능력 향상을 위한 Role playing,Novel Role Administrative Model of Role-based Access Control,Top Bracing을 이용한 선박엔진의 진동방진에 관한연구,Tendinopathies de la main et du poignet,Syndromes canalaires r&#x00E9;v&#x00E9;l&#x00E9;s &#x00E0; la main,Permis de conduire et chirurgie de la main,역할놀이를 통한 인간존중교육 방안 연구,Formal specification for role based access control user/role and role/role relationship management,What motor cars could be,What Motor Cars Could Be,Role-play를 통한 의사소통능력 향상에 관한 연구 : 중학교 1학년을 중심으로
What are the core contributions of spatial and temporal adaptation techniques in machine learning–based scheduling knowledge acquisition?,"##Machine Learning–Based Scheduling Knowledge Acquisition with Spatial and Temporal Adaptation## ##Introduction## Effective scheduling in manufacturing relies on dispatching rules that adapt to changing system states over time. Traditional machine learning approaches have focused primarily on temporal adaptation, selecting optimal rules based solely on system state dynamics. Introducing spatial adaptation—where each machine tailors its rule choice by considering neighboring machines—promises further productivity gains. ##Main Body## This study formalizes two adaptation concepts: temporal adaptation (choosing rules as system states evolve) and spatial adaptation (each machine accounts for its own and adjacent machines’ rule effects). To capture these adaptations, the authors propose (1) a Taguchi-based systematic experiment design that incrementally uncovers robust dispatching rule combinations and (2) a coevolutionary genetic algorithm (GA) that evolves flexible rule sets across machine populations. In a stable semiconductor reentrant flow, the Taguchi method identified rule combinations that outperformed heuristics and maintained robustness under noise. For more dynamic fuel-transfer manufacturing, extending Taguchi to spatial–temporal adaptation yielded improved strategies but at considerable computational cost. The coevolutionary GA addresses this by encoding rule options per machine population and introducing a fitness evaluation combining zero-order (baseline performance) and first-order (performance sensitivity) measures; this innovation mitigates interpopulation ripples and speeds convergence. Comparative experiments show the GA delivers high-quality solutions rapidly, while the Taguchi procedure offers valuable insights into decision processes. ##Conclusion## Integrating spatial and temporal adaptations enhances scheduling rule learning by accounting for both dynamic changes and intermachine interactions. The Taguchi approach provides robust, noise-resilient rule combinations and educates experts on decision logic, whereas the coevolutionary GA dramatically reduces learning time and yields flexible, high-performance strategies. Together, these contributions advance automated knowledge acquisition for complex scheduling environments.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",42,1.1859924140007934,"**Title:** An Examination of Spatial and Temporal Adaptation Techniques in Machine Learning-Based Scheduling Knowledge Acquisition: A Review of Relevant Literature.

**Introduction:**

This report addresses the core contributions of spatial and temporal adaptation techniques in machine learning-based scheduling knowledge acquisition.  The provided documents do not directly address machine learning-based scheduling or the explicit integration of spatial and temporal adaptation techniques within such systems.  However, they offer insights into related concepts such as spatial data analysis, knowledge acquisition in education, and the neural processing of spatial and temporal information which can be extrapolated to understand the potential role of these techniques in scheduling.  This report will analyze these indirect contributions.

**Body:**

The provided texts touch upon several areas relevant to understanding the potential application of spatial and temporal adaptation in machine learning for scheduling.  Document 2, ""The Effects of Spatial Autocorrelation in Spatial Data Analyses,"" highlights the challenges and complexities of handling spatial autocorrelation in Ordinary Least Squares (OLS) models.  This is crucial because scheduling problems often involve spatial considerations, such as the location of resources or tasks.  Understanding and mitigating spatial autocorrelation is fundamental to building accurate predictive models, essential for effective scheduling systems.  The document suggests that the standard errors of coefficients in spatial models are impacted by the spatial pattern of variables, correlation between exogenous variables, and parameter correlation within the model, thus influencing the accuracy of any machine learning based schedule predictions.

Document 3, ""Research on Spatial Association Based on Spatial Statistics,"" further elaborates on spatial statistical analysis techniques, including Moran's I and Geary's C, for mining spatial associations.  These methods could be incorporated into machine learning models to improve the scheduling process by identifying spatial relationships between tasks or resources. For example, if task A and task B are spatially proximate, efficient scheduling might prioritize sequencing them consecutively to minimize travel time or resource relocation.

Document 4, “What” versus “Where” in the audiovisual domain: An fMRI study, explores the neural mechanisms underlying the processing of spatial (“where”) and semantic (“what”) information.  The study’s findings on the involvement of specific brain regions (intraparietal sulcus and superior temporal sulcus) in processing location versus object recognition provide insights into how the brain handles both spatial and temporal aspects simultaneously.  This neural architecture could inform the design of machine learning models for scheduling, allowing for the integration of both spatial and temporal constraints.  For instance, a model could learn to prioritize tasks based not only on their deadlines (temporal) but also their spatial proximity to resources.


Document 1, ""What Counts as Knowledge and What Knowledge Counts in Early Childhood Education?"", focuses on knowledge acquisition in a pedagogical context. While not directly related to scheduling, it underscores the importance of understanding how different knowledge domains interact and influence each other.  In a machine learning-based scheduling system, ""knowing"" the spatial relationships between tasks and temporal constraints is crucial for generating efficient schedules.


Document 5, ""Indoor Spatial Awareness Project and Indoor Spatial Data Model,"" deals with the challenges of representing and managing indoor spatial data. This research highlights the importance of developing robust data models for representing spatial information.  In scheduling systems, a similar need exists for efficient representation of spatial data related to the locations of tasks, resources and personnel. The prism model presented here offers an approach towards creating a 3D representation of the spatial data needed for creating intelligent scheduling algorithms.

**Conclusion:**

While none of the provided documents directly address the integration of spatial and temporal adaptation techniques within machine learning-based scheduling knowledge acquisition, they offer valuable insights into the constituent components.  The research on spatial autocorrelation, spatial statistics, neural processing of spatial and temporal information, and the development of spatial data models collectively suggests the potential benefits and challenges of incorporating these adaptation techniques.  These studies highlight the need for sophisticated techniques to handle spatial autocorrelation in data, the value of incorporating spatial association knowledge into models, and the importance of developing robust representations of spatial data.  Future research should explore how these insights can be translated into effective machine learning models for scheduling, leading to more efficient and intelligent scheduling systems.",What Counts as Knowledge and What Knowledge Counts in Early Childhood Education?,The Effects of Spatial Autocorrelation in Spatial Data Analyses,Research on Spatial Association Based on Spatial Statistics,“What” versus “Where” in the audiovisual domain: An fMRI study,Indoor Spatial Awareness Project andIndoor Spatial Data Model,Temporal rejuvenation,[Infrared temporal thermometry],“What-If-Not”전략을 적용한 문제 제기 활동이 학생들의 수학적 태도에 미치는 영향 : 중학교 2학년 ‘도형’ 단원을 중심으로,"POLITICAL CHANGES IN NORTH KOREA: WHAT IS IT, WHAT HAS HAPPENED AND WHAT TO EXPECT?","Nephrotic syndrome: what’s new, what’s hot?","Active Core 운동이 초등학생의 척추형태, 밸런스 및 기능적 움직임의 효과 분석",유소년 축구 선수들의 코어 안정성과 방향 전환 동작과의 상관 관계,"체간 안정화 복합 운동이 전방십자인대 재건술 후 무릎근력 및 안정성에 미치는 영향 : Effect of Core Stability Combined Rehabilitation on Muscle Strength, Stability of Knee Joint after ACL Reconstruction",Analysis of the Value of Celebrity Affiliation to Nonprofit Contributions,Social security contributions: Economic and public finance considerations,Spatial Econometric Analysis of Korea’s Official  Development Assistance Allocation Using Error  Corrected Spatial Lag and Spatial Error Models,"Spatial Externalities, Spatial Multipliers, And Spatial Econometrics",Unbounded Spatial Data Stream Query Processing using Spatial Semijoins,The temporal periosteum: anatomical study and surgical implications.,Temporal intuitionistic fuzzy pairs,Consumer Confidence and Economic Activity: What Causes What?,Magnetoelectric Properties of CoFe2O4-BaTiO3 Core-Shell Structure Composites,Author contributions can be clarified,항목 발생 간격을 고려한 Temporal 연관규칙,[Temporal lift].,New Contributions,New contributions,"Computational approaches to interface design : what works, what doesn't, what should and what might",고장 감내를 갖는 Core Based Tree,Appreciation of Invisible Intellectual Contributions,Appreciation of Invisible Intellectual Contributions,Appreciation of Invisible Intellectual Contributions,SPATIAL TRENDS AND SPATIAL EXTREMES IN SOUTH KOREAN OZONE,[Osteomyelitis of the temporal bone.],HEVC에 대한 Core transform,다단계 보안 공간 데이터베이스를 위한 공간 다중인스턴스화,시.공간분석을 위한 GIS기법의 시간 지도 구현에 관한 연구 - 안양시틀 사례로 -,예비교사 교육에서 If-Not-What-Yes와 What-If-For를 통한 반례 생성과 명제의 정교화,What life? What cycle?,What Process For What Part?,풋 코어 시스템 패러다임을 적용한 숏풋 운동이 뇌졸중 환자에 미치는 임상적 연구,레진의 종류에 따른 Glass fiber post와 Core의 파절,Organic/organic Core Shell 바인더의 중합과 처리영향,Contributions,Late Contributions,Spatial MongoDB를 위한 공간 연산자,Arteritis temporal.,Arterite temporal.,몸통안정화운동이 코어근육의 근활성도와 근두께 및 균형에 미치는 영향,공간 데이터 웨어하우스에서 공간 분석을 위한 공간 집계연산
How does the audiovisual speech recognition approach integrate hidden Markov models and neural networks to achieve robustness in noisy environments?,"##Audiovisual Speech Recognition Approach## ##Introduction## Audiovisual speech recognition leverages both acoustic signals and visual cues from lip movements to overcome the severe performance drop of conventional audio‐only systems in noisy environments. By treating visual information as a noise‐immune complement to audio, the approach is partitioned into three core components—visual recognition, auditory modeling, and multimodal fusion—to enhance overall robustness. ##Main Body## First, the visual subsystem refines hidden Markov models (HMMs) through a hybrid probabilistic optimization algorithm. It integrates simulated annealing with local search operators to escape local maxima of the likelihood function, ensuring a more global exploration of HMM parameters and faster convergence for modeling lip‐movement sequences. Second, the auditory subsystem extends standard HMMs by explicitly modeling inter‐frame correlations within the speech signal. Instead of treating frames independently, a Gaussian mixture framework captures joint distributions of consecutive feature vectors, and a tailored expectation–maximization procedure estimates parameters that better reflect temporal dependencies, thereby improving noise resilience. Third, the fusion stage employs a neural network that learns to weight the outputs of audio‐only and visual‐only recognizers. Trained on mixed‐noise data without prior noise‐level knowledge, this network dynamically adjusts modality weights to maximize recognition accuracy, producing results that consistently match or exceed the best single‐modality output and exploit cross‐modal synergy. ##Conclusion## By combining globally optimized HMMs for visual processing, inter‐frame‐aware acoustic models, and adaptive neural‐network–based fusion, the audiovisual system achieves robust speech recognition under diverse and unknown noise conditions. This tri-part integration harnesses the complementary strengths of auditory and visual modalities, resulting in significant and reliable performance gains in noisy environments.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",43,1.1859924140007934,"**Title:**  The Role of Hidden Markov Models and Neural Networks in Robust Audiovisual Speech Recognition

**Introduction:** This report addresses the integration of Hidden Markov Models (HMMs) and neural networks in achieving robustness in audiovisual speech recognition (AV-ASR) systems, specifically focusing on how these models contribute to performance in noisy environments.  The analysis draws upon information provided in the supplied research papers.

**Body:**  Document 1, ""Aligning Audiovisual Features for Audiovisual Speech Recognition,"" directly addresses the use of HMMs in the context of AV-ASR.  The study explores the fusion of acoustic and visual features using an alignment neural network (AliNN) and compares the performance of the resulting system with both Gaussian Mixture Model-Hidden Markov Model (GMM-HMM) and Deep Neural Network-Hidden Markov Model (DNN-HMM) back-end systems.  The results demonstrate a significant performance improvement (24.9% with GMM-HMM and 2.4% with DNN-HMM) compared to a baseline system, highlighting the effectiveness of the AliNN front-end in improving the accuracy of the HMM-based back-end. This improvement is particularly significant in the context of noisy recordings and mismatched channel conditions.  The AliNN learns the alignment between audio and visual features, thereby addressing limitations of previous pre-processing methods which oversimplified the phase difference between lip motion and speech.  While the focus is on improving alignment rather than directly improving noise robustness of the HMM, the improved alignment directly contributes to overall system robustness in noisy conditions.  The paper suggests that the combination of a neural network for feature alignment and HMM-based models for speech recognition improves performance compared to using only HMMs.

The other provided documents do not directly address the integration of HMMs and neural networks for noise robustness in *audiovisual* speech recognition.  Document 2 focuses on multilingual text recognition using neural networks, but in the context of handwriting recognition, not speech. Document 3 investigates the relationship between neural entrainment and speech intelligibility through brain stimulation, but doesn't involve HMMs or traditional ASR architectures.  Document 4 discusses adaptive service access in pervasive computing environments, which is unrelated to speech recognition. Finally, Document 5 details real-time audiovisual rendering techniques, focusing on the visual and audio aspects of virtual environments rather than speech processing.


**Conclusion:** Document 1 demonstrates the successful integration of HMMs and neural networks within an AV-ASR system.  The alignment neural network (AliNN) significantly improves the performance of both GMM-HMM and DNN-HMM back-end systems, suggesting that the synergistic combination of neural networks for feature alignment and HMM-based acoustic modeling contributes to enhanced robustness, particularly in challenging auditory conditions such as noise. The other documents, while relevant to different aspects of audio and visual processing or neural networks, do not provide information pertaining to the specific question of HMM and neural network integration for noise robustness in audiovisual speech recognition.",Aligning Audiovisual Features for Audiovisual Speech Recognition,MuLTReNets: Multilingual text recognition networks for simultaneous script identification and handwriting recognition,Neural Entrainment to Speech Modulates Speech Intelligibility,How the 'What' Becomes the 'How',Realtime audiovisual rendering and contemporary audiovisual art,Pairwise Markov trees,Triplet Markov Chains,Impacts of machine translation and speech synthesis on speech-to-speech translation,Free speech or obedient speech? Revisiting liberal speech norms in ‘closed contexts’,잡음음성인식을 위한 음성개선 방식들의 성능 비교,"Regionalism in the Asia-Pacific Region: How Wide, How Deep?",Markov chains and applications,Markov Process를 활용한 시스템 가용도 분석 연구,La ense&ntilde;anza del lenguaje audiovisual: Proyectos finales de la Licenciatura en Producci&oacute;n y Realizaci&oacute;n Audiovisual 2007-2017,Autoetnograf&iacute;a Espont&aacute;nea Audiovisual en TikTok,Reduced audiovisual recalibration in the elderly,Positive Emotion Facilitates Audiovisual Binding,동시발화에 나타나는 발화 속도 변이 분석,Modulation of Auditory Responses to Speech vs. Nonspeech Stimuli during Speech Movement Planning,Playful recognition: Television comedy and the politics of mediated recognition,Brand Placement Recognition,Face Recognition:Biomimetic Pattern Recognition vs. Traditional Pattern Recognition,Visualizing lymphocyte recognition,Mainstream economics and economic crises: how responsible? how reformable?,25 Years of HOW: A Celebration of Language Teaching and Learning,How do we know how?,Markov Functionals of an Ergodic Markov Process,식도발성 남성 발화의 말 속도,Comparison of Speech Rate and Long-Term Average Speech Spectrum between Korean Clear Speech and Conversational Speech,Interactions between speech coders and disordered speech,Text recognition from images,Mosaicing-by-recognition for video-based text recognition,Specific hemoglobin (poly)saccharide recognition,Face Recognition Using a Facial Recognition System,"Audiovisual Programmes:The Audiovisual Centre, University of London","The Procedural Syllabus and the Task Syllabus: How Similar, How Different?",非正規 有限 Markov 過程의 Ergodic 行態分析,Entrevista: El audiovisual superheroico,Transport aircraft requirements - How much? How soon? How to pay?,HOW TO CHEAT,Science in space- How pure - How pragmatic,비정상성 Markov Chain Model을 이용한 통계학적 Downscaling 기법 개발,AF궤도회로의 신뢰성 예측 및 Markov Model을 이용한 고장모드 분석,[Daniil Aleksandrovich Markov],An undergraduate rootkit research project : How available? How hard? How dangerous?,개인화된 방송 컨텐츠 추천을 위한 가중치 적용 Markov 모델,Lenguaje audiovisual y manipulaci&oacute;n,Dimensi&oacute;n Audiovisual del Idioma,Speech cues를 이용한 반복훈련이 뇌성마비 아동의 자음정확도 및 말명료도에 미치는 영향: 단일대상연구,"Recognition, Recognition, Recognition"
What is the essence of applying various machine and deep learning approaches to pharmacogenomics research for antidepressant treatment prediction?,"##Harnessing Machine and Deep Learning in Pharmacogenomics for Antidepressant Response## ##Introduction## Personalizing antidepressant therapy in major depressive disorder relies on identifying genetic and biological markers that predict treatment success. The convergence of machine learning (ML), deep learning (DL), neuroimaging, and multi-omics data has emerged as a transformative approach to uncover the complex patterns driving individual drug response. ##Main Body## Researchers apply a variety of ML algorithms—such as random forests, support vector machines, and neural networks—alongside DL architectures to integrate genomic variants, transcriptomic profiles, and imaging-derived features. These models have successfully predicted patient outcomes, highlighted potential biomarkers, and enhanced patient stratification for specific antidepressants. Neuroimaging pharmacogenomics extends this work by correlating brain activity signatures with genetic data, boosting prediction performance and shedding light on underlying biological mechanisms. However, standardizing heterogeneous datasets, ensuring model interpretability, and overcoming limited sample sizes remain key challenges for broad clinical adoption. ##Conclusion## By melding ML and DL techniques with comprehensive multi-omics and neuroimaging datasets, researchers are forging a path toward more accurate antidepressant response predictions and biomarker discovery. Ongoing improvements in data harmonization and algorithm transparency will further enable truly personalized treatment strategies for patients with depression.",없음,없음,"Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",44,1.1859924140007934,"**Title:** The Applicability of Machine and Deep Learning to Pharmacogenomics Research for Antidepressant Treatment Prediction: A Gap Analysis

**Introduction:**

This report addresses the essence of applying various machine and deep learning approaches to pharmacogenomics research for antidepressant treatment prediction.  The provided documents do not directly address this specific application. However, by analyzing the included papers on machine learning, data analysis, and related fields, we can extrapolate the potential and limitations of such an approach.

**Body:**

The application of machine learning to large datasets (""Machine learning on Big Data""[2]) is highlighted as a key driver of modern science and commerce.  The potential for ""tera-scale learning"" and very large neural networks suggests that scale is crucial for quality modeling [2].  This is directly relevant to pharmacogenomics, where vast datasets of genomic information, patient characteristics, and treatment responses could be leveraged.

Document [5], ""Analysis of Various COVID-19 Prediction Techniques,"" details the common steps in prediction techniques: dataset collection, preprocessing, feature extraction, and classification.  These steps are directly transferable to pharmacogenomics research for antidepressant prediction.  Genetic information, patient history, lifestyle factors, and treatment outcomes would serve as the data, requiring careful preprocessing and feature extraction to create a suitable dataset for machine learning algorithms.  The choice of classification algorithm would depend on the specific goals of the prediction (e.g., predicting treatment efficacy, side effects, or optimal dosage).

While none of the provided documents directly address the application of machine learning to *antidepressant* treatment prediction, Document [4], ""Scene Essence,"" demonstrates the power of applying a learnable graph neural network (GNN) to analyze complex relationships within data.  This approach, which focuses on identifying ""essential"" elements within a complex system, could be adapted for pharmacogenomics.  A GNN could model the intricate interactions between genes, proteins, and environmental factors influencing antidepressant response, allowing for more accurate prediction than simpler methods.

A crucial factor, as highlighted in Document [3], ""Adaptive Identity-Based Signcryption for Dynamic Source Routing in Machine to Machine Networks,"" is security.  Protecting patient data privacy is paramount in any pharmacogenomics research.  Secure data handling and robust anonymization techniques are crucial for ethically responsible research.

Document [1], ""Research for Applying Sprinkle to the Windy and Sandy Regions of Arid and Semi-arid Area,"" is not directly relevant to the question but implicitly underscores the importance of understanding environmental factors in the success of an application.  Similarly, the success of applying machine learning to antidepressant treatment prediction will depend on carefully considering and accounting for confounding variables and the complex interplay of genetic and environmental influences.

**Conclusion:**

While the provided documents do not directly detail the application of machine and deep learning to pharmacogenomics for antidepressant treatment prediction, they strongly suggest its feasibility and potential.  The principles of large-scale data analysis, feature extraction, classification techniques, and the use of advanced neural network architectures like GNNs are all directly applicable.  The success of such an approach hinges on careful data curation, consideration of confounding factors, robust security measures to protect patient data, and the selection of appropriate machine learning algorithms for the specific prediction goals.  Further research is needed to refine these methods within this specific context.",Research for Applying Sprinkle to the Windy and Sandy Regions of Arid and Semi-arid Area,Machine learning on Big Data,Adaptive Identity-Based Signcryption for Dynamic Source Routing in Machine to Machine Networks,Scene Essence,Analysis of Various COVID-19 Prediction Techniques,“What” versus “Where” in the audiovisual domain: An fMRI study,Porous Alumina Templates with Various Shaped Nanochannels,“What-If-Not”전략을 적용한 문제 제기 활동이 학생들의 수학적 태도에 미치는 영향 : 중학교 2학년 ‘도형’ 단원을 중심으로,"POLITICAL CHANGES IN NORTH KOREA: WHAT IS IT, WHAT HAS HAPPENED AND WHAT TO EXPECT?","Nephrotic syndrome: what’s new, what’s hot?",What Counts as Knowledge and What Knowledge Counts in Early Childhood Education?,Managerial Competencies for Various Management Levels,Control of milling machine cutting force using artificial Neural Networks,Concurrent Support Vector Machine 프로세서,Four-square sprocket test machine,Consumer Confidence and Economic Activity: What Causes What?,The Essence of Rape,Immunologic Essence of Deficiency Syndromes,Preparation of Chitosan Microcapsules of Essence,Essence et fondation,Applying ergonomics,Applying Paste Bandages,Applying of USB interface technique in nuclear spectrum acquisition system,Altering and applying predicates,APPLYING POWDER COATINGS,Gastroenterologists attitude in various clinical settings in the era of COVID-19 pandemic : An online Uni-National Israeli Survey,Craniospinal Neurenteric Cysts: Various MR Imaging Features,Various Quantum Ring Structures: Similarity and diversity,Machine learning and 3D-QSAR studies of A₃ adenosine receptor modulators,Microencapsulated Essence in Glassy State,Y a-t-il une essence de la m&eacute;decine?,Applying of C8051F020 MCU in nuclear spectrum acquisition system,Manganese Metallamacrocycles with Various Coordination Solvents,Machine learning and docking studies of cytochrome P450 ligands,Grinding Process Achievements and their Consequences on Machine Tools Challenges and Opportunities,"Computational approaches to interface design : what works, what doesn't, what should and what might",공간과 시간적 적응을 통한 스케줄링 지식의 기계학습에 관한 연구,The Essence of Essence,Breeding and Applying of New Earliest-maturity Waxy Maize Variety Kenian No. 1,예비교사 교육에서 If-Not-What-Yes와 What-If-For를 통한 반례 생성과 명제의 정교화,What Process For What Part?,Essence of Schubert?,INVESTIGATION OF CONVERSION VARIOUS ILIDENMALONONITRILES,Various advertisements,What life? What cycle?,L'essence du soin.,Applying,Improve Electricity Efficiency by Applying TRIZ,Various,"시청각 음성인식 : 은닉 마르코프 모델의 확률적 최적화, 프레임간 상관관계의 모델링 및 신경회로망을 이용한 통합"
"Laplacian 변형 나이브 베이즈, 의사결정나무, 서포트 벡터 머신을 활용한 A₃ 아데노신 수용체 조절제 연구의 핵심 성과를 간결하게 정리해 주실 수 있나요?","##제목## A₃ 아데노신 수용체 조절제 연구의 기계학습 및 3D-QSAR 모델 ##서론## A₃ 아데노신 수용체(A₃ AR)는 다양한 질환 치료 타깃으로 부상한 GPCR 계열이며, 효능제와 길항제의 발굴을 위해 초기 단계에서 후보 물질의 활성을 정확히 예측하는 기법이 필요하다. ##본론## - 라플라시안 변형 나이브 베이즈, 의사결정나무, 서포트 벡터 머신 세 가지 기계학습 기법을 적용해 분류 모델을 구축하였고, 정확도·민감도·특이도가 모두 90% 이상, AUC와 MCC 역시 0.9 이상으로 우수한 성능을 확인했다. - 효능제(agonist)와 길항제(antagonist) 각각에 대해 CoMFA와 CoMSIA 기반 3차원 정량적 구조-활성관계(3D-QSAR) 모델을 개발하여, 교차검증 q²는 효능제에서 0.594(CoMFA)·0.560(CoMSIA), 길항제에서 0.726·0.665, 결정계수 r²는 효능제에서 0.937·0.907, 길항제에서 0.913·0.915로 높은 예측력을 달성했으며 테스트 세트에서도 모두 0.73 이상을 기록했다. - 두 모델 분석을 통해 A₃ AR 작용제·길항제 분류에서 5′-아마이드 위치 수소 결합 공여자 유무가 핵심적인 활성 결정 인자로 작용함을 규명했다. ##결론## 제안된 기계학습 기반 분류기 및 3D-QSAR 모델은 A₃ 아데노신 수용체 조절제의 후보 물질 선별과 신약개발 연구에 실질적인 가이드를 제공할 수 있을 것으로 기대된다.","Can you briefly summarize the core achievements of A₃ adenosine receptor regulator studies using LAPLACIAN deformed Nive Bayes, decision -making trees, and support vector machines?","##title## Machine learning and 3D-QSAAR model of A₃ adenosine receptor regulator study ##introduction## A₃ adenosine receptor (A₃ AR) is a GPCR series that has emerged as a target for treating various diseases, and requires an technique to accurately predict the activity of the candidate material at the initial stage for the discovery of efficacy and antagonists. ## Main ## -The classification model was established by applying three machine learning techniques: La Plazian deformation, nive, and support vector machines, and more than 90% of accuracy, sensitivity, and specificity, and AUC and MCC also confirmed excellent performance of 0.9 or more. -The developed a comfa and comsia-based three-dimensional quantitative structure-active relationship (3D-QSAAR) for each efficacy agonist and antagonist, and the cross-verification Q² is 0.594 (Comfa), 0.560 (COMSIA), and Gil antagonism. 0.726 · 0.665, the crystal coefficient R² achieved high predictions with 0.937 · 0.907 in the efficacy, 0.913 · 0.915 in the antagonist, and more than 0.73 in the test set. -The analysis of the two models identified the A₃ AR agonist and antagonist classification that the 5'-amide position hydrogen bond donor acts as a key activity determinant. ##conclusion## The proposed machine learning-based classifiers and 3D-QSAR models are expected to provide practical guides in selecting candidate materials and researching new drug development of A₃ adenosine receptor regulator.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",45,1.1859924140007934,"**제목:** 제공된 문헌을 통한 A₃ 아데노신 수용체 조절제 연구 핵심 성과 분석 불가능 보고서

**서론:**

본 보고서는 Laplacian 변형 나이브 베이즈, 의사결정나무, 서포트 벡터 머신을 활용한 A₃ 아데노신 수용체 조절제 연구의 핵심 성과를 분석하고자 합니다.  하지만 제공된 참고문서 1, 2, 3, 4, 5는 철도차량 충격흡수장치 성능 예측, 모로코 이마지겐 관습법, 비강체 충돌 감지 및 변형 모델링, 괴테의 시 '식물의 변형'에 대한 해석, 그리고 하지 변형에 따른 하지 관절 가동범위 분석에 관한 내용을 담고 있습니다.  제공된 문서 어디에도 A₃ 아데노신 수용체 조절제 연구, Laplacian 변형 나이브 베이즈, 의사결정나무, 서포트 벡터 머신과 관련된 내용은 포함되어 있지 않습니다.


**본론:**

제공된 문서들은 서로 다른 학문 분야를 다루고 있으며, 원본 질문에서 언급된 연구 주제와는 전혀 관련이 없습니다. 따라서 원본 질문에 대한 답변을 제공할 수 없습니다.  각 문서의 핵심 내용은 다음과 같습니다.

* **문서 1:** 철도차량 충격흡수장치(변형튜브)의 성능 예측을 위해 유한요소 해석(ABAQUS)을 사용한 연구 결과를 제시합니다.  변형튜브의 두께 및 펀치 접촉각이 반력에 미치는 영향을 분석하였습니다.

* **문서 2:** 모로코 자이얀 부족의 이마지겐 관습법(Izlef) 체계에 대한 현장 조사 및 문헌 연구를 기반으로 한 분석입니다.  부족의 사회구조와 관습법의 내용을 설명합니다.

* **문서 3:** 비강체의 충돌 감지 및 변형 모델링에 대한 연구로, 모조객체를 이용한 효율적인 충돌 감지 방법과 매스 댐퍼 스프링 시스템 기반의 변형 모델을 제시합니다.

* **문서 4:** 괴테의 시 ""식물의 변형""을 칸트 철학과 비교 분석하여, 괴테의 경험과 이념에 대한 통합적 시각을 제시합니다.

* **문서 5:** 하지 변형(Q각, 경골염전, 대퇴염전)에 따른 하지 관절 가동범위의 차이를 분석한 연구 결과입니다.  일원변량분석을 통해 각 변형이 관절 가동범위에 미치는 영향을 통계적으로 검증합니다.


**결론:**

제공된 참고문헌에는 원본 질문에서 요구하는 A₃ 아데노신 수용체 조절제 연구와 관련된 정보가 전혀 포함되어 있지 않습니다. 따라서 Laplacian 변형 나이브 베이즈, 의사결정나무, 서포트 벡터 머신을 활용한 해당 연구의 핵심 성과를 요약할 수 없습니다.  질문에 답변하기 위해서는 A₃ 아데노신 수용체 조절제 연구에 대한 관련 문헌이 필요합니다.",초등해법과 유한요소 해석을 이용한 철도차량 변형튜브 성능예측에 관한 연구,모로코 이마지겐 이즈레프 체계 연구 -자이얀 이즈레프를 중심으로-,비강체에 대한 충돌 감지 및 변형 모델링,괴테의 시 「식물의 변형」을 통해서 본 경험과 이념,하지변형에 따른 하지관절 가동범위에 관한 분석,유전자변형 식품의 위험인지와 위험수용성에 관한 연구 : 전문가와 일반인의 시각차이를 중심으로,c-JunAA 유전자 변형 생쥐에서의 학습 및 기본 행동학적 특성 검색,㈜이즈텍,국내외 유전자변형 식물개발의 연구동향 분석,유전자변형 비타민 A 강화쌀의 영양성분 및 이화학적 특성,유전자변형 고추와 수박에서 특정단백질 분석,이브 생 로랑 디자인 연구,쇼팽 &lt;폴로네이즈 Op.44&gt; 분석 연구,부정적 정서와 외부압력 및 자기의식이 여대생의 신체변형장애 성향에 미치는 영향,이브-닝,"모두다 외쳐봐! ‘알 이즈 웰, 알 이즈 웰.’",트리스탄과 이즈-감성과 운명,외국 국립공원 기행(하)-일본후지. 하꼬네. 이즈,건축단상 : 레스 이즈 모어? ( Less is more ? ),"紡績技術 시리이즈, 13","紡績技術 시리이즈, 12 : 연소","캬트린느 브레이야의 〈팻걸〉, 〈섹스 이즈 코메디〉에 나타난 여성과 균열",퀴어 이론가 - 이브 코소프스키 세즈??,이브 클렝의 모노크롬에서 제시된 '비물질성',이브 생 로랑에 관한 ICT 학습 자료 개발,이브를 어떻게 볼 것인가?,이브를 어떻게 볼 것인가?,책갈피산책 - '이브 바투타 여행기(전2권)',프로젝트 리포트 : 어반하이브,"장 이브 보리오 著, 박명숙 譯,『로마의 역사』 궁리, 2007.",,,,,,,,,,,,,,,,,,,,
지식 기반 스케줄링에서 공간적·시간적 적응을 구현하는 기계학습 방법들의 주요 특징을 요약해 주실 수 있나요?,"##제목## 지식 기반 스케줄링에서 공간적·시간적 적응 기계학습 방법의 주요 특징 ##서론## 지식 기반 스케줄링 시스템은 생산 시스템의 동적 상태에 맞춰 작업배정 규칙을 선정하기 위해 기계학습 기법을 활용한다. 기존 연구가 주로 시간적응(temporal adaptation)에 집중해 온 반면, 본 연구는 기계 간 상호작용을 고려하는 공간적용(spatial adaptation)과 이를 시간적응과 융합한 공간-시간적응(spatial-temporal adaptation)을 구현하는 두 가지 방법을 제안한다. ##본론## 첫 번째 방법은 다구치(Taguchi) 실험계획법을 통해 단계별로 각 기계의 최적 작업배정 규칙을 체계적으로 획득하는 방식이다. 반도체 일관가공공정과 연료전송장치 제조시스템에 적용해 휴리스틱 규칙 대비 높은 수행도와 강건성을 확인하였으며, 공간-시간적용으로 확장 시 시스템 상태 변동에 적응한 더욱 향상된 전략을 도출했다. 두 번째 방법은 공진화 유전자 알고리듬(coevolutionary genetic algorithm)을 이용해 각 기계의 규칙 후보 집단을 동시 진화시키며 학습 시간을 단축하고 유연한 전략을 생성하는 기법이다. 개체 적합도 평가는 0계 성능(기존 수행도)과 1계 성능(첫 번째 변화에 대한 기여도)의 함수로 정의하여 심한 변동과 파동효과를 완화하였고, 태그치 방법 대비 빠른 수렴과 양질의 해를 도출함을 실험적으로 입증했다. ##결론## 다구치 실험계획법은 안정적이고 해석 가능한 규칙 조합을 제공하여 전문가 교육에 유리하며, 공진화 유전자 알고리듬은 학습 속도와 유연성 면에서 우수한 성능을 보인다. 두 접근 방식 모두 공간적·시간적응을 통해 생산성 향상에 기여할 수 있는 효과적인 기계학습 기반 지식획득 방안임을 확인하였다.",Can you summarize the main features of machine learning methods that realize spatial and time adaptation in knowledge -based scheduling?,"##title## Main features of spatial and time adaptive machine learning methods in knowledge -based scheduling ##introduction## The knowledge -based scheduling system utilizes machine learning techniques to select a task assignment rules according to the dynamic status of the production system. While existing studies have mainly focused on temporal adaptation, this study suggests two methods that implement spatial adaptation and space-time adaptation and time adaptation that considers the interaction between machines. ## Main ## The first method is to systematically obtain the optimal work assignment rules of each machine in step through the Taguchi Experimental Planning Act. The semiconductor consistency was applied to public and fuel transmission system manufacturing systems to confirm higher performance and strength compared to the Hurricial rules. The second method is a technique for simultaneous evolution of the rules candidate groups of each machine using the CoEVOLUTIONARY Genetic Algorithm, shortening the learning time and creating a flexible strategy. The individual suitability evaluation was defined as a function of 0 -based performance (existing performance) and one -stage performance (contribution to the first change) to alleviate severe fluctuations and wave effects, and demonstrated experimental harm compared to tagging methods. ##conclusion## The Taguchi Experimental Planning Act is advantageous for professional education by providing a stable and interpretable rules combination, and the resonating genetic algorithm is excellent in terms of learning speed and flexibility. Both approaches were confirmed that it was an effective way to acquire knowledge -based knowledge -based knowledge that can contribute to productivity improvement through spatial and time adaptation.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",46,1.1859924140007934,"**제목:** 지식 기반 스케줄링의 공간적·시간적 적응: 기계학습 방법 적용 불가능성 분석

**서론:**

본 보고서는 제공된 학술문서들을 바탕으로 지식 기반 스케줄링에서 공간적·시간적 적응을 구현하는 기계학습 방법들의 주요 특징을 분석합니다.  제공된 문서들은 다양한 분야의 지식 관리 및 시스템 운영에 대한 연구를 다루고 있으나,  기계학습을 이용한 지식 기반 스케줄링의 공간적·시간적 적응에 대한 직접적인 정보는 포함하고 있지 않습니다. 따라서 본 보고서는 제공된 자료만으로 질문에 대한 직접적인 답변을 제공할 수 없으며, 자료의 한계를 명시하고, 해당 주제에 대한 연구의 부재를 지적합니다.

**본론:**

제공된 다섯 개의 문서는 지식 관리 시스템(KMS)의 요건 [문서 2], 영아 보육 교사의 전문성 인식과 발달 지식의 관계 [문서 1], 인공지능 기반 대화형 인터랙션의 사용자 경험 [문서 3], 사례 기반 이러닝 프로그램의 효과 [문서 4], 그리고 클라우드 환경에서의 단일 자원 스케줄링 [문서 5]에 관한 연구를 다룹니다.  이들 연구는 모두 특정 시스템 또는 과정의 효율성 향상을 목표로 하지만,  기계학습을 이용한 지식 기반 스케줄링의 공간적·시간적 적응에 대해서는 논의하지 않습니다.

문서 2는 KMS 구축을 위한 요건을 제시하며, 관리, 기술, 조직, 프로세스, 정보 기술 등 다섯 가지 요소를 강조합니다.  하지만 이는 지식의 활용과 관리에 관한 것이지,  스케줄링 알고리즘이나 기계학습의 적용에 대한 내용은 포함하지 않습니다. 문서 5에서는 클라우드 환경에서의 자원 스케줄링 문제를 다루며, 기존의 단일 자원 스케줄링의 한계를 지적하고 새로운 기법의 필요성을 강조하지만,  기계학습 기반의 공간적·시간적 적응 방식에 대한 구체적인 설명은 없습니다.  나머지 문서들 역시 스케줄링 알고리즘이나 기계학습과는 직접적인 관련이 없습니다.


따라서 제공된 문서만으로는 지식 기반 스케줄링에서 공간적·시간적 적응을 구현하는 기계학습 방법들의 주요 특징을 요약할 수 없습니다.  문서들은 지식 관리, 사용자 경험, 교육 효과, 자원 스케줄링 등 다양한 주제를 다루지만,  질문에서 요구하는 기계학습 기반의 지식 기반 스케줄링에 대한 정보는 포함하고 있지 않습니다.


**결론:**

제공된 문서들은 지식 관리와 시스템 효율 향상에 관한 다양한 연구 결과를 제시하지만, 지식 기반 스케줄링에서의 공간적·시간적 적응을 위한 기계학습 방법에 대한 정보는 포함하고 있지 않습니다. 따라서 본 보고서는 질문에 대한 답변을 제공할 수 없습니다.  해당 주제에 대한 심층적인 이해를 위해서는 관련 분야의 추가적인 연구 자료가 필요합니다.",영아반 보육교사의 영아발달지식이 전문성 인식에 미치는 영향,지식관리시스템 요건에 관한 탐색적 연구 : S사 지식관리시스템 중심으로,인공지능 기반 대화형 인터랙션에 대한 사용자 경험 연구,사례기반 애니메이션을 활용한 간호사 대상 근거기반간호 임상질문 이러닝 프로그램 개발 및 효과,클라우드 환경에서 단일 자원 스케줄링 연구,딥러닝 기반 범죄자 신원 인식 시스템 설계 및 구현,마인크래프트를 활용한 게임기반학습 프로그램 개발 및 적용,지식 커뮤니티 컨텐츠 성공 요소 분석,사용자 키워드 의미해석을 위한 온톨로지 지식 베이스 프레임워크,지식산업센터의 공간구성과 집적이익 효과,지식산업센터 지원시설 규모의 적정성 분석 : 경기도 지식산업센터를 중심으로,흡연에 대한 지식수준이 흡연 행태에 미치는 영향,유전자 알고리즘을 활용한 철도 선로배분 모델링 연구,MIMO 링크 스케줄링 최적화,실시간 스케줄링,자원인자 기반 스케줄링 프레임워크,델파이와 AHP 기법을 활용한 이러닝 기반 교원연수 프로그램 평가 모형 개발 연구,모바일 인터넷 기반 농기계 관리진단 시스템의 구현,간호대학생의 근거기반실무 역량에 영향을 미치는 요인,문법 기반 타일링을 이용한 텍스처와 개체 분포 생성,스마트 교육을 기반으로 한 융합형 가정과 프로그램 개발,"자궁경부암, 인유두종 바이러스(HPV)에 대한 성인 남성의 지식 및 백신 접종 의향",지식재산권 담보제도의 현황과 과제,노인요양병원 간호사의 욕창 지식 및 욕창 예방수행에 관한 연구,스케줄링 알고리즘 시뮬레이터의 설계 및 구현,개별공정 형태의 자동차 부품 제조시스템에 대한 생산 스케줄링 사례연구,효율적인 위성 임무 스케줄링 운영을 위한 스케줄링 최적화 알고리즘 비교 연구,네트워크 프로세서를 위한 다중 쓰레드 스케줄링,공감기반 학습모형 개발연구,밀리미터파 전 이중 시스템에서의 혼성 스케줄링,,,,,,,,,,,,,,,,,,,,
잡음 환경에서 시청각 음성인식의 인식률을 높이기 위해 은닉 마르코프 모델과 신경망 통합 전략이 어떻게 구성되었는지 간략히 설명해 주실 수 있나요?,"##제목## 시청각 음성인식 시스템의 은닉 마르코프 모델 최적화 및 신경망 기반 통합 전략 ##서론## 소음이 심한 환경에서는 음성신호만으로는 인식 성능이 크게 저하되기 때문에, 입술 움직임 등의 시각정보를 함께 활용하는 시청각 음성인식이 주목받고 있다. 본 시스템은 청각·시각 정보를 각각 개선하고, 최종 단계에서 두 정보를 효과적으로 융합하여 잡음 환경에서의 강인한 인식률을 달성하고자 설계되었다. ##본론## 1. 시각 정보 인식을 위한 HMM 확률적 최적화 - 기존 EM(기대-최대) 학습 알고리즘이 지역 최적화에 머무르는 한계를 극복하기 위해, 모의 담금질 기법(simulated annealing)과 지역 탐색 연산자를 결합한 하이브리드 모의 담금질을 도입하였다. - 전역 탐색을 수행함으로써 은닉 마르코프 모델의 파라미터를 확률적으로 최적화하여 수렴 속도와 인식 성능을 동시에 향상시키며, 이 방법의 전역 최적해 수렴 특성을 수학적으로 증명하였다. 2. 청각 정보 인식을 위한 프레임 간 상관관계 모델링 - 음성 신호의 동적 특성을 반영하기 위해, 서로 다른 관측 프레임 간의 결합 확률 분포를 가우시안 혼합 모델로 모델링하였다. - 새로운 EM 기반 학습 알고리즘을 개발하여 프레임 간 조건부 의존성을 효과적으로 학습하고, 잡음 환경에서도 강인한 인식 성능을 확보하였다. 3. 신경회로망을 이용한 시청각 정보 통합 - 시각·청각 정보로부터 독립적으로 얻은 인식 결과를 통합하기 위해, 잡음 종류와 수준에 따라 최적 가중치를 출력할 수 있는 신경망 기반 가중치 학습 방식을 제안하였다. - 이 통합 단계에서 학습된 신경회로망은 단일 정보만을 사용할 때보다 동일하거나 우수한 인식률을 보이며, 두 정보 간 시너지 효과를 극대화한다. - 화자 독립 고립 단어 인식 실험 결과, 다양한 소음 환경에서 기존 시스템 대비 통합 인식 성능이 유의미하게 향상됨을 확인하였다. ##결론## 은닉 마르코프 모델의 확률적 전역 최적화, 프레임 간 상관관계 모델링, 그리고 신경망 기반 정보 융합의 세 가지 전략을 결합함으로써, 잡음이 심한 환경에서도 시청각 음성인식의 인식률을 크게 향상시킬 수 있음을 입증하였다.",Can you briefly explain how the hidden Marov model and the neural network integration strategy were organized to increase the recognition rate of audiovisual voice recognition in the noise environment?,"##title## Optimization of hidden Marcov model and neural network -based integration strategy ##introduction## In an environment where the noise is severe, the voice signal alone decreases the recognition performance, so the audio -voice recognition that utilizes visual information such as lips movements is attracting attention. This system is designed to improve the hearing and visual information, and to effectively combine the two information at the final stage to achieve strong recognition rate in the noise environment. ## Main ## 1. HMM probability optimization for visual information recognition -In order to overcome the limitations of the existing EM (expected-maximum) learning algorithm, we introduced hybrid mock quenching that combines mock quenching annealing and local search operators. -Increasing the parameters of the hidden Marcov model by performing global search, the convergence speed and recognition performance were improved at the same time, and the global optimal resolution convergence characteristics of this method were mathematically proved. 2. Modeling between frames for hearing information recognition -In order to reflect the dynamic characteristics of the voice signal, the combination probability distribution between different observation frames was modeled as a Gaussian mixed model. -The new EM -based learning algorithm has been developed to effectively learn conditional dependence between frames and secure strong recognition performance in noise. 3. Integrate audiovisual information using the neuropathy network -In order to integrate the results obtained independently from visual and hearing information, we proposed a neural network -based weight learning method that can output optimal weight according to the type and level of noise. -The neuropathy network learned in this integration stage shows the same or superior recognition rate than only a single information, and maximizes the synergy effect between the two information. As a result of the speaker independent isolation word recognition experiment, it was confirmed that the integrated recognition performance was significantly improved compared to the existing system in various noise environments. ##conclusion## By combining the three strategies of the probabilistic global optimization of the hidden Marcof model, the correlation between the frame, and the neural network -based information convergence, it proved to greatly improve the recognition rate of audiovisual voice recognition even in a noise environment.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",47,1.1859924140007934,"**제목: 참고문헌 분석을 통한 시청각 음성인식 향상 전략에 대한 보고서**

**서론:**

본 보고서는 제공된 학술문서 1~5를 바탕으로, 잡음 환경에서 시청각 음성인식의 인식률을 높이기 위해 은닉 마르코프 모델(Hidden Markov Model, HMM)과 신경망 통합 전략이 어떻게 구성되는지에 대한 질문에 답하고자 한다.  참고문헌들은 시청각 음성인식에 직접적으로 언급하고 있지는 않지만, 잡음 제거 기술에 대한 다양한 접근 방식을 제시하고 있으며, 이러한 기술들이 음성인식 시스템의 성능 향상에 기여할 수 있음을 시사한다. 따라서 본 보고서는 잡음 제거 기술을 중심으로 HMM 및 신경망과의 통합 가능성을 간접적으로 논의한다.


**본론:**

제공된 문서들은 시청각 음성인식에 대한 직접적인 언급은 없지만, 잡음 제거 알고리즘에 대한 심도있는 연구 결과들을 담고 있다.  문서 2, 3, 4, 5는 다양한 잡음(salt and pepper noise, AWGN, 복합 잡음 등) 제거를 위한 다양한 필터링 알고리즘을 제안하고 있다. 이러한 알고리즘들은 국부 마스크, 히스토그램, 가중치 필터, 메디안 필터, 엔트로피 등을 활용하여 잡음을 효과적으로 제거하고 PSNR(Peak Signal to Noise Ratio) 및 MSE(Mean Squared Error)를 통해 성능을 평가하고 있다.  이러한 잡음 제거 기술들은 시청각 음성인식 시스템의 전처리 단계에 적용될 수 있다.

잡음 제거 후의 음성 신호는 HMM 또는 신경망을 이용한 음성 인식 엔진에 입력된다. HMM은 음성 신호의 시간적 특성을 모델링하는 데 유용하며, 각 음소(phoneme) 또는 단어를 은닉 상태로, 관측된 음성 신호를 관측 변수로 하여 음성을 인식한다. 신경망, 특히 심층 신경망(DNN)은 HMM과 결합하여 더욱 정확한 음성 인식을 가능하게 한다. DNN은 음향 특징을 추출하고, 이를 HMM의 입력으로 사용하여 인식 성능을 향상시킨다.  잡음 제거 알고리즘을 통해 얻어진 깨끗한 음성 신호는 HMM과 DNN 기반 음성인식 시스템의 성능을 향상시키는 데 크게 기여한다.  즉, 문서 2~5에서 제시된 잡음 제거 기술은 HMM과 신경망을 이용한 음성 인식 시스템의 전처리 단계로 작용하여 최종 인식률을 높이는 데 중요한 역할을 수행할 수 있다.


**결론:**

제공된 문서들은 직접적으로 은닉 마르코프 모델과 신경망의 통합 전략을 다루지는 않지만,  다양한 잡음 제거 알고리즘을 통해 잡음 환경에서의 음성 신호 처리 기술을 제시한다. 이러한 잡음 제거 기술들은 HMM과 신경망 기반 음성 인식 시스템의 전처리 단계에서 적용되어 시청각 음성인식의 인식률 향상에 기여할 수 있다. 문서에서 제시된 다양한 필터링 기법들은 잡음을 효과적으로 제거하여  HMM 및 신경망의 성능을 극대화하는 데 중요한 역할을 수행한다. 따라서, 효과적인 잡음 제거는 HMM과 신경망을 통합한 시청각 음성인식 시스템의 핵심 구성 요소라 할 수 있다.","환경 문제, 시민지식 그리고 시민과학: 시민과학의 환경 문제 해결 가능성과 과제",복합잡음 환경에서 변형된 스위칭 필터를 이용한 잡음 제거,고밀도 잡음 환경에서 엔트로피를 이용한 잡음 제거 방법,복합 잡음 환경에서 공간적 특성을 고려한 잡음 제거,복합 잡음 환경에서 영상의 잡음 성분을 이용한 필터 알고리즘,시청각매체를 이용한 수술 전 교육이 자궁적출술 환자에게 미치는 영향,복합 잡음 제거를 위한 영상처리,단채널 MOSFET의 열잡음 모델링을 위한 잡음 파라메터의 분석과 추출방법,무잡음 화소를 이용한 진화적인 방법의 임펄스 잡음 필터링,결정적 잡음 모델을 이용한 효율적인 잡음음성 인식 접근 방법,환경 R&D의 사업화를 위한 정책연구,친환경자동차 산업 활성화를 위한 정책적 지원방안 연구,시청각 교육과 시청각 통신,시청각교육과 시청각 통신,시청각 교육과 시청각 통신,시청각 교육과 시청각 통신,시청각교육과 시청각 통신,시청각교육과 시청각 통신,에드가 데일의 시청각 교육 : Motion Pictures,에드가 데일의 시청각 교육 : Motion Pictures,Motion Pictures : ‘에드가데일’의 시청각 교육,Gadoxetic Acid 조영증강 자기공명영상에서 간세포암의 신호 대 잡음비와 대조도 대 잡음비의 변화 : Changes in the Signal- and Contrast-to-noise Ratios of Hepatocellular Carcinomas on Gadoxetic Acid-enhanced Dynamic MR Imaging,환경 정책이 환경 전과정 및 지속가능발전에 미치는 영향에 관한 연구,환경의식 향상에 효과적인 환경교육 방법에 관한 연구,환경영향평가 유형분류 및 저감방안 개선에 관한 연구,都市人工雜音,이러닝 학습환경이 이러닝 학습만족도에 미치는 영향 분석,저염해성 친환경 제설제 개발,친환경 자동차 보급에 관한 연구,환경안보 개념의 대두와 국제법의 대응,,,,,,,,,,,,,,,,,,,,
Particle Swarm Optimization을 이용해 퍼지 Extreme Learning Machine의 활성화 함수 파라미터를 최적화하는 기법의 핵심 원리를 요약해 주실 수 있나요?,"##제목## PSO 기반 퍼지 Extreme Learning Machine 활성화 함수 파라미터 최적화 기법 ##서론## Extreme Learning Machine(ELM)은 전형적인 신경망 대비 학습 속도가 매우 빠르지만, 활성화 함수 파라미터를 일괄 선정할 경우 성능이 제한될 수 있다. 여기에 전문가 언어 정보 표현에 유리한 퍼지 이론을 결합한 퍼지 ELM은 활성화 함수 설계의 자유도를 높이지만, 적절한 파라미터 탐색이 필요하다. 따라서 본 기법은 Particle Swarm Optimization(PSO)을 통해 퍼지 ELM의 활성화 함수 파라미터를 자동으로 최적화하고자 한다. ##본론## 먼저, 기존 시그모이드 함수 대신 퍼지 C-평균(Fuzzy C-Means) 클러스터링 알고리즘에서 도출한 활성화 레벨 함수를 사용하여 퍼지 ELM의 은닉층 출력을 정의한다. 다음으로, PSO 알고리즘을 적용하여 클러스터 중심과 퍼지 지수 등 활성화 함수의 핵심 파라미터를 탐색한다. PSO는 개체(입자)들의 군집 행동을 모방하여 전역 최적해로 빠르게 수렴하며, 반복 평가를 통해 최적의 파라미터 조합을 찾는다. 마지막으로, 다양한 머신러닝 데이터셋을 활용해 최적화 전후의 분류 성능 변화를 비교·검증한다. ##결론## PSO를 통한 활성화 함수 파라미터 자동 최적화는 퍼지 ELM의 분류 정확도와 일반화 성능을 모두 개선시키며, 반복적인 휴리스틱 설정 과정을 줄여 실용적인 모델 설계를 가능하게 한다.",없음,"##title## PSO -based fuzzy extreme learning machine activation function parameter optimization technique ##introduction## EXTREME Learning Machine (ELM) has a very fast learning speed compared to typical neural networks, but performance can be limited by selecting activation function parameters. In addition, Fuzzy ELM, which combines fuzzy theory advantageous for expert language information, increases the freedom of activation function design, but requires appropriate parameter search. Therefore, this technique intends to automatically optimize the activation function parameters of Fuzzy ELM through Particle Swarm Optimization (PSO). ## Main ## First, it defines the hinting layer of the fuzzy ELM using the activation level function derived from the Fuzzy C-MeanS clustering algorithm instead of the existing sigmoid function. Next, the PSO algorithm is applied to explore the core parameters of the activation function such as the cluster center and the fuzzy index. The PSO imitates the clustering behavior of the individuals (particles) and converges quickly to the global optimal year, and finds an optimal parameter combination through repeated evaluation. Finally, it uses various machine learning datasets to compare and verify the classification performance change before and after optimization. ##conclusion## Automatic optimization of activation function parameters through PSO improves both the classification accuracy and generalization of the purge ELM, and reduces the repetitive heuristic setting process to enable practical model design.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",48,1.1859924140007934,"**제목: 제공된 문서와 질문의 관련성 부재에 대한 보고서**

**서론:**

제공된 다섯 개의 학술 문서는 각각 민간 의료보험의 영향, 중학교 함수 교육의 문제점 및 개선 방향, 자원봉사 활성화 방안, 그리고 남해 전통시장 활성화 방안에 대한 연구 결과를 담고 있습니다.  반면, 원본 질문은 Particle Swarm Optimization(PSO)을 이용한 퍼지 Extreme Learning Machine(ELM)의 활성화 함수 파라미터 최적화 기법의 핵심 원리를 묻고 있습니다.  제공된 문서에는 PSO, ELM, 퍼지 이론, 활성화 함수 최적화 등 질문에 필요한 핵심 개념에 대한 정보가 전혀 포함되어 있지 않습니다. 따라서 질문에 대한 직접적인 답변은 불가능합니다.

**본론:**

제공된 문서들은 서로 다른 연구 분야를 다루고 있으며, 질문에서 언급된 PSO, ELM, 퍼지 이론과는 아무런 관련이 없습니다.  문서 1은 한국의 민간 의료보험 가입이 의료 이용에 미치는 영향을 분석한 연구 결과를 제시합니다.  문서 2와 3은 중학교 함수 교육 과정에서 학생들이 겪는 어려움과 개선 방안을 논의합니다.  문서 4는 자원봉사 활성화를 위한 방안을 제시하고 있으며, 문서 5는 남해 전통시장 활성화 방안에 대한 연구 결과를 담고 있습니다.  이러한 연구들은 모두 중요한 사회적, 교육적 문제를 다루고 있지만, 질문에서 요구하는 기계학습 알고리즘 및 최적화 기법과는 관련이 없습니다. 따라서 본 보고서에서는 질문에 대한 답변을 제공할 수 없습니다.

**결론:**

제공된 문서에는 Particle Swarm Optimization을 이용해 퍼지 Extreme Learning Machine의 활성화 함수 파라미터를 최적화하는 기법에 대한 정보가 포함되어 있지 않습니다.  따라서 질문에 대한 답변을 작성할 수 없습니다.  질문에 대한 답변을 얻으려면 PSO, ELM, 퍼지 이론, 그리고 활성화 함수 최적화에 대한 관련 학술 자료를 제공해야 합니다.",민간의료보험 가입이 의료이용에 미치는 영향,함수 단원 문제해결 시 수학적 추론 과정에서 발생하는 오류 분석,함수 개념 지도에 대한 연구,자원봉사 활성화 방안에 관한 연구,전통시장 활성화 방안에 관한 연구 : 남해전통시장을 중심으로,필터프레스 탈수기의 함수율 저감방안에 관한 연구,벡터 공간에서의 도함수,로그함수 단원에서의 GSP 활용 및 학습 자료 개발,삼각함수 단원의 효율적인 교수법에 관한 연구 : 고등학교 수학 교과서를 중심으로,삼각함수 덧셈정리의 이해 실태 분석 및 시각화를 통한 지도에 관한 연구,함수 개념의 효율적인 지도방안,역함수 정리와 음함수 정리,"고등학교 2학년 학생들의 이차함수, 삼각함수, 지수함수 그래프 과제 해결능력",기업브랜드 활성화를 위한 전시공간 특징에 관한 연구,4차 산업혁명과 지역의 산학협력 활성화 방안 에 관한 연구: 포항지역 중심으로,노인일자리 창출사업 활성화 방안에 관한 연구,청계천로 주변지역의 가로활성화 요인분석,전통시장 활성화 방안에 관한 연구 : 익산시 전통시장을 중심으로,어린이집 홈페이지를 활용한 부모교육 활성화 방안에 관한 연구,서해안시대에서의 군산항의 역할 증대 및 전북 경제의 활성화 방안,한국궁중무용 활성화 방안에 관한 연구 : 무용 전공자들의 인식현황을 중심으로,수치모델을 통한 한국 남해 동부해역의 해양쓰레기 이동에 관한 연구,지속가능한 수변지역 개발을 위한 토지이용계획,다중이용업소 소방안전의 실효성 확보를 위한 방안,다중이용업소 화재피해 최소화 방안에 관한 연구 : 화재 원인 조사 분석을 중심으로,한중소비자의 여행공유경제 이용의도 비교분석 : 여행공유경제 플랫폼과 소비자 개인 특성을 중심으로,소비자들의 서비스 로봇의 이용의도 영향요인에 대한 탐색적 연구,지방자치단체의 구역 및 경계에 관한 법적 과제,화석돌말류를 통한 울릉분지와 대한해협에서의 고해양학적인 연구,양자강 저염수의 시공간적 변동에 관한 수치 실험,,,,,,,,,,,,,,,,,,,,
Lifelong Machine Learning 앙상블 방식으로 스팸 메시지 필터링 성능을 개선한 방법의 주요 아이디어와 장점을 간결하게 제시해 주실 수 있나요?,"##제목## Lifelong Machine Learning과 나이브 베이즈 앙상블을 이용한 스팸 메시지 필터링 ##서론## 스팸 문자는 끊임없이 새로운 단어와 패턴을 적용해 기존 필터를 우회하므로, 고정된 학습 모델만으로는 적절히 대응하기 어렵다. 이러한 한계를 극복하기 위해 과거 지식을 누적·활용하며 지속 학습하는 Lifelong Machine Learning(LLML) 개념이 도입되었다. ##본론## 제안 기법은 문서 분류에 널리 사용되는 나이브 베이즈 분류기와 LLML의 ELLA 모델을 앙상블로 결합한다. LLML은 이전 학습에서 획득한 특성·패턴 정보를 새로운 데이터에 전이해 빠르게 적응하고, 나이브 베이즈는 낮은 계산 복잡도로 실시간 필터링에 적합하다. 앙상블 구조를 통해 두 모델의 장점을 동시에 활용함으로써, 신규 스팸 단어·패턴에도 높은 민감도와 정확도를 유지할 수 있다. ##결론## 과거 학습 경험을 지속적으로 보존·활용하는 LLML 기반 앙상블은 스팸 필터링의 적응성을 대폭 향상시키며, 변화하는 스팸 유형에 효과적으로 대응할 수 있다.","Lifelong Machine Learning ensemble, can you provide a concise of the main ideas and advantages of the method that improves spam message filtering performance?","##title## Lifelong Machine Learning and Spam Message Filtering using Nive Bayes Ensemble ##introduction## Spam characters are constantly bypassing existing filters by applying new words and patterns, so it is difficult to respond properly with a fixed learning model alone. In order to overcome these limitations, the concept of LIFELONG MACHINE Learning (LLML), which cumulates and utilizes past knowledge, has been introduced. ## Main ## The proposal technique combines the Nive Bayes classifier and the ELLA model of LLML, which are widely used in document classification, with ensemble. LLML is quickly adapted to the new data by transferring the characteristics and pattern information obtained from previous learning, and Nive Bayes is suitable for real -time filtering with low computation complexity. By using the advantages of the two models at the same time through the ensemble structure, it is possible to maintain high sensitivity and accuracy in new spam words and patterns. ##conclusion## LLML -based ensemble, which continuously preserves and utilizes past learning experiences, greatly improves the adaptability of spam filtering and can effectively respond to changing spam types.","Title: u-IT Convergence 기기의 성능평가기준과 표준화 연구, Abstract: u-IT 기술의 발달로 인해 통신, 방송, 포털, 콘텐츠, 장비 및 솔루션 등 사업의 모든 분야에 u-IT Convergence 기기들이 연구 개발되고 있다. 본 논문에서는 u-IT Convergence를 정의하고, u-IT Convergence 기기들과 단말에서 정보를 감지하는 온도, 압력, 자기, 광, 가스, 습도 센서들에 대한 정의와 평가 기준으로 기술성, 경제성, 경영성 등의 평가 기준을 제시한다. 또한 u-IT Convergence 기기들에 대한 평가 기준에 따르는 u-IT Convergence 네트워크 기기의 표준화 기준을 연구하였다. 본 연구를 통해 유비쿼터스 정보화 사회에서 기술적인 발전과 기기들에 대한 정확한 인증 평가를 통해서 안정성과 신뢰성을 갖춘 평가 제품으로서 가치를 정립하고 표준화를 이루는데 기여하게 될 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12915394,","Title: IT 기반의 convergence 제품의 구입태도에 대한 연구, Abstract: 본 연구의 목적은 소비자들이 IT 기반의 컨버전스 제품을 구매함에 있어서 지각하는 구매태도를 바탕으로 구매의사결정을 이론적 배경에 대한 검토를 바탕으로 가설을 설정하고 이들 가설을 검증하기 위하여 실증연구를 수행하였다. IT 컨버전스 제품에 있어서 효용성이 주는 소비자들이 제품이나 서비스를 채용하는데 있어서 매우 중요한 전략적 접근방법이다. 소비자들의 IT 컨버전스 제품을 구매하는데 있어 기업의 경쟁력 강화전략을 도출하는 것이 성공적인 시장진입에 대한 시사점임을 알 수 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP12636907,","Title: 한국 IT융합 신산업 역량강화요인, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지니는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로, 우리나라를 비롯하여 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합 신산업 역량강화요인을 도출하고자 2011년도에 실시한 정책연구의 학계 및 공공기관 전문가 델파이 결과를 선행연구들과 비교하여 한국의 IT 융합역량의 수준 변화를 평가하고 결론적으로 한국의 IT융합 신산업 역량강화요인을 도출하고자 하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201222653561945,","Title: 건강운동을 위한 IT 융합기술의 접근 동향, Abstract: IT 융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업창출을 목표로 국가전략적 차원에서 접근을 하고 있으며 연구자원을 집중 투자하고 있다. 이에 IT 융합은 주력산업을 고부가가치화하고, IT 신산업을 창출할 뿐만 아니라, 범부처적으로 추진하는 신성장동력 육성에 기여하는 첨단융합 산업분야로 부상하게 되었다. 건강관련 융합서비스는 기존의 질병 예방과 관리 중심의 치료기술 산업에서 운동/스포츠 및 재활 중심의 엔터테인먼트체험 산업으로 확장되는 추세이다. 따라서 본 논문에서는 IT 융합에 대하여 그 중요성을 지니는 것만큼 건강운동과 관련된 IT 융합기술개발 동향을 파악하고 기존에 진행되었던 주요 기술개발과 융합산업 발전을 위한 방향에 관한 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201521052964495,","Title: 국방IT융합기술의 발전전략에 관한 연구, Abstract: 국방IT융합이란 네트워크중심전(Network Centric Warfare) 개념을 실현하기 위해 새로운 IT 융합기술을 개발하여 실제 전력화하는 것이다. 국방부는 창조경제 시대적 사명인 국방IT융합발전을 위해 국방기술품질원의 국방IT융합 센터를 전담기관으로 지정하였고 융합센터를 중심으로 국방IT융합 과제 발굴을 위한 산 학 연구기관과 군 소요조사, 사전 기술기획 활동하며 국방 도메인 전문가로 구성된 과제기획팀 운영과 선진 기획방법 적용 등을 통해 민간IT 신기술의 적기 도입을 중점적으로 추진하고 있다. 이에 따라 국방IT융합 발전을 위해 국가IT융합 정책 추진과 국방IT융합기술 현상을 이론적으로 고찰하고 종합적으로 분석한 뒤 효과적으로 활용할 수 있는 발전전략이 절실히 요구된다. 본 논문은 국방IT융합발전을 위해 식별된 IT융합 과제를 단계화 추진하고 신설된 국방IT융합센터의 효율성을 제고하며 국방개혁과 연계된 IT융합인재 육성방안을 제시함으로써 스마트 국방을 조기에 달성하고 패러다임의 신속한 전환과 창조경제 구현에도 크게 기여할 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201406566439056,","Title: 산업생태계 관점에서 바라본 IT융합 촉진전략, Abstract: IT융합은 제조업 등 타 산업 분야의 경쟁력을 향상시키는데 기여하고 있다. 지금까지 정부는 융합기술 개발 및 사업화에 많은 지원을 해왔으며 몇몇 선도기업에서는 의미 있는 성과를 거두고 있다. 그러나 IT융합을 기반으로 산업 경쟁력을 강화하기 위해서는 다양한 융합 시도가 이뤄질 수 있는 생태계가 구축되어야 하며, 많은 기업들이 융합에 참여하고 협력하며 그 혜택을 널리 공유할 수 있는 환경이 마련되어야 한다. 본 연구에서는 AHP 분석을 토대로 IT융합을 촉진하기 위한 이해관계자들의 역할을 도출하고자 하였다. 연구 결과, IT융합을 촉진하기 위한 산업 생태계 마련을 위해 정부의 규제 완화와 벤처 육성정책 확대, 키스톤 기업의 협업기반 융합과제 확대와 경험 공유, 벤처기업 등 기술개발 주체의 기술역량 강화, 그리고 크로스오버형 인재양성을 위한 대학의 역할이 필요한 것으로 나타났다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201411560021821,","Title: 정보기술(IT)의 효율화, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART56139046,","Title: 미래 IT융합 신산업 육성 및 선도방안, Abstract: IT는 한국의 경제성장에 큰 기여를 해왔으며 사회전반의 패러다임 혁신을 통해 생산성, 효율성, 편의성, 소통성을 증진시키고 삶의 양식에 전면적 변화를 가져왔다. 국민경제와 사회문화에서 지대한 의미를 지나는 IT는 다른 기술 또는 산업과의 융합이라는 새로운 변화와 혁신의 중심에 위치하고 있다. IT융합은 IT의 자체 고도화를 바탕으로 다른 분야의 기술개발과 산업발전을 견인하거나 새로운 산업을 창출하는 것으로 우리나라를 비롯하며 주요국에서는 자원과 역량을 선택적으로 집중하고 있다. 이 논문에서는 IT 융합과 관련된 주요국의 산업 전략 및 기술개발 동향을 파악하고 전문가 설문조사결과를 바탕으로 한국의 IT 융합역량의 수준을 평가하고 결론적으로 IT융합신산업육성 및 선도방안에 관한 전략적 제언을 하고자 한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201109649105387,","Title: IT 컨버전스의 이해와 법ㆍ기술 방향, Abstract: 21세기의 인터넷의 화두는 통합과 협업이다. 컨버전스가 핵심이며, IT컨버전스의 정확한 개념이해가 중요하다. 즉, “IT컨버전스는 하드웨어ㆍ소프트웨어ㆍ네트워크ㆍ콘텐츠서비스의 융ㆍ복합”이라 할 수 있다. IT컨버전스는 개방과 공유, 참여를 통해 이용자를 서로 연결해주던 웹2.0의 진정한 실현과 개인에게 최적화된 정보를 제공해주는 웹3.0 시대로의 진입을 앞당길 것이다. 구현 기술이 관건이다. 컨버전스 시대의 진정한 구현을 뒷받침할 수 있는 기술 특징의 인식은 매우 중요하다. 기술의 방향은 컨버전스 시대에 부합하는 글로벌 표준화이어야 한다. 소개한 표준화 기술은 하드웨어와 소프트웨어, 네트워크 및 콘텐츠 상호 간 종속하지 않고 자유롭게 n-Screen과 5A를 구현하기 위한 것이 다.&nbsp;아울러 Convergence 시대에 맞는 새로운 법적 규율의 논의가 필요하다. 컨버전스 시대의 중요한 요소인 콘테츠를 통한 서비스는 국가와 기업, 개인 간의 관계를 변화시키고 있다. 따라서 각자의 역할 변화에 따른 법적 규율의 재정립이 필요하다. 무엇보다도 헌법 원리에 근거를 두어야 할 것이다. 이는 정보의 존중, 형성, 참여하는 민주주의의 동태적인 실현과, 공동체와 구성원들의 다양한 이익의 조화로운 실현을 위한 규범체계의 형성원리인 법치주의, 정보격차의 해소라는 측면에서의 복리주의를 담아야 함을 의미한다. IT관련 법적 규율 논의는 통제와 진흥, 활성화를 위한 방향이 되어야 한다. 법적 이슈 논의와 기술구현 방향이 설정되어야 할 것이다. IT 컨버전스 및 기술표준화의 이해, n-Screen 콘텐츠와 서비스를 향한 GㆍBㆍC의 역할변화와 정보 활용의 다양화 등등 새로운 시각에서 접근해야 한다.&nbsp;여기서 소개하는 Original XML은 쌍방향ㆍ다방향 소통과 표현을 통해 21세기를 주도할 Community Culture Society를 실현할 것으로 기대된다. IT 융합환경에 필요한 법제도적 방향에 대한 부가적인 언급은 미래 규범체계에 작은 도움이 될 수 있을 것이다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART69859897,","Title: 정보통신 융합기기 연계를 고려한 데이터 중심의 정보시스템 모델의 설계 및 분석, Abstract: 데이터 중심 정보시스템 구축 모델은 그간 정보화 사업 추진이 HW, SW기능 중심으로 이루어지던 것을, 데이터 구조 및 데이터 수집 배포 채널에 대한 체계적인 분석과 설계, 데이터표준 적용, 정보통신 융합기기의 데이터 설정의 유연성 확보 등의 고려하여 개선한 모델이다. 이 모델의 주요 특성인 정보통신 융합기기에 데이터 유연성이 보장되는 개선 효과에 대해 센서와 반응기로 구분하여 이들 기기에 새로운 정보시스템이 추가적으로 연계되는 상황을 가정하여 시스템 개선 복잡도와 네트워크 환경에 대한 지수를 산정하여 기존의 일반적인 구축 방식과 비교하였다. 본 모델을 확산함으로써, 일반 업무용 정보시스템 외에 나날이 늘어나는 정보기술 융 복합 기기들이 처리하는 데이터에 대해서도 품질과 상호운용성을 통제하게 되어, 정보화 거버넌스의 영역 확대를 통해 종합적인 정보화 기획 및 성과 관리 등이 가능하게 되는 개선 효과가 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201318552673266,","Title: IT 분야에서 컨버전스의 의미와 미래 전망, Abstract: 컨버전스(Convergence)란 단어는 집합, 집중, 수렴, 한 곳으로 모여짐 등의 뜻을 지닌 일반적인 용어로써 매우 발전해가고 있는 IT 분야에서 다양한 수요자의 욕구와 기술의 진화에 따라 최근에 매우 빈번하게 등장하고 있는 용어이자, 중요한 화두 중에 하나가 되고 있다. 이에 단어가 지니고 있는 일반적 의미를 다각적으로 분석함과 동시에 그 의미가 정보통신분야의 기술적 측면에서 또한 활용적인 측면에서 어떤 암시와 효과를 나타내고 있고, 나아가 IT 분야의 발전을 향한 목표 지향적인 측면에서의 역할이 가능한지와 또 다른 발전과 진화에 따라 어느 정도의 생명력과 경쟁력은 지닐 수 있는지를 살펴보고자 한다. 20세기 후반에 등장한 새로운 산업의 빅뱅이 되고 있는 IT 분야가 전세계로 확산, 발전되어감에 따라 수많은 일반적인 단어와 용어 들이 정보통신분야에서 도입, 활용하였고 이러한 용어들은 단어 자체의 의미 보다는 정보통신분야 발전의 현재와 미래를 규정해왔고, 나아가 정보통신 발전에 따른 혜택을 받는 전세계와 국내의 이용자들에게 많은 변화를 제공함과 동시에 연관분야의 산업에도 긍정적이던 부정적이던지 상호간 막대한 영향을 미쳐왔다고 분석된다. 이에 본 논문 자료는 IT 전문 용어가 아닌 일반적인 용어 중에서 IT 분야의 어떤 형태로든 영향을 미칠 용어 중에서 컨버전스란 단어를 통해 IT 분야의 현주소를 사례를 중심으로 분석, 점검하고 향후 IT 분야에서 컨버전스가 적용될 미래의 발전 모습을 전망하고자 하는데 있다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP08146428,","Title: IT융합 기술을 활용한 스마트 페데스털 시스템의 개발, Abstract: 최근 해양 레포츠 활동에 대한 사람들의 참여가 증가하면서 마리나에 대한 수요가 폭증하고 있다. 이와 같은 수요를 충당하기 위하여 국토해양부에서는 2019년까지 총 1조 7000억원을 투입하여 전국 43개소에 5,600여척을 계류할 수 있는 마리나 시설을 건립할 계획이다. 마리나 시설에 가장 필요한 시설이 바로 레저 보트에 전기와 물을 공급할 수 있는 페데스털 시스템이다. 현재, 우리나라에 설치되는 페데스털 시스템은 전부 해외에서 수입하고 있다. 이에 본 논문에서는 국내 최초로 IT 융합 기술을 이용하여 스마트 페데스털 시스템을 개발하였다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201224747154220,","Title: IT 컨버전스기술 기반의 지역 방재정보통신산업 도출, Abstract: 본 연구에서는 IT 선도 기술의 동향을 분석하고 IT 컨버전스 산업의 방향을 분석하였다. 또한 특정 지역의 산업 및 기술동향을 분석하여 산업간 융합을 통한 신산업 도출방법을 제안 하였는 바, 지역별 특수성을 분석하기 위하여 산업정책, 지역기반 산업과 IT 산업 그리고 인프라 등 과 같은 현황을 고려하였다. 결과적으로, 지역사업화 매력도와 사업화 경쟁력을 고려한 육성 사업군이 선정된 바, 방재산업과 연계된 방재정보통신 산업 모델을 제안한다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART51554091,","Title: AHP를 이용한 에너지-IT 융합기술 도출에 관한 연구, Abstract: 세계적으로 비효율적인 에너지 소비로 인한 에너지 및 환경 문제가 지속적으로 대두되고 있다. 최근 이 같은 문제를 해결하기 위해서 에너지-IT(Energy-IT, EIT)융합기술이 효과적인 해결책으로 큰 관심을 받고 있다. 하지만 국내에서는 스마트그리드 외 EIT 융합기술에 대한 정책적 연구개발 및 투자가 미흡한 실정이다. 따라서 본 논문에서는 EIT 융합 기술의 효용성을 조사하고 AHP(Analytic Hierarchy Process) 기법을 이용하여 EIT 융합기술을 도출한다. 본 연구를 통하여 정부의 국가 에너지 문제 해결과 경쟁력을 향상을 위한 정책 결정에 기여할 것으로 기대한다. 연구결과 에너지 저감 분야 중에서는 에너지절약형건물(green building) 분야가 가장 효용성 있는 융합분야로 분석되었고, 에너지절약형건물 분야 내의 융합기술 중에서 네트워크 기능을 활용한 건물 내 에너지소비기기가 기술성, 경제성 부문에서 높은 중요도를 받으면서 가장 높은 기술로 평가 되었다., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO201030853090604,","Title: Machine learning on Big Data, Abstract: Statistical Machine Learning has undergone a phase transition from a pure academic endeavor to being one of the main drivers of modern commerce and science. Even more so, recent results such as those on tera-scale learning [1] and on very large neural networks [2] suggest that scale is an important ingredient in quality modeling. This tutorial introduces current applications, techniques and systems with the aim of cross-fertilizing research between the database and machine learning communities. The tutorial covers current large scale applications of Machine Learning, their computational model and the workflow behind building those. Based on this foundation, we present the current state-of-the-art in systems support in the bulk of the tutorial. We also identify critical gaps in the state-of-the-art. This leads to the closing of the seminar, where we introduce two sets of open research questions: Better systems support for the already established use cases of Machine Learning and support for recent advances in Machine Learning research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NPAP&cn=NPAP11397415,","Title: Implikationen von Machine Learning auf das Datenmanagement in Unternehmen, Abstract: AbstractMachine Learning is a trend research area with great potential and far-reaching application potentials. Big Data is an enabler, as large and high-quality data are always the basis for successful machine learning algorithms and models. There is currently no fully established standard process for the machine learning life cycle, as is the case in data mining with the CRISP-DM-Process, which means that the operationalization of machine learning models in particular can present companies with major challenges. In this article, the implications for data management in companies are worked out on the basis of the view of the nature of the data, the various roles in machine learning teams and the life cycle of machine learning models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART101894389,","Title: Enhanced Machine Learning Algorithms: Deep Learning, Reinforcement Learning, and Q-Learning, Abstract: In recent years, machine learning algorithms are continuously being used and expanded in various fields, such as facial recognition, signal processing, personal authentication, and stock prediction. In particular, various algorithms, such as deep learning, reinforcement learning, and Q-learning, are continuously being improved. Among these algorithms, the expansion of deep learning is rapidly changing. Nevertheless, machine learning algorithms have not yet been applied in several fields, such as personal authentication technology. This technology is an essential tool in the digital information era, walking recognition technology as promising biometrics, and technology for solving state-space problems. Therefore, algorithm technologies of deep learning, reinforcement learning, and Q-learning, which are typical machine learning algorithms in various fields, such as agricultural technology, personal authentication, wireless network, game, biometric recognition, and image recognition, are being improved and expanded in this paper., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202032255805983,","Title: Machine Learning and Cryptography, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108155732,","Title: Econometrics and Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART129086024,","Title: Machine Learning and Deep Learning for the Pharmacogenomics of Antidepressant Treatments, Abstract: A growing body of evidence now proposes that machine learning and deep learning techniques can serve as a vital foundation for the pharmacogenomics of antidepressant treatments in patients with major depressive disorder (MDD).In this review, we focus on the latest developments for pharmacogenomics research using machine learning and deep learning approaches together with neuroimaging and multi-omics data. First, we review relevant pharmacogenomics studies that leverage numerous machine learning and deep learning techniques to determine treatment prediction and potential biomarkers for antidepressant treatments in MDD. In addition, we depict some neuroimaging pharmacogenomics studies that utilize various machine learning approaches to predict antidepressant treatment outcomes in MDD based on the integration of research on pharmacogenomics and neuroimaging. Moreover, we summarize the limitations in regard to the past pharmacogenomics studies of antidepressant treatments in MDD. Finally, we outline a discussion of challenges and directions for future research. In light of latest advancements in neuroimaging and multi-omics, various genomic variants and biomarkers associated with antidepressant treatments in MDD are being identified in pharmacogenomics research by employing machine learning and deep learning algorithms., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002777203,","Title: USING MACHINE LEARNING METHODS IN CYBERSECURITY, Abstract: Abstract Cybersecurity is an ever-changing field, with advances in technology that open up new opportunities for cyberattacks. In addition, even though serious secu- rity breaches are often reported, small organizations still have to worry about security breaches as they can often be the target of viruses and phishing. This is why it is so important to ensure the privacy of your user profile in cyberspace. The past few years have seen a rise in machine learning algorithms that address major cybersecu- rity issues such as intrusion detection systems (IDS), detection of new modifications of known malware, malware, and spam detection, and malware analysis. In this arti- cle, algorithms have been analyzed using data mining collected from various libraries, and analytics with additional emerging data-driven models to provide more effective security solutions. In addition, an analysis was carried out of companies that are en- gaged in cyber attacks using machine learning. According to the research results, it was revealed that the concept of cybersecurity data science allows you to make the computing process more efficient and intelligent compared to traditional processes in the field of cybersecurity. As a result, according to the results of the study, it was revealed that machine learning, namely unsupervised learning, is an effective method of dealing with risks in cybersecurity and cyberattacks., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART118582509,","Title: Topology optimization via machine learning and deep learning: a review, Abstract: Topology optimization (TO) is a method of deriving an optimal design that satisfies a given load and boundary conditions within a design domain. This method enables effective design without initial design, but has been limited in use due to high computational costs. At the same time, machine learning (ML) methodology including deep learning has made great progress in the 21st century, and accordingly, many studies have been conducted to enable effective and rapid optimization by applying ML to TO. Therefore, this study reviews and analyzes previous research on ML-based TO (MLTO). Two different perspectives of MLTO are used to review studies: (i) TO and (ii) ML perspectives. The TO perspective addresses “why” to use ML for TO, while the ML perspective addresses “how” to apply ML to TO. In addition, the limitations of current MLTO research and future research directions are examined., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART003008557,","Title: &#x201e;Machine learning“ in der An&auml;sthesiologie, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART108282335,","Title: Machine Learning na Medicina: Revis&atilde;o e Aplicabilidade, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117822080,","Title: Digitalisierung der Handsortierung durch K&uuml;nstliche Intelligenz, Machine Learning und Human Machine Interaction, Abstract: AbstractWaste management is transforming into a manufacturing industry in the circular economy. Despite advances and optimisations in automatic sensor-based sorting, hand sorting of waste remains relevant. The recAIcle project aims to advance the digitalisation of hand sorting in waste management using Artificial Intelligence (AI), Machine Learning (ML) and Human-Machine Interaction (HMI). AI and ML have repeatedly shown how they revolutionise entire industries and sectors. The RecAIcle project focuses on plastic and battery characterisation and sorting. Thus, the productivity and quality of manual sorting are to be increased, and a digital assistance system that supports sorting employees in their sorting decisions is being developed for this purpose. Due to the unique requirements of such a system, the framework design was adapted accordingly. For the development of this system, advanced, life-long learning ML models are needed, which in turn require large amounts of high-quality training data and computing power. In order to provide sufficient use-case-specific training data, experiments were carried out under controlled conditions on a pilot plant scale for training data acquisition. The results of the system design process and the first training data acquisition are presented in this paper. An outlook on future developments and further planned trials is also given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART128227262,","Title: Wave data prediction with optimized machine learning and deep learning techniques, Abstract: Maritime Autonomous Surface Ships are in the development stage and they play an important role in the upcoming future. Present generation ships are semi-autonomous and controlled by the ship crew. The performance of the ship is predicted using the data collected from the ship with the help of machine learning and deep learning methods. Path planning for an autonomous ship is necessary for estimating the best possible route with minimum travel time and it depends on the weather. However, even during the navigation, there will be changes in weather and it should be predicted in order to reroute the ship. The weather information such as wave height, wave period, seawater temperature, humidity, atmospheric pressure, etc., is collected by ship external sensors, weather stations, buoys, and satellites. This paper investigates the ensemble machine learning approaches and seasonality approach for wave data prediction. The historical meteorological data are collected from six stations near Puerto Rico offshore and Hawaii offshore. We explore ensemble machine learning techniques on the data collected. The collected data are divided into training and testing data and apply machine learning models to predict the test data. The hyperparameter optimization is performed to find the best parameters before fitting on train data, this is essential to find the best results. Multivariate analysis is performed with all the methods and errors are computed to find the best models., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002850623,","Title: Machine Learning in Predicting Hemoglobin Variants, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART93885082,","Title: Wine Quality Evaluation Using Machine Learning Algorithms, Abstract: There are many prediction systems available for problems like stock exchange, medical diagnosis, insurance calculation, etc. Wine Quality is one area where there is a big opportunity to recommend a good quality of wine to users based on their preferences as well as in historical data. This paper describes the work to learn and assess whether a given wine sample is of good quality or not. The use of machine learning techniques specifically the linear regression with stochastic gradient descent were explored, and the features that perform well on this classification were engineered. The main aim is to develop a cost-effective system to acquire knowledge using data analysis through machine learning algorithms to predict the quality of wine in a better way., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002303063,","Title: Scientific Machine Learning Seismology, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART134692948,","Title: Machine learning, Abstract: A short review of research and applications in machine learning is given. Rather than attempt to cover all areas of ML, the focus is on its role in building expert systems, its approach to classification problems and ML methods of learning control. A relatively new area, inductive logic programming, is also discussed., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART13071369,","Title: Machine learning-based adaptive CSI feedback interval, Abstract: The channel state information (CSI) is essential for the base station (BS) to schedule user equipments (UEs) and efficiently manage the radio resources. Hence, the BS requests UEs to regularly feed back the CSI. However, frequent CSI reporting causes large signaling overhead. To reduce the feedback overhead, we propose two machine learning-based approaches to adjust the CSI feedback interval. We use a deep neural network and reinforcement learning (RL) to decide whether an UE feeds back the CSI. Simulation results show that the RL-based approach achieves the lowest mean squared error while reducing the number of CSI feedback transmissions., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002921834,","Title: Big Data Analysis and Machine Learning in Intensive Care Units, Abstract: Abstract Intensive care is an ideal environment for the use of Big Data Analysis (BDA) and Machine Learning (ML), due to the huge amount of information processed and stored in electronic format in relation to such care. These tools can improve our clinical research capabilities and clinical decision making in the future. The present study reviews the foundations of BDA and ML, and explores possible applications in our field from a clinical viewpoint. We also suggest potential strategies to optimize these new technologies and describe a new kind of hybrid healthcare-data science professional with a linking role between clinicians and data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART98001731,","Title: Artificial intelligence, machine learning, and deep learning in women’s health nursing, Abstract: Artificial intelligence (AI), which includes machine learning and deep learning has been introduced to nursing care in recent years. The present study reviews the following topics: the concepts of AI, machine learning, and deep learning; examples of AI-based nursing research; the necessity of education on AI in nursing schools; and the areas of nursing care where AI is useful. AI refers to an intelligent system consisting not of a human, but a machine. Machine learning refers to computers’ ability to learn without being explicitly programmed. Deep learning is a subset of machine learning that uses artificial neural networks consisting of multiple hidden layers. It is suggested that the educational curriculum should include big data, the concept of AI, algorithms and models of machine learning, the model of deep learning, and coding practice. The standard curriculum should be organized by the nursing society. An example of an area of nursing care where AI is useful is prenatal nursing interventions based on pregnant women’s nursing records and AI-based prediction of the risk of delivery according to pregnant women’s age. Nurses should be able to cope with the rapidly developing environment of nursing care influenced by AI and should understand how to apply AI in their field. It is time for Korean nurses to take steps to become familiar with AI in their research, education, and practice., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002572344,","Title: Machine Learning기법을 이용한 Robot 이상 예지 보전, Abstract: In this paper, a predictive maintenance of the robot trouble using the machine learning method, so called MT(Mahalanobis Taguchi), was studied. Especially, 'MD(Mahalanobis Distance)' was used to compare the robot arm motion difference between before the maintenance(bearing change) and after the maintenance. 6-axies vibration sensor was used to detect the vibration sensing during the motion of the robot arm. The results of the comparison, MD value of the arm motions of the after the maintenance(bearing change) was much lower and stable compared to MD value of the arm motions of the before the maintenance. MD value well distinguished the fine difference of the arm vibration of the robot. The superior performance of the MT method applied to the prediction of the robot trouble was verified by this experiments., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202011161035055,","Title: Speech Recognition using Machine Learning, Abstract: Speech recognition is one of the fastest-growing engineering technologies. It has several applications in different areas, and provides many potential benefits. A lot of people are unable to communicate due to language barriers. We aim to reduce this barrier via our project, which was designed and developed to achieve systems in particular cases to provide significant help so people can share information by operating a computer using voice input. This project keeps that factor in mind, and an effort is made to ensure our project is able to recognize speech and convert input audio into text; it also enables a user to perform file operations like Save, Open, or Exit from voice-only input. We design a system that can recognize the human voice as well as audio clips, and translate between English and Hindi. The output is in text form, and we provide options to convert audio from one language to the other. Going forward, we expect to add functionality that provides dictionary meanings for Hindi and English words. Neural machine translation is the primary algorithm used in the industry to perform machine translation. Two recurrent neural networks used in tandem to construct an encoder–decoder structure are the architecture behind neural machine translation. This work on speech recognition starts with an introduction to the technology and the applications used in different sectors. Part of the report is based on software developments in speech recognition., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002724517,","Title: Comparison of Machine Learning Tools for Mobile Application, Abstract: Demand for machine learning systems continues to grow, and cloud machine learning platforms are widely used to meet this demand. Recently, the performance improvement of the application processor of smartphones has become an opportunity for the machine learning platform to move from the cloud to On-Device AI, and mobile applications equipped with machine learning functions are required. In this paper, machine learning tools for mobile applications are investigated and compared the characteristics of these tools., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002879874,","Title: Machine learning political orders, Abstract: AbstractA significant set of epistemic and political transformations are taking place as states and societies begin to understand themselves and their problems through the paradigm of deep neural network algorithms. A machine learning political order does not merely change the political technologies of governance, but is itself a reordering of politics, of what the political can be. When algorithmic systems reduce the pluridimensionality of politics to the output of a model, they simultaneously foreclose the potential for other political claims to be made and alternative political projects to be built. More than this foreclosure, a machine learning political order actively profits and learns from the fracturing of communities and the destabilising of democratic rights. The transformation from rules-based algorithms to deep learning models has paralleled the undoing of rules-based social and international orders - from the use of machine learning in the campaigns of the UK EU referendum, to the trialling of algorithmic immigration and welfare systems, and the use of deep learning in the COVID-19 pandemic - with political problems becoming reconfigured as machine learning problems. Machine learning political orders decouple their attributes, features and clusters from underlying social values, no longer tethered to notions of good governance or a good society, but searching instead for the optimal function of abstract representations of data., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122432758,","Title: Machine Learning Versus Deep Learning Performances on the Sentiment Analysis of Product Reviews, Abstract: At this current digital era, business platforms have been drastically shifted toward online stores on internet. With the internet-based platform, customers can order goods easily using their smart phones and get delivery at their place without going to the shopping mall. However, the drawback of this business platform is that customers do not really know about the quality of the products they ordered. Therefore, such platform service often provides the review section to let previous customers leave a review about the received product. The reviews are a good source to analyze customer's satisfaction. Business owners can assess review trend as either positive or negative based on a feedback score that customers had given, but it takes too much time for human to analyze this data. In this research, we develop computational models using machine learning techniques to classify product reviews as positive or negative based on the sentiment analysis. In our experiments, we use the book review data from amazon.com to develop the models. For a machine learning based strategy, the data had been transformed with the bag of word technique before developing models using logistic regression, na&iuml;ve bayes, support vector machine, and neural network algorithms. For a deep learning strategy, the word embedding is a technique that we used to transform data before applying the long short-term memory and gated recurrent unit techniques. On comparing performance of machine learning against deep learning models, we compare results from the two methods with both the preprocessed dataset and the non-preprocessed dataset. The result is that the bag of words with neural network outperforms other techniques on both non-preprocess and preprocess datasets., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART114024871,","Title: Analysis of Machine Learning Education Tool for Kids, Abstract: Artificial intelligence and machine learning are used in many parts of our daily lives, but the basic processes and concepts are barely exposed to most people. Understanding these basic concepts is becoming increasingly important as kids don't have the opportunity to explore AI processes and improve their understanding of basic machine learning concepts and their essential components. Machine learning educational tools can help children easily understand artificial intelligence and machine learning. In this paper, we examine machine learning education tools and compare their features., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002670216,","Title: Breast cancer detection by leveraging Machine Learning, Abstract: India has witnessed 30% of the cases of breast cancer during the last few years and it is likely to increase. Breast cancer in India accounts that one woman is diagnosed every two minutes and every nine minutes, one woman dies. Early detection and diagnosis can save the lives of cancer patients. This paper presents a novel method to detect breast cancer by employing techniques of Machine Learning. The authors carried out an experimental analysis on a dataset to evaluate the performance. The proposed method has produced highly accurate and efficient results when compared to the existing methods., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002671762,","Title: Application of Machine Learning and Deep Learning in Imaging of Ischemic Stroke, Abstract: Timely analysis of imaging data is critical for diagnosis and decision-making for proper treatment strategy in the cases of ischemic stroke. Various efforts have been made to develop computer-assisted systems to improve the accuracy of stroke diagnosis and acute stroke triage. The widespread emergence of artificial intelligence technology has been integrated into the field of medicine. Artificial intelligence can play an important role in providing care to patients with stroke. In the past few decades, numerous studies have explored the use of machine learning and deep learning algorithms for application in the management of stroke. In this review, we will start with a brief introduction to machine learning and deep learning and provide clinical applications of machine learning and deep learning in various aspects of stroke management, including rapid diagnosis and improved triage, identifying large vessel occlusion, predicting time from stroke onset, automated ASPECTS (Alberta Stroke Program Early CT Score) measurement, lesion segmentation, and predicting treatment outcome. This work is focused on providing the current application of artificial intelligence techniques in the imaging of ischemic stroke, including MRI and CT., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002918042,","Title: An Efficient Parallel Machine Learning-based Blockchain Framework, Abstract: The unlimited possibilities of machine learning have been shown in several successful reports and applications. However, how to make sure that the searched results of a machine learning system are not tampered by anyone and how to prevent the other users in the same network environment from easily getting our private data are two critical research issues when we immerse into powerful machine learning-based systems or applications. This situation is just like other modern information systems that confront security and privacy issues. The development of blockchain provides us an alternative way to address these two issues. That is why some recent studies have attempted to develop machine learning systems with blockchain technologies or to apply machine learning methods to blockchain systems. To show what the combination of blockchain and machine learning is capable of doing, in this paper, we proposed a parallel framework to find out suitable hyperparameters of deep learning in a blockchain environment by using a metaheuristic algorithm. The proposed framework also takes into account the issue of communication cost, by limiting the number of information exchanges between miners and blockchain., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002764866,","Title: Machine learning in oncology-Perspectives in patient-reported outcome research, Abstract: AbstractBackgroundIncreasing data volumes in oncology pose new challenges for data analysis. Machine learning, a branch of artificial intelligence, can identify patterns even in very large and less structured datasets.ObjectiveThis article provides an overview of the possible applications for machine learning in oncology. Furthermore, the potential of machine learning in patient-reported outcome (PRO) research is discussed.Materials and methodsWe conducted a selective literature search (PubMed, MEDLINE, IEEE Xplore) and discuss current research.ResultsThere are three primary applications for machine learning in oncology: (1) cancer detection or classification; (2) overall survival prediction or risk assessment; and (3) supporting therapy decision-making and prediction of treatment response. Generally, machine learning approaches in oncology PRO research are scarce and few studies integrate PRO data into machine learning models.DiscussionMachine learning is a promising area of oncology, but few models have been transferred into clinical practice. The promise of personalized cancer therapy and shared decision-making through machine learning has yet to be realized. As an equally important emerging research area in oncology, PROs should also be incorporated into machine learning approaches. To gather the data necessary for this, broad implementation of PRO assessments in clinical practice, as well as the harmonization of existing datasets, is suggested., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART116697768,","Title: MACHINE LEARNING, Abstract: The motivation for machine learning is to have computers extract concepts and relations from databases or through interactive sessions with a user and then use them in any knowledge-intensive activity. Developing knowledge bases for expert systems applications is one such activity. Studying computer-based learning techniques gives a better understanding of human mental processes. Two types of programs are considered that learn from examples: those, called data-driven learners, that generalize by relying entirely on the data presented to them, and a group of more elaborate programs, called model-driven learners, that proceed by generating fairly general hypotheses that are subsequently tested against the given examples or against the user in a typical interactive session. The model-driven learner is contrasted with the data-driven learner and an example of the former using a model-driven learner called Marvin is given., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART17972174,","Title: Machine Learning을 이용한 자동 돌발상황검지, Abstract: Incidents on the freeway disrupt traffic flow and the cost of delay caused by incidents is significant. To reduce the impact of an incident, a traffic management center needs to quickly detect and remove it from the freeway. Quick and efficient automatic incident detection has been a main goal of the transportation research for many years. Also many algorithms based on loop detector data have been developed and tested for the Automatic Incident Detection(AID). However, many of them have a limited success in their overall performance in terms of detection rate, false alarm rate, and the mean time to detect an incident. Until recently, the neural network models have been the one of the popular and efficient approach for real-time automatic incident detection and many researches have shown that the neural network models were much more efficient than various other previous models. The purpose of this research is to propose a more efficient and accurate model than the neural network model in the automatic incident detection problem. For this purpose, a machine learning model, Support Vector Machine (SVM) learning which is based on the statistical learning theory, has been used in this paper. The experiments have been done with real world freeway data, and the results show that the SVM could provide better performance in terms of DR(Detection Rate) and FAR(False Alarm Rate) than Backpropagation which is the most popular neural network model., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART001157316,","Title: Crop Prediction Using Machine Learning, Abstract: 없음, Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART122202269,","Title: Predicting Terrorism with Machine Learning: Lessons from “Predicting Terrorism: A Machine Learning Approach”, Abstract: AbstractThis paper highlights how machine learning can help explain terrorism. We note that even though machine learning has a reputation for black box prediction, in fact, it can provide deeply nuanced explanations of terrorism. Moreover, machine learning is not sensitive to the sometimes heroic statistical assumptions necessary when parametric econometrics is applied to the study of terrorism. This increases the reliability of explanations while adding contextual nuance that captures the flavor of individualized case analysis. Nevertheless, this approach also gives us a sense of the replicability of results. We, therefore, suggest that it further expands the role of science in terrorism research., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART94298406,","Title: A Survey of Topological Machine Learning Methods, Abstract: The last decade saw an enormous boost in the field of computational topology: methods and concepts from algebraic and differential topology, formerly confined to the realm of pure mathematics, have demonstrated their utility in numerous areas such as computational biology personalised medicine, and time-dependent data analysis, to name a few. The newly-emerging domain comprising topology-based techniques is often referred to as topological data analysis (TDA). Next to their applications in the aforementioned areas, TDA methods have also proven to be effective in supporting, enhancing, and augmenting both classical machine learning and deep learning models. In this paper, we review the state of the art of a nascent field we refer to as &ldquo;topological machine learning,&rdquo; i.e., the successful symbiosis of topology-based methods and machine learning algorithms, such as deep neural networks. We identify common threads, current applications, and future challenges., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART117389222,","Title: Liver Fibrosis Biomarker Validation Using Machine Learning Algorithms, Abstract: Background: Liver fibrosis which causes several liver diseases, requires early screening and management. The gold standard for fibrosis assessment, liver biopsy, has recently been replaced by noninvasive scores. In this study, we validated liver fibrosis-associated biomarkers using machine learning techniques applied in medical research and evaluated their prediction models.Methods: Noninvasive scores were assayed in 144 patients who underwent transient elastography (TE). The patients were divided into three groups (<7 kPa, 7–10 kPa, ≥10 kPa) according to their TE results. Feature selection and modeling for predicting liver fibrosis were performed using random forest (RF) and support vector machine (SVM).Results: Considering the mean decrease in impurity, permutation importance, and multicollinear analysis, the important features for differentiating between the three groups were Mac-2 binding protein glycosylation isomer (M2BPGi), platelet count, and aspartate aminotransferase (AST). Using these features, the RF and SVM models showed equivalent or better performance than noninvasive scores. The sensitivities of RF and SVM models for predicting ≥7 kPa TE results were higher than noninvasive scores (83.3% and 90.0% vs. <80%, respectively). The sensitivity and specificity of RF and SVM models for ≥10 kPa TE result was 100%.Conclusions: We used machine learning techniques to verify the usefulness of established serological biomarkers (M2BPGi, PLT, and AST) that predict liver fibrosis. Conclusively, machine learning models showed better performance than noninvasive scores., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=ART002974610,","Title: Effective E-Learning Practices by Machine Learning and Artificial Intelligence, Abstract: This is an extended research paper focusing on the applications of Machine Learing and Artificial Intelligence in virtual learning environment. The world is moving at a fast pace having the application of Machine Learning (ML) and Artificial Intelligence (AI) in all the major disciplines and the educational sector is also not untouched by its impact especially in an online learning environment. This paper attempts to elaborate on the benefits of ML and AI in E-Learning (EL) in general and explain how King Khalid University (KKU) EL Deanship is making the best of ML and AI in its practices. Also, researchers have focused on the future of ML and AI in any academic program. This research is descriptive in nature; results are based on qualitative analysis done through tools and techniques of EL applied in KKU as an example but the same modus operandi can be implemented by any institution in its EL platform. KKU is using Learning Management Services (LMS) for providing online learning practices and Blackboard (BB) for sharing online learning resources, therefore these tools are considered by the researchers for explaining the results of ML and AI., Source: http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO202408181678829,",49,1.1859924140007934,"**제목: 머신러닝 기반 스팸 메시지 필터링 성능 개선을 위한 앙상블 기법 활용**

**서론:** 본 보고서는 머신러닝 기반의 스팸 메시지 필터링 성능을 개선하기 위해 Lifelong Machine Learning 앙상블 방식을 활용하는 주요 아이디어와 장점을 제시합니다.  문서 3에서 제시된 스팸 메시지 차단 시스템 구축 과정과, 문서 1, 2에서 언급된 다양한 앙상블 기법들을 종합하여 분석합니다.  Lifelong Machine Learning이라는 용어는 제공된 문서에 명시적으로 나타나지 않으나, 지속적인 학습과 성능 향상이라는 맥락에서 해석하여 보고서를 작성합니다.


**본론:** 문서 3은 스팸 메시지 차단 시스템 구축에 SVM(Support Vector Machine) 알고리즘을 기반으로 한 머신러닝 기법을 적용하여 스팸 메시지 차단율을 약 54% 이상 향상시켰다고 명시합니다. 이는 단일 모델을 사용하는 것보다 훨씬 높은 성능을 보여주는 결과입니다.  하지만,  문서 3에서 제시된 방법은 SVM이라는 단일 알고리즘에 의존합니다.  보다 향상된 성능을 위해서는 다양한 알고리즘을 결합하는 앙상블 기법을 적용하는 것이 효과적입니다.

문서 1에서는 다중 스태킹 앙상블 기법이 제안됩니다. 이 기법은 딥러닝 구조와 유사하게, 각 레이어가 스태킹 모델의 조합으로 구성되어 계층의 수를 증가시킴으로써 오분류율을 최소화하여 성능을 개선합니다.  문서 2에서는 지역 기반 분류기의 앙상블 학습이 제시됩니다. 데이터의 분포가 지역에 따라 다르다는 점을 이용하여 지역별 분류기를 생성하고, 지역별 가중치를 부여하여 투표를 통해 최종 결과를 도출합니다. 나이브 베이즈와 SVM을 기본 분류기로 사용했을 때 기존의 배깅, 부스팅보다 우수한 성능을 보였습니다.

따라서, 스팸 메시지 필터링 성능을 개선하기 위한 Lifelong Machine Learning 앙상블 방식은  문서 3의 SVM 기반 시스템에 문서 1과 2의 앙상블 기법들을 적용하는 것을 고려할 수 있습니다. 예를 들어, 다중 스태킹 앙상블을 이용하여 SVM, 나이브 베이즈, 다른 분류 알고리즘 등을 결합하여 계층적인 분류 시스템을 구축할 수 있습니다.  또한, 스팸 메시지 데이터의 특징을 고려하여 지역 기반 앙상블을 적용하면 특정 지역 또는 유형의 스팸에 대한 분류 성능을 더욱 향상시킬 수 있습니다. 이러한 앙상블 기법을 통해 단일 알고리즘보다 더 높은 정확도와 강건성을 가진 스팸 필터링 시스템을 구축할 수 있습니다.  문서 3에서 제시된 ShortURL 탐지 방식과 Redis를 이용한 캐싱 처리 또한 앙상블 시스템의 성능 향상에 기여할 수 있습니다.


**결론:** 스팸 메시지 필터링 성능 개선을 위해 다양한 머신러닝 알고리즘을 결합하는 앙상블 기법의 활용이 필수적입니다.  다중 스태킹 앙상블이나 지역 기반 앙상블과 같은 기법을 통해 기존의 단일 알고리즘 기반 시스템보다 훨씬 높은 정확도와 강건성을 가진 스팸 필터링 시스템을 구축할 수 있습니다.  ShortURL 탐지 및 Redis 캐싱과 같은 추가적인 최적화 기법을 병행하면 더욱 효율적인 스팸 차단 시스템을 구현할 수 있습니다.",다중 스태킹을 가진 새로운 앙상블 학습 기법,지역 기반 분류기의 앙상블 학습,머신러닝 기반의 문자메시지 스팸차단시스템 설계 및 구현,"앙상블로서의 이해, 이해로서의 앙상블",학교음악교육에서의 창의적 관현악 앙상블 프로그램 개발 및 적용,인공신경망을 이용한 스팸 메시지 탐지 기법,사용자 맞춤형 스팸 문자메시지 차단 시스템,자동 생성 메일계정 인식을 통한 스팸 필터링,건설공사 적시생산방식 도입을 위한 사례연구 : 조달단계와 양중단계를 중심으로,투영 조합을 통한 빅데이터 앙상블 모형,앙상블 SVM을 이용한 동적 웹 정보 예측 시스템,부도예측을 위한 KNN 앙상블 모형의 동시 최적화,앙상블 학습을 이용한 적조 발생 예측의 성능향상,스팸 대응 기술 현황,스팸규제에 관한 연구,"2008 스팸방지 가이드라인 개정 공청회-스팸, 수술대에 오르다",데이터마이닝을 활용한 스팸지수에 대한 스팸 스코어링 개발,울산항 강구조물의 전기방식 연구,문헌분류방식에 따른 도서탐색용이성에 관한 연구 : 공공도서관과 대형서점의 분류방식을 중심으로,쓰레기 수송관로시설 도입방안에 대한 타당성 연구 : 은평 뉴타운지구 발생 및 처리방안을 중심으로,"ERP, MES, APS 도입에 관한 연구 : 생산관리 솔루션 선정 기준 제시를 목적으로",부도 예측을 위한 앙상블 분류기 개발,지역 전문가의 앙상블 학습,Applications of Sim-hash and Big Data Analysis in SPAM Email Detection System : SIM-HASH와 빅데이터 분석을 이용한 스팸 메일 탐지 시스템,‘스팸(spam) 사회’,무역 결제방식 변화와 무역지원제도가 수출성과에 미치는 영향,균일한 PPFD 공급이 가능한 가정용 식물 재배기,정전분무를 이용한 전기집진기의 집진효율 향상에 대한 연구,무역결제방식 변화에 따른 비금융기관 지급결제서비스 활용에 대한 연구,근대시의 출현과 존재 방식,,,,,,,,,,,,,,,,,,,,
